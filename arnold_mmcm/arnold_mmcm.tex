\documentclass[leqno]{report}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{chngcntr}
\usepackage{caption}
\usepackage{bm}
\usepackage{upgreek}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{tikz}
\usepackage{hyperref}

\hypersetup{
    colorlinks,
    linkcolor={red!30!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

% replace Greek letter to upright ones
\renewcommand{\pmb}[1]{{
  \renewcommand{\alpha}{\upalpha}
  \renewcommand{\beta}{\upbeta}
  \renewcommand{\gamma}{\upgamma}
  \renewcommand{\delta}{\updelta}
  \renewcommand{\epsilon}{\upepsilon}
  \renewcommand{\varepsilon}{\upvarepsilon}
  \renewcommand{\zeta}{\upzeta}
  \renewcommand{\eta}{\upeta}
  \renewcommand{\theta}{\uptheta}
  \renewcommand{\iota}{\upiota}
  \renewcommand{\kappa}{\upkappa}
  \renewcommand{\lambda}{\uplambda}
  \renewcommand{\mu}{\upmu}
  \renewcommand{\nu}{\upnu}
  \renewcommand{\xi}{\upxi}
  \renewcommand{\pi}{\uppi}
  \renewcommand{\rho}{\uprho}
  \renewcommand{\sigma}{\upsigma}
  \renewcommand{\tau}{\uptau}
  \renewcommand{\upsilon}{\upupsilon}
  \renewcommand{\varphi}{\upvarphi}
  \renewcommand{\phi}{\upphi}
  \renewcommand{\chi}{\upchi}
  \renewcommand{\psi}{\uppsi}
  \renewcommand{\omega}{\upomega}
  \boldsymbol{#1}
}}

\counterwithout{section}{chapter}
\renewcommand{\thesubsection}{\Alph{subsection}}
\numberwithin{equation}{section}
\renewcommand{\theequation}{\arabic{equation}}
\renewcommand{\thefigure}{\arabic{figure}}

\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma} % same numbering with theorem
\newtheorem{prop}{Proposition}
\newtheorem{cor}{Corollary}

\renewcommand{\thethm}{\arabic{thm}}

\newtheorem*{thm*}{Theorem}
\newtheorem*{lem*}{Lemma}
\newtheorem*{prop*}{Proposition}
\newtheorem*{cor*}{Corollary}

% change the style of the proof
\expandafter\let\expandafter\oldproof\csname\string\proof\endcsname
\let\oldendproof\endproof
\renewenvironment{proof}[1][\proofname]{%
  \oldproof[\textsc{#1}]%
}{\oldendproof}

\theoremstyle{definition}
\newtheorem{defn}{Definition}[section]
\renewcommand{\thedefn}{\arabic{defn}}
\newtheorem*{defn*}{Definition}

\theoremstyle{remark}
\newtheorem{rem}{Remark}
\newtheorem*{rem*}{Remark}

\makeatletter
\newtheoremstyle{smallcap}
  {3pt}% space before
  {3pt}% space after
  {%\addtolength{\@totalleftmargin}{3.5em}
   %\addtolength{\linewidth}{-3.5em}
   %\parshape 1 3.5em \linewidth
   \small
  }% body font
  {}% indent
  {\small \sc}% header font
  {.}% punctuation
  {.3em}% after theorem header
  {}% header specification (empty for default)
\makeatother

\theoremstyle{smallcap}
\newtheorem{ex}{Example}
\newtheorem*{ex*}{Example}

\newtheorem{prob}{Problem}
\newtheorem*{prob*}{Problem}
\numberwithin{prob}{section}
\renewcommand{\theprob}{\arabic{prob}}

\newtheorem{ans}{Answer}
\newtheorem*{ans*}{Answer}

\newcommand{\solution}[1]{\textit{Solution.} #1}
\newcommand{\hint}[1]{\textit{Hint.} #1}

% fix the arrow direction for tikz
\makeatletter
\def\pgf@plot@curveto@handler@finish{%
  \ifpgf@plot@started%
    \pgfpathcurvebetweentimecontinue{0}{0.95}{\pgf@plot@curveto@first}{\pgf@plot@curveto@first@support}{\pgf@plot@curveto@second}{\pgf@plot@curveto@second}%
  \fi%
}
\makeatother

% larger arrow
\tikzset{
  big arrow/.style={
    decoration={markings,mark=at position 1 with {\arrow[scale=4]{>}}},
    postaction={decorate},
    shorten >=0.4pt}}

\begin{document}

\definecolor{DarkBlue}{RGB}{0,0,64}
\definecolor{DarkBrown}{RGB}{64,20,10}
\definecolor{DarkGreen}{RGB}{0,64,0}
\definecolor{DarkPurple}{RGB}{64,0,42}
% annotation macros
\newcommand{\repl}[2]{{\color{gray} [#1] }{\color{blue} #2}}
\newcommand{\add}[1]{{\color{blue} #1}}
\newcommand{\del}[1]{{\color{gray} [#1]}}
\newcommand{\note}[1]{{\color{DarkGreen}\footnotesize \textsc{Note.} #1}}
\newcommand{\answer}[1]{{\color{DarkBlue}\footnotesize \textsc{Answer.} #1}}
\newcommand{\summary}[1]{{\color{DarkPurple}\footnotesize \textsc{Summary.} #1}}


\tableofcontents


\part{NEWTONIAN MECHANICS}
\chapter{Experimental facts}

\section{The principles of relativity and determinancy}

\section{The galilean group and Newton's equations}

\section{Examples of mechanical systems}



\chapter{Investigation of the equations of motion}

\section{Systems with one degree of freedom}

\section{Systems with two degrees of freedom}

\section{Conservative force fields}

\section{Angular momentum}

\section{Investigation of motion in a central field}

\section{The motion of a point in three-space}

\section{Motions of a system of $n$ points}

\section{The method of similarity}

\part{LAGRANGIAN MECHANICS}

\chapter{Variational principles}

In this chapter we show that the motions
of a newtonian potential system are extremals
of a variational principle,
``Hamilton's principle of least action.''

This fast has many important consequences,
including a quick method for writing equations
of motion in curvilinear coordinate systems,
and a series of qualitative deductions--for example,
a theorem on returning to a neighborhood of initial point.

In this chapter we will use an $n$-dimensional coordinate space.
%
A vector in such a space is a set of numbers
$\mathbf x = (x_1, \dots, x_n)$.
Similar,
$\partial f/\partial \mathbf x$
means
$(\partial f/\partial x_1, \dots, \partial f/\partial x_n)$,
and
$(\mathbf a, \mathbf b) = a_1 b_1 + \cdots a_n b_n$.


\section{Calculus of variations}

For what follows, we will need some facts from the calculus of variations.
%
A more detailed exposition can be found in
``A Course in the Calculus of Variations''
by M. A. Lavrentiev and L. A. Lusternik, M. L., 1938,
or
G. E. Shilov, ``Elementary Functional Analysis,''
MIT Press, 1974.


The calculus of variations is concerned with the extremals of
functions whose domain is an infinite-dimensional space:
the space of curves.
%
Such functions are called \emph{functionals}.

An example of a functional is the length of a curve in the euclidean plane:
if $\gamma = \{(t, x): x(t) = x,  t_0 \le t \le t_1 \}$,
then $\Phi(\gamma) = \int_{t_0}^{t_1} \sqrt{1 + {\dot x}^2 } dt$.

In general, a functional is any mapping from the space of curves
to the real numbers.

We consider an ``approximation'' $\gamma'$ to $\gamma$,
$\gamma' = \{(t, x): x = x(t) + h(t)\}$.
%
We will call it $\gamma' = \gamma + h$.
Consider the increment of $\Phi$,
$\Phi(\gamma + h) - \Phi(\gamma)$
(Figure 41).

\section{Lagrange's equations}




% section 14
\section{Legendre transformations}

The Legendre transformation is a very useful mathematical tool:
it transforms functions on a vector space
to functions on the dual space.
%
Legendre transformations are related to
projective duality and tangential coordinates in algebraic geometry
and the construction of dual Banach space in analysis.
%
\note{
  A Banach space is a complete vector space with a norm.
}
%
They are often encountered in physics
(for example, in the definition of thermodynamic quantities).

% subsection A
\subsection{Definition}

Let $y = f(x)$ be a convex function, $f''(x)$.
%
The \emph{Legendre transformation}
of the function $f$ is a new function $g$ of a new variable $p$,
which is constructed in the following way
(Figure \ref{fig:Legendre_transformation}).


\setcounter{figure}{42}
\begin{figure}[h]
  \centering
  \begin{tikzpicture}
    \draw[->] (0, 0) -- (4.5, 0);
    \draw[->] (0, 0) -- (0, 3);
    \node[] at (4.7, 0) {$x$};
    \node[] at (0.2, 2.8) {$y$};

    % y = p x
    \draw[] (0,0) -- (3.6, 2.4);

    % tangent line
    \draw[] (0.75, 0) -- (2.55, 1.2);

    % g(p)
    \node[] at (1.0, 1.4) {$g(p)$};
    \draw[] (1.5, 0.5) -- (1.5, 1.0);
    \draw[dotted] (1.5, 0.0) -- (1.5, 0.5);
    \draw[] (1.5, 0.75) -- (1.0, 1.2);

    % f(x)
    \draw[scale=1,domain=0:3.4,smooth,variable=\x, very thick]
    plot ({\x}, {\x*\x*0.5/2.25});
    %\draw[thick] plot [smooth, tension=1]
    %    coordinates{(0, 0) (1.5, 0.5) (2.8, 1.9) (3.2, 2.5)};
    \node[] at (3.3, 2.8) {$f(x)$};

    \node[] at (1.5, -0.2) {$x(p)$};

    % p
    \node[] at (3.5, 2.15) {$p$};
    \draw[] (3.3, 2.2) -- (3.3, 2.1) -- (3.15, 2.1);
  \end{tikzpicture}
  \caption{
    \label{fig:Legendre_transformation}
    Legendre transformation
  }
\end{figure}

We draw the graph of $f$ in the $x,y$ plane.
%
Let $p$ be a given number.
%
Consider the straight line $y = p \, x$.
%
We take the point $x = x(p)$
at which the curve is farthest from the straight line
in the vertical direction for each $p$ the function
$p \, x - f(x) = F(p, x)$ has a maximum with respect to $x$
at the point $x(p)$.
%
Now define $g(p) = F(p, x(p))$.

The point $x(p)$ is defined by the extremal condition
$\partial F/\partial x = 0$, i.e.,
$f'(x) = p$.
%
Since $f$ is convex the point $x(p)$ is unique.\footnote{
If it exits.}

\begin{prob*}
  Show that the domain of $g$ can be a point,
  a closed interval, or a ray if $f$ is defined
  on the whole $x$ axis.
  %
  Prove that if $f$ is defined on a closed interval,
  then $g$ is defined on the whole $p$ axis.

  \answer{
    Since the function $f(x)$ is convex,
    $f'(x)$ is increasing.
    %
    If $f'(-\infty) = f'(+\infty)$,
    the domain of $g$ is a point.
    Otherwise, if both $f'(-\infty)$ and $f'(\infty)$
    are finite, the domain is a closed interval;
    or if one of them is infinity,
    the domain is a ray.
  }
\end{prob*}

% subsection B
\subsection{Examples}

\begin{ex}
  Let $f(x) = x^2$.
  Then $F(p, x) = p \, x - x^2$,
  $x(p) = \frac 1 2 p$,
  $g(p) = \frac 1 4 p^2$.
\end{ex}

\begin{ex}
  Let $f(x) = m x^2 / 2$,
  then $g(p) = p^2/ 2  m$.
\end{ex}

\begin{ex}
  Let $f(x) = x^\alpha/\alpha$
  then $g(p) = p^\beta/\beta$,
  where $1/\alpha + 1/\beta = 1$
  ($\alpha > 1, \beta > 1$).
\end{ex}

\begin{figure}[h]
  \centering
  \begin{tikzpicture}
    [
      enode/.style={minimum size=0, inner sep=0},
      wnode/.style={circle, draw, fill=white, minimum size=1.5mm, inner sep=0}
    ]
    \draw[->] (0, 0) -- (2.5, 0);
    \draw[->] (0, 0) -- (0, 2.5);
    \node[] at (2.4, -0.2) {$x$};
    \node[] at (0.1, 2.7) {$f$};

    % y = p0 x
    \draw[] (0, 0) -- (2.4, 0.8);

    % p0
    \node[] at (1.8, 0.2) {$p_0$};
    \draw[] (1.5, 0.5) -- (2.1, 0.5) -- (2.1, 0.7);

    % y = p1 x
    \draw[] (0, 0) -- (0.8, 2.4);

    % p1
    \node[] at (0.3, 1.8) {$p_1$};
    \draw[] (0.5, 1.5) -- (0.7, 1.5) -- (0.7, 2.1);

    % 2
    \node[wnode, label={-45:$2$}] (f2) at (1.0, 1.0) {};
    % 3
    \node[enode, label={90:$3$}] (f3) at (1.5, 2.5) {}
      edge[very thick] (f2);
    % 1
    \node[enode, label={-90:$1$}] (f1) at (-0.5, 0.5) {}
      edge[very thick] (f2);



    % right panel

    \draw[->] (4, 0) -- (6.5, 0);
    \draw[->] (4, 0) -- (4, 2.5);

    \node[] at (6.7, 0) {$p$};
    \node[] at (4.1, 2.7) {$g$};

    % 1
    \node[wnode, label={-90:$1$}] (g1) at (4.4, -0.6) {};
    % p0
    \node[] (p0) at (4.4, -0.2) {$p_0$};
    \draw (4.4, 0.0) -- (4.4, 0.1);

    % 2
    \node[] at (5.2, -0.2) {$2$};

    % 3
    \node[wnode, label={60:$3$}] (g3) at (6.0, 0.8) {}
      edge[very thick] (g1);
    % p1
    \node[] (p1) at (6.0, -0.2) {$p_1$};
    \draw (6.0, 0.0) -- (6.0, 0.1);
  \end{tikzpicture}
  \caption{
    \label{fig:Legendre_transformation_angle}
    Legendre transformation
    taking an angle to a line segment
  }
\end{figure}

\begin{ex}
  Let $f(x)$ be a convex polygon.
  %
  Then $g(p)$ is also a convex polygon in which
  the vertices of $f(x)$ correspond to the edges
  of $g(p)$, and the edges of $f(x)$
  to the vertices of $g(p)$.
  %
  For example,
  the corner depicted in Figure \ref{fig:Legendre_transformation_angle}
  is transformed to a segment under
  the Legendre transformations.
\end{ex}


% subsection C
\subsection{Involutivity}

Let us consider a function $f$ which is differentiable
as many as necessary, with $f''(x) > 0$.
%
It is easy to verify that
a Legendre transformation
takes convex functions to convex functions.
\note{
  Since $g(p) = x \, p - f(x)\big|_{x = x(p)}$,
  we have
  $g'(p) = x + \left.[p - f'(x)]\frac{dx}{dp}\right|_{x=x(p)} = x,$
  and
  $g''(p) = \frac{ d x(p) }{ d p } = \left.\frac{ 1 } { f''(x) }\right|_{x = x(p)} > 0.$
}
Therefore, we can apply it twice.

\begin{thm*}
  The Legendre transformation is involutive,
  i.e., its square is the identity:
  if under the Legendre transformation $f$
  is taken to $g$, then the Legendre transform
  of $g$ will again be $f$.
\end{thm*}

\begin{proof}
  In order to apply the Legendre transform to $g$,
  with variable $p$, we must by definition look at
  a new independent variable (which we will call $x$),
  construct the function
  $$
  G(x, p) = x \, p - g(p),
  $$
  and find the point $p(x)$ at which $G$ attains its maximum:
  $\partial G/\partial p = 0$,
  i.e., $g'(p) = x$.
  %
  Then the Legendre transform of $g(p)$ will be the function
  of $x$ equal to $G(x, p(x))$.

  We will show that $G(x, p(x)) = f(x)$.
  To this end, we notice that $G(x, p) = x \, p - g(p)$
  has a simple geometric interpretation:
  it is the ordinate\note{$y$-coordinate}
  of the point abscissa $x$ on the line
  tangent to the graph of $f(x)$
  with slope $p$ (Figure \ref{fig:involutivity_Legendre_transformation}).
%
  \begin{figure}[h]
    \centering
    \begin{tikzpicture}
      \draw[->] (0, 0) -- (4, 0);
      \draw[->] (0, 0) -- (0, 5);
      \node[] at (4.3, 0) {$x$};
      \node[] at (0.3, 4.5) {$y$};

      % f(x)
      \draw[scale=1.0, domain=0:3.2,smooth,variable=\x, very thick]
        plot ({\x},{\x*\x*0.3+1});
      \node[] at (2.8, 4.2) {$f(x)$};

      % x0
      \draw[thick] (1.5, 0) -- (1.5, 1.675);
      \node[] at (1.5, -0.3) {$x_0$};
      \node[circle, draw=black, fill=white, minimum size=1.5mm, inner sep=0]
        at (1.5, 1.675) {};

      % x(p)
      \draw[blue!50!gray] (2.5, 0) -- (2.5, 2.875);
      \node[] at (2.5, -0.3) {$x(p)$};

      % tangent line at (2.5, 2.875)
      % slope is 1.5
      \draw[blue!50!gray] (0.5, -0.125) -- (3.5, 4.375);

      % tangent line at (0.5, 1.075)
      % slope is 0.3
      \draw[red!50!gray] (0.0, 0.925) -- (3.5, 1.975);

      % tangent line at (3.2, 4.072)
      % slope is 1.92  y = 1.92*x - 2.072
      \draw[green!50!gray] (1.3, 0.164) -- (3.5, 4.648);

    \end{tikzpicture}
    \caption{
      \label{fig:involutivity_Legendre_transformation}
      Involutivity of the Legendre transformation.
    }
  \end{figure}
%
  \note{Suppose at $x_1$, the tangent line to $y = f(x)$
    has slope $p = f'(x_1)$,
    then $g(p) = p x_1 - f(x_1)$.
    Here $x_1 = x(p)$ in Figure \ref{fig:involutivity_Legendre_transformation}.
    %
    Now the equation of this tangent line is
    $y - f(x_1) = p (x - x_1)$,
    which is
    $y = p x - g(p) = G(x, p)$.
    %
    This means $G(x, p)$ gives the $y$ coordinate
    of the tangent line obtained at $x_1 = x(p)$
    at another $x$;
    this point always lies below $f(x)$.
  }
  For fixed $p$, the function $G(x, p)$
  is a linear function of $x$,
  with $\partial G/\partial x = p$,
  and for $x = x(p)$
  we have $G(x, p) = x \, p - g(p) = f(x)$
  by definition of $G(p)$.

  Let us now fix $x = x_0$ and vary $p$.
  %
  Then the values of $G(x, p)$ will be the ordinates
  of the points of intersection of the line $x = x_0$
  with the line tangent to the graph of $f(x)$
  with various slopes $p$.
  %
  By the convexity of the graph,
  it follows that all these tangents
  lie below the curve,
  and therefore the maximum of $G(x, p)$
  for a fixed $x(p_0)$ is equal to $f(x)$
  (and is achieved for $p = p(x_0) = f'(x_0)$).
\end{proof}

\begin{cor*}\footnote{
    One can easily see that
    this is the theory of ``Clairaut's equation.''
  }
  Consider a given family of straight lines
  $y = p \, x - g(p)$.
  %
  Then its envelope has the equation
  $y = f(x)$,
  where $f$ is the Legendre transform of $g$.
\end{cor*}

% subsection D
\subsection{Young's inequality}

\begin{defn*}
  Two functions, $f$ and $g$,
  which are the Legendre transform
  of one another are called dual
  \emph{in the sense of Young}.
\end{defn*}

By definition of the Legendre transform,
$F(x, p) = p \, x - f(x)$ is less than
or equal to $g(p)$ for any $x$ and $p$.
\note{Fixing $p$ and varying $x$,
  we have $F(x, p) \le g(p)$ by definition $g(p)$.
  Fixing $x$ and varying $p$,
  we have $xp - g(p) \le f(x)$ because
  $f(x)$ is Legendre transform of $g(p)$.
}
From this we have \emph{Young's inequality}:
$$
p \, x \le f(x) + g(p).
$$

\setcounter{ex}{0}
% example 1
\begin{ex}
If $f(x) = \frac{1}{2} x^2$,
then $g(p) = \frac{1}{2} p^2$
and we obtain the well-known inequality
$px \le \frac 1 2 x^2 + \frac 1 2 p^2$
for all $x$ and $p$.
\end{ex}

% example 2
\begin{ex}
  If $f(x) = x^\alpha/\alpha$,
  then $g(p) = p^\beta/\beta$,
  where $(1/\alpha) + (1/\beta) = 1$,
  and we obtain \emph{Young's inequality}
  $px \le \frac{x^\alpha}{\alpha} + \frac{p^\beta}{\beta}$
  for all $x > 0, p > 0, \alpha > 1, \beta > 1$,
  and $1/\alpha + 1/\beta = 1$.
\end{ex}


% subsection E
\subsection{The case of many variables}


Now let $f(\mathbf x)$ be a convex function
of the vector variable
$\mathbf x = (x_1, \dots, x_n)$
(i.e., the quadratic form
$\left( (\partial^2 f/\partial \mathbf x^2) d \mathbf x, d\mathbf x \right)$
is positive definite).
%
Then
the Legendre transform is the function $g(\mathbf p)$
of the vector variable
$\mathbf p = (p_1, \dots, p_n)$,
defined as above by the equalities
$g(\mathbf p) = F(\mathbf p, \mathbf x) = \max_\mathbf{x} F(\mathbf p, \mathbf x)$,
where
$F(\mathbf p, \mathbf x) = (\mathbf p, \mathbf x) - f(\mathbf x)$
and
$\mathbf p = \partial f/\partial \mathbf x$.

All of the above arguments, including Young's inequality,
can be carried over without change to this case.

\begin{prob*}
  Let $f: \mathbb R^n \to \mathbb R$
  be a convex function.
  Let $\mathbb R^{n*}$ denote the dual vector space.
  %
  Show that the formulas above completely
  define the mapping $g: \mathbb R^{n*} \to \mathbb R$
  (under the condition that the linear form
  $df|_\mathbf{x}$ ranges over all of $\mathbb R^{n*}$
  when $\mathbf x$ ranges over $\mathbb R^n$).
\end{prob*}

\begin{prob*}
  Let $f$ be the quadratic form
  $f(\mathbf x) = \sum_{ij} f_{ij} \, x_i \, x_j$.
  %
  Show that its Legendre transform is again
  a quadratic form $g(\mathbf p) = \sum_{ij} g_{ij} \, p_i \, p_j$,
  and that the values of both forms
  at the corresponding points coincide
  (Figure \ref{fig:Legendre_transformation_quadratic}):
  $$
  f(\mathbf x(\mathbf p)) = g(\mathbf p)
  \quad
  \mathrm{and}
  \quad
  g(\mathbf p(\mathbf x)) = f(\mathbf x).
  $$

  \answer{
    $p_i = 2 \sum_j f_{ij} x_j  \to x_i = \frac 1 2 \sum_j f^{-1}_{ij} p_j$.
    $$
    F(\mathbf p, \mathbf x)
    =
    \sum_i p_i x_i - \sum_{ij} f_{ij} \, x_i \, x_j
    =
    \sum_{ij} f_{ij} \, x_i \, x_j
    =
    \sum_{ij} \sum_{kl} f^{-1}_{kl} p_k \, p_l.
    $$
  }
  \begin{figure}[h]
    \centering
    \begin{tikzpicture}
      \draw[->] (0, 0) -- (4.2, 0);
      \draw[->] (0, 0) -- (0, 4.0);
      \node[] at (4.5, 0) {$x$};
      \node[] at (0.2, 3.8) {$y$};

      % y = p x
      \draw[] (0,0) -- (4.1, 4.1);

      % tangent line at (2, 1), slop is 1.0
      % y = 1 + (x - 2) = x - 1
      \draw[] (1.0, 0) -- (3.0, 2.0);

      % g(p)
      \node[] at (1.5, 2.2) {$g(p)$};
      \draw[] (2.0, 1.0) -- (2.0, 2.0);
      \draw[] (2.0, 1.5) -- (1.5, 1.9);

      % f(x)
      \node[] at (2.4, 0.5) {$f(x)$};
      \draw[] (2.0, 0.0) -- (2.0, 1.0);

      % f(x)
      \draw[scale=1,domain=0:4.1,smooth,variable=\x, very thick]
       plot ({\x}, {\x*\x/4});

    \end{tikzpicture}
    \caption{
      \label{fig:Legendre_transformation_quadratic}
      Legendre transformation
      of a quadratic form
    }
  \end{figure}

\end{prob*}

\section{Hamilton's equations}

\section{Liouville's theorem}

\chapter{Lagrangian mechanics on manifolds}

\section{Holonomic constraints}

\section{Differentiable manifolds}

The definition of tangent vectors can also be given
in intrinsic terms,
independent of the embedding of $M$ into $E^n$.

We will call two curves
$\mathbf x = \pmb\varphi(t)$
and
$\mathbf x = \pmb\psi(t)$
\emph{equivalent}
if $\pmb\varphi(0) = \pmb\psi(0) = \mathbf x$
and
$\lim_{t\to 0} (\pmb\varphi(t) - \pmb\psi(t))/t = 0$
in some chart.
%
Then this tangent relationship is true in any chart (prove this!)

\begin{defn*}
  A \emph{tangent vector} to a manifold $M$ at the point $x$
  is an equivalence class of curves $\pmb\varphi(t)$,
  with $\pmb\varphi(0) = \mathbf x$.

  It is easy to define the operations of multiplication
  of a tangent vector by a number and addition of tangent vectors.
  %
  The set of tangent vectors to $M$ at $\mathbf x$ forms a
  \emph{vector space} $TM_\mathbf{x}$.
  %
  This space is also called the \emph{tangent space}
  to $M$ at $\mathbf x$.
\end{defn*}

For embedded manifolds the definition above agrees with the previous
definition.  Its advantage lies in the fact that it also holds
for abstract manifolds, not embedded anywhere.

\begin{defn*}
  Let $U$ be a chart of an atlas for $M$
  with coordinates $q_1,\dots,q_n$.
  Then the \emph{components} of the tangent vector to the curve
  $\mathbf q = \pmb\varphi(t)$
  are the numbers $\xi_1, \dots, \xi_n$,
  where $\xi_i = (d\varphi_i/dt)|_{t = 0}$.
\end{defn*}


\setcounter{subsection}{3}
% subsection D
\subsection{The tangent bundle}

The union of the tangent spaces to $M$
at the various points, $\bigcup_{\mathbf x\in M} TM_\mathbf{x}$,
has a natural differentiable manifold structure,
the dimension of which is twice
the dimension of $M$.
\note{Each point $\mathbf x$ contains an $n$-dimensional
  tangent space. The point $\mathbf x$ itself
  lies on the $n$-dimensional manifold $M$.
  So the union of the tangent spaces is $2n$-dimensional.}

This manifold is called the \emph{tangent bundle}
of $M$ and is denoted by $TM$.
%
A point of $TM$ is a vector $\pmb\xi$,
tangent to $M$ at some point $\mathbf x$.
%
Local coordinates on $TM$ are constructed as follows.
%
Let $q_1, \dots, q_n$ be local coordinates on $M$,
and $\xi_1, \dots, \xi_n$ components of a tangent vector
in this coordinate system.
%
Then the $2n$ numbers
$(q_1, \dots, q_n, \xi_1, \dots, \xi_n)$
give a local coordinate system on $TM$.
%
One sometimes writes $dq_i$ for $\xi_i$.

The mapping $p:TM \to M$
which takes a tangent vector $\pmb\xi$
to the point $\mathbf x\in M$
at which the vector is tangent to $M$
($\pmb\xi \in TM_\mathbf{x}$),
is called the \emph{natural projection}.
%
The inverse image of a point $\mathbf x \in M$
under the natural projection,
$p^{-1}(\mathbf x)$, is the tangent space $TM_\mathbf{x}$.
%
This space is called the
\emph{fiber of the tangent bundle over the point $\mathbf x$}.


% subsection E
\subsection{Riemannian manifolds}

If $M$ is a manifold embedded in euclidean space,
then the metric on euclidean space allows us
measure the lengths of curves, angles between vectors,
volumes, etc.
%
All of these quantities are expressed by means of
the lengths of tangent vectors, that is,
by the positive-definite quadratic form given on
every tangent space $TM_\mathbf{x}$ (Figure 63):
$$
TM_\mathbf{x} \to \mathbb R
\qquad
\pmb\xi \to \langle\pmb\xi, \pmb\xi \rangle.
$$

\begin{figure}[h]
  \centering
  \begin{tikzpicture}
    [
      wnode/.style={circle, fill=white, draw=black, minimum size=1mm, inner sep=0},
      enode/.style={minimum size=0, inner sep=0}
    ]

    \draw[->] (0, 0) -- (5,0);
    \draw[->] (0, 0) -- (0,3);
    \draw[->] (0, 0) -- (-1,-1.5);

    % the frame
    \node[enode] (a1) at (1, 0.2) {};
    \node[enode] (a2) at (4, 0.2) {};
    \node[enode] (a3) at (3, 2.9) {};
    \node[enode] (a4) at (0.3, 1.5) {};
    \draw (a1)[bend left=15]
       to (a2)[bend right=10]
       to (a3)[bend right=20]
       to (a4)[bend left=20] to (a1);

    % M
    \node[enode] at (1.2, 0.5) {$M$};

    % parallelogram
    \draw[thick] (2.0, 0.6) -- (3.6, 0.8) -- (3.2, 1.9) -- (1.6, 1.7) -- cycle;

    % ellipse
    \draw[rotate around={5:(2.65,1.2)}] (2.65,1.2) ellipse (0.65 and 0.4);

    % x and its arrow
    \node[wnode, label={180:$\mathbf x$}] at (2.6, 1.2) {}
      edge[very thick,->] (3.1, 1.25);

    % TMx
    \node[enode] (TMx) at (4.1,1.8) {$TM_\mathbf{x}$};

    % xi
    \node[enode] (xi) at (2.6,0.2) {$\pmb\xi$}
      edge[] (2.9, 1.2);

    % x0 - x1
    \node[wnode, label={0:$\mathbf x_0$}] (x0) at (0.6, 1.4) {};
    \node[wnode, label={0:$\mathbf x_1$}] (x1) at (2.5, 2.5) {};
    \draw[very thick] (x0)[bend left=20] to (x1);
    \draw[] (1.0, 1.6) -- (0.8, 1.8)
            (1.25, 1.85) -- (1.05, 2.05)
            (1.5, 2.0) -- (1.35, 2.25)
            (1.85, 2.15) -- (1.7, 2.45)
            (2.3, 2.3) -- (2.2, 2.6)
    ;
    % dx
    \node[enode, label={90:$d\mathbf x$}] (dx) at (1.3, 2.7) {}
      edge[] (1.6, 2.25);
  \end{tikzpicture}
  \caption{Riemannian metric}
\end{figure}


For example, the length of a curve on a manifold
is expressed using this form as
$I(\gamma) = \int_{\mathbf x_0}^{\mathbf x_1}
\sqrt{\langle d\mathbf, d\mathbf x\rangle}$,
or, if the curve is given parametrically,
$\gamma:[t_0, t_1] \to M, t \to \mathbf x(t) \in M$,
then
$$
I(\gamma) = \int_{\mathbf x_0}^{\mathbf x_1}
\sqrt{ \langle \dot{\mathbf x}, \dot{\mathbf x} \rangle } \, dt
$$

\begin{defn*}
  A differentiable manifold with a fixed positive-definite
  quadratic form $\langle \pmb\xi, \pmb\xi \rangle$
  on every tangent space $TM_\mathbf{x}$
  is called a \emph{Riemannian manifold}.
  %
  The quadratic form is called the \emph{Riemannian metric}.
\end{defn*}

\begin{rem*}
  Let $U$ be a chart of an atlas for $M$ with coordinates
  $q_1, \dots, q_n$.
  Then a Riemannian metric is given by the formula
  $$
  ds^2 = \sum_{i,j=1}^n a_{ij}(q) \, dq_i \, dq_j
  \qquad
  a_{ij} = a_{ji},
  $$
  where $dq_i$ are the coordinates of a tangent vector.

  The functions $a_{ij}(q)$ are assumed to be
  differentiable as many times as necessary.
\end{rem*}


% subsection F
\subsection{The derivative map}

Let $f: M \to N$ be a mapping of a manifold $M$ to a manifold $N$.
%
$f$ is called \emph{differentiable} if in local coordinates on $M$ and $N$
it is given by differentiable functions.


\begin{defn*}
  The \emph{derivative} of a differentiable mapping $f: M \to N$
  at a point $\mathbf x \in M$ is the linear map of the tangent spaces
  $$
  f_{*\mathbf x}: TM_\mathbf{x} \to TN_{f(\mathbf x)},
  $$
  which is given in the following way (Figure 64).

  \begin{figure}[h]
    \centering
    \begin{tikzpicture}
    [
      wnode/.style={circle, fill=white, draw=black, minimum size=1mm, inner sep=0},
      enode/.style={minimum size=0, inner sep=0}
    ]
      % curve
      \draw plot [thick, smooth, tension=1.0]
      coordinates{(-0.8, -0.5) (-0.5, -0.1) (0.2, 0.4) (1.1, 0.4)};

      % manifold M
      \draw[] (0, 0) circle (1.5);
      \node[enode] at (0, 1.7) {$M$};

      % TMx
      \node[enode] at (0.3, 0) {$TM_\mathbf{x}$};
      % x
      \node[wnode, label={90:$\mathbf x$}] at (-0.5, -0.1) {}
        edge[very thick,->] (0.2, 0.7);

      % box
      \draw (0, -1.0) -- (1.1, 0.3) -- (0, 1.2) -- (-1.1, -0.1) -- cycle;



      % curve
      \draw plot [thick, smooth, tension=1.0]
      coordinates{(3.6, 0.2) (4.0, 0.43) (4.3, 0.5) };
      \draw plot [thick, smooth, tension=0.6]
      coordinates{(4.3, 0.5) (5.0, 0.3) (5.8, -0.6)};

      % manifold N
      \draw[] (5, 0) circle (1.5);
      \node[enode] at (4, 1.7) {$N$};

      % TNy
      \node[enode] at (4.5, 0.1) {$TN_\mathbf{y}$};
      % y
      \node[wnode, label={30:$\mathbf y$}] at (4.3, 0.5) {}
        edge[very thick,->] (5.7, 0.5);

      % box
      \draw (4, -0.2) -- (6, -0.2) -- (6, 1.0) -- (4, 1.0) -- cycle;


      % mapping f
      \node[enode] (f1) at (1.05, 1.05) {};
      \node[enode] (f2) at (3.95, 1.05) {};
      \node[enode, label={-90:$f$}] (f) at (2.5, 1.5) {};
      \draw (f1)[bend left=15, very thick] to
            (f)[bend left=15, very thick,->] to (f2);

      % mapping f*x
      \node[enode] (fx1) at (0.5, -0.35) {};
      \node[enode] (fx2) at (4.8, -0.2) {};
      \node[enode, label={90:$f_{*\mathbf x}$}] (fx) at (2.5, -1.1) {};
      \draw (fx1)[bend right=20, very thick] to
            (fx)[bend right=20, very thick,->] to (fx2);

    \end{tikzpicture}
    \caption{Derivative of a mapping}
  \end{figure}

  Let $\mathbf v\in TM_\mathbf{x}$.
  Consider a curve $\pmb\varphi: \mathbb R \to M$
  with $\pmb\varphi(0) = \mathbf x$,
  and velocity vector $(d\pmb\varphi/dt)|_{t = 0} = \mathbf v$.
  %
  Then $f_{*\mathbf x}\mathbf v$
  is the velocity vector of the curve
  $f \circ \pmb\varphi: \mathbb R \to N$.
  $$
  f_{*\mathbf x}\mathbf v
  =
  \left.
  \frac{d}{dt}
  \right|_{t = 0}
  f(\pmb\varphi(t)).
  $$
\end{defn*}

\begin{prob*}
  Show that the vector $f_{*\mathbf x}\mathbf v$
  does not dependent on the curve $\pmb\varphi$,
  but only on the vector $\mathbf v$.

  \answer{
    $f_{*\mathbf x}\mathbf v = f'(\mathbf x) \, \mathbf v$.
  }
\end{prob*}

\begin{prob*}
  Show that the map
  $f_{*\mathbf x}: TM_\mathbf{x} \to TN_{f(\mathbf x)}$
  is linear.

  \answer{
    $f_{*\mathbf x}(\lambda_1 \mathbf v_1 + \lambda_2 \mathbf v_2)
    = f'(\mathbf x) \, (\lambda_1 \mathbf v_1 + \lambda_2 \mathbf v_2)$.
  }
\end{prob*}

\begin{prob*}
  Let $\mathbf x = (x_1, \dots, x_m)$
  be coordinates in a neighborhood of $\mathbf x \in M$,
  and $\mathbf y = (y_1, \dots, y_n)$
  be coordinates in a neighborhood of $\mathbf y \in N$.
  Let $\pmb\xi$ be the set of components of the vector $\mathbf v$,
  and $\pmb\eta$ the set of components of the vectors
  $f_{*\mathbf x}\mathbf v$.
  Show that
  $$
  \pmb\eta = \frac{ \partial \mathbf y } { \partial \mathbf x } \pmb\xi,
  \quad \mathrm{i.e.} \quad
  \eta_i = \sum_j \frac{ \partial y_i } { \partial x_j } \xi_j.
  $$

  Taking the union of the mappings $f_{*\mathbf x}$
  for all $\mathbf x$,
  we get a mapping of the whole tangent bundle
  $$
  f_{*\mathbf x}: TM \to TN
  \qquad
  f_{*} \mathbf v
  \quad
  \mathrm{for} \;
  \mathbf x \in TM_\mathbf{x}.
  $$
\end{prob*}

\begin{prob*}
  Show that $f_\mathbf{*}$ is a differentiable map.

  \answer{
    From
    $f_*(\mathbf x, \pmb\xi)
    =
    \left(\mathbf y, \frac{\partial \mathbf y}{\partial \mathbf x}\pmb\xi\right)$,
    we have
    $$
    \frac{ \partial f_*(\mathbf x, \pmb\xi) }{ \partial x_i}
    =
    \left(
      \frac{\partial \mathbf y}{\partial x_i},
      %
      \frac{\partial }{\partial x_i}
        \left(
          \frac{\partial \mathbf y}{\partial \mathbf x}
        \right) \pmb\xi
    \right),
    %
    \qquad
    %
    \frac{ \partial f_*(\mathbf x, \pmb\xi) }{ \partial \xi_i}
    =
    \left(\mathbf 0,
        \left(
          \frac{\partial \mathbf y}{\partial \mathbf x}
        \right)
        \frac{\partial \pmb\xi}{\partial \xi_i}
    \right).
    $$
  }
\end{prob*}

\begin{prob*}
  Let $f: M \to N$,
  $g: N \to K$,
  and
  $h = f \circ g: M\to K$.
  Show that $h_* = g_* \circ f_*$.

  \answer{
    Denote $\pmb\psi(t) = f(\pmb\varphi(t))$, then
  $$
  h_{*\mathbf x}\mathbf v
  =
  \left.
  \frac{d}{dt}
  \right|_{t = 0}
  g(f(\pmb\varphi(t)))
  =
  g'(\pmb\psi(t)) \, f'(\pmb\varphi(t)) \, \mathbf v
  =
  \left[ g_{*f(\mathbf x)} \, \circ f_{*\mathbf x} \right]
  \, \mathbf v.
  $$
  }
\end{prob*}


\section{Lagrangian dynamical systems}

In this paragraph we define lagrangian dynamical systems on manifolds.
Systems with holonomic constraints are a particular case.

% subsection A
\subsection{Definition of a lagrangian system}


\section{E. Noether's theorem}

\section{D'Alembert's principle}

\chapter{Oscillations}

\section{Linearization}

\section{Small oscillations}

\section{Behavior of characteristic frequencies}

\section{Parametric resonance}

\setcounter{subsection}{4}
% subsection E
\subsection{Stability of an inverted pendulum with vertically
  oscillating point of suspension}

\begin{prob*}
  Can the topmost, usually unstable, equilibrium position of
  a pendulum become stable if the point of suspension oscillates
  in the vertical direction (Figure 102)?

  \setcounter{figure}{101}
  \begin{figure}[h]
    \centering
    \begin{tikzpicture}[scale=0.6]
      % upper panel
      \draw[thick, <->] (-0.3, 3) -- (-0.3, 5);
      \node[] at (-0.6, 4) {$2a$};

      \draw[ultra thick] (0,3) -- (0,5);
      \draw[] (0, 4) -- (2, 7);

      \draw[very thick] (1.5, 6.25) arc (60:90:4);
      \draw[very thick, ->] (1.5, 6.25) -- (0, 6.25);

      \draw[thick,->] (2, 7) -- (2, 5);
      \node[] at (2.4, 6) {$mg$};
      \draw[fill=black] (2, 7) circle (0.2);

      % lower panel

      % t axis
      \draw[->] (0,0) -- (5,0);
      \node[] at (5.5, 0) {$t$};

      % a axis
      \draw[->] (0,-2) -- (0,2);
      \node[] at (0.2, 1.8) {$a$};

      % sine wave
      \draw[ultra thick] (0,0) sin (1,1);
      \draw[ultra thick] (1,1) cos (2,0);
      \draw[ultra thick] (2,0) sin (3,-1);
      \draw[ultra thick] (3,-1) cos (4,0);

      \draw[] (0,1) -- (4.1, 1);
      \draw[] (0,-1) -- (4.1, -1);

      \node[] at (2.1, 0.2) {$\tau$};
      \node[] at (4.0, 0.2) {$2\tau$};

      \node[] at (2, 1.7) {Parabola};
      \draw (2, 1.4) -- (1.5, 0.7);
    \end{tikzpicture}
    \caption{
    Inverted pendulum with oscillating point of suspension
    }
  \end{figure}

  Let the length of the pendulum be $l$,
  the amplitude of the oscillation of the point of suspension
  be $a \ll l$,
  the period of oscillation of the point of suspension $2 \,\tau$,
  and, moreover,
  in the source of every half-period let the acceleration
  of the point of suspension be \emph{constant} and equal to $\pm c$
  (then $c = 8a/\tau^2$)
  \note{
    $a = \frac{1}{2} c \, (\tau/2)^2$.
  }
  It turns out that for fast enough oscillations of the point
  of suspension ($\tau \ll 1$)
  the topmost equilibrium becomes stable.

  \solution{
    The equation of motion can be written in the form
    $\ddot x = (\omega^2 \pm d^2) \, x$
    (the sign changes after time $t$),
    where $\omega^2 = g/l$
    and $d^2 = c/l$.
    If the oscillation of the suspension is fast enough,
    then $d^2 > \omega^2$.

    ...
  }
\end{prob*}

%\chapter{Rigid bodies}
%
%\section{Motion in a moving coordinate system}
%
%\section{Inertial forces and the Coriolis force}
%
%\section{Rigid bodies}
%
%\section{Euler's equations. Poinsot's description of the motion}
%
%\section{Lagrange's top}
%
%\section{Sleeping tops and fast tops}

\part{HAMILTONIAN MECHANICS}

Hamiltonian mechanics is geometry in phase space.
%
Phase space has the structure of a symplectic manifold.
%
The group of symplectic diffeomorphisms acts on phase space.
%
The basic concepts and theorems of hamiltonian mechanics
(even when formulated in terms of local symplectic coordinates)
are invariant under this group
(and under the larger group of transformations which also transform time).

A hamiltonian mechanical system is given by an even-dimensional
manifold (the ``phase space''),
a symplectic structure on it (the ``Poincar\'e integral invariant'')
and a function on it (the ``hamiltonian function'').
%
Every one-parameter group of symplectic diffeomorphisms of the phase space
preserving the hamiltonian function is associated to a first integral of
the equations of motion.

Lagrangian mechanics is contained in hamiltonian mechanics as a special
case (the phase space in this case is the cotangent bundle
of the configuration space, and the hamiltonian function is
the Legendre transformation of the lagrangian function).

The hamiltonian point of view allows us to solve completely a series of
mechanical problems which do not yield solutions by other means
(for example, the problem of attraction by two stationary centers
and the problem of geodesics on triaxial ellipsoid).
%
The hamiltonian point of view has even greater value for the approximate
methods of perturbation theory (celestial mechanics),
for understanding the general character of motion
in complicated mechanical systems (ergodic theory, statistical mechanics)
and in connection with other areas of mathematical physics
(optics, quantum mechanics, etc.).

\chapter{Differential forms}

\section{Exterior forms}

\section{Exterior multiplication}



\setcounter{subsection}{2}
%subsection C
\subsection{\label{sec:exterior_mapping}Behavior under mappings}


Let $f: \mathbb{R}^m \to \mathbb{R}^n$ be a linear map,
and $\omega^k$ an exterior $k$-form on $\mathbb{R}^n$.
Then there is a $k$-form $f^*\omega^k$ on $\mathbb{R}^m$,
whose value on the $k$ vectors $\pmb\xi_1, \dots, \pmb\xi_k \in \mathbb{R}^m$
is equal to the value of $\omega^k$ on their images:
$$
(f^*\omega^k)(\pmb\xi_1, \dots, \pmb\xi_k)
=
\omega^k(f\pmb\xi_1, \dots, f\pmb\xi_k).
$$

\note{
  We should note that besides the explicit mapping
  of the tangent vectors, the actual point $\mathbf x \in \mathbb R^m$,
  at which the $k$-form is evaluated is also mapped.
  More explicitly,
$$
(f^*\omega^k_{\mathbf x})(\pmb\xi_1, \dots, \pmb\xi_k)
=
\omega^k_{f\mathbf x}(f\pmb\xi_1, \dots, f\pmb\xi_k),
$$
  The $\omega^k_{\mathbf x}$ on the left
  is a $k$-form on $\mathbb R^m$,
  the $\omega^k_{f\mathbf x}$ on the right is a $k$-form
  on $\mathbb R^n$ for $f\mathbf x \in \mathbb R^n$.
  The subscript usually is omitted in this book.
}

\setcounter{prob}{7}
\begin{prob}
  Verify that $f^*\omega^k$ is an exterior form.

\answer{Antisymmetry:
  $$
  \begin{aligned}
  (f^*\omega^k)(\pmb\xi_1, \dots, \pmb\xi_i, \dots, \pmb\xi_j, \dots, \pmb\xi_k)
  &=
  \omega^k(f\pmb\xi_1, \dots, f\pmb\xi_i, \dots, f\pmb\xi_j, \dots, f\pmb\xi_k)
  \\
  &=
  -\omega^k(f\pmb\xi_1, \dots, f\pmb\xi_j, \dots, f\pmb\xi_i, \dots, f\pmb\xi_k)
  \\
  &=
  -(f^*\omega^k)(\pmb\xi_1, \dots, \pmb\xi_j, \dots, \pmb\xi_i, \dots, \pmb\xi_k).
  \end{aligned}
  $$
}
\end{prob}

\begin{prob}
Verify that $f^*$ is a linear operator from the space of $k$-forms on $\mathbb R^n$
to the space of $k$-forms on $\mathbb R^m$
(the star \emph{superscript} means that $f^*$ acts in the opposite direction from $f$).

\answer{
  $$
  \begin{aligned}
  [f^*(\omega_1^k + \omega_2^k)](\pmb\xi_1, \dots, \pmb\xi_k)
  &=
  (\omega_1^k + \omega_2^k)(f\pmb\xi_1, \dots, f\pmb\xi_k)
  \\
  &=
  \omega_1^k(f\pmb\xi_1, \dots, f\pmb\xi_k)
  +\omega_2^k(f\pmb\xi_1, \dots, f\pmb\xi_k)
  \\
  &=
  (f^*\omega_1^k)(\pmb\xi_1, \dots, \pmb\xi_k)
  +
  (f^*\omega_2^k)(\pmb\xi_1, \dots, \pmb\xi_k).
  \end{aligned}
  $$
}
\end{prob}

\begin{prob}
  Let $f: \mathbb R^m \to \mathbb R^n$ and
  $g: \mathbb R^n \to \mathbb R^p$.
  Verify that $(g\circ f)^* = f^* \circ g^*$.

\answer{
  $$
  \begin{aligned}
  (g\circ f)^*\omega^k(\pmb\xi_1, \dots, \pmb\xi_k)
  &=
  \omega^k((g\circ f)\, \pmb\xi_1, \dots, (g\circ f)\, \pmb\xi_k)
  \\
  &=
  (g^*\omega^k)(f\pmb\xi_1, \dots, f\pmb\xi_k)
  \\
  &=
  (f^*\circ g^*) \, \omega^k(\pmb\xi_1, \dots, \pmb\xi_k).
  \end{aligned}
  $$
}
\end{prob}

\begin{prob}
  \label{prob:fstar_exprod}
Verify that $f^*$ preserves exterior multiplication:
$f^*(\omega^k \wedge \omega^l) = (f^*\omega^k) \wedge (f^*\omega^l).$

\answer{
  $$
  \begin{aligned}
  f^*(\omega^k\wedge \omega^l)(\pmb\xi_1, \dots, \pmb\xi_{k+l})
  &=
  (\omega^k\wedge \omega^l)(f\pmb\xi_1, \dots, f\pmb\xi_{k+l})
  \\
  &=
  \sum_{i}
  (\pm)
    \omega^k(f\pmb\xi_{i_1}, \dots, f\pmb\xi_{i_k}) \
    \omega^l(f\pmb\xi_{i_{k+1}}, \dots, f\pmb\xi_{i_{k+l}})
  \\
  &=
  \sum_{i}
  (\pm)
    (f^*\omega^k)(\pmb\xi_{i_1}, \dots, \pmb\xi_{i_k}) \
    (f^*\omega^l)(\pmb\xi_{i_{k+1}}, \dots, \pmb\xi_{i_{k+l}}).
  \\
  &=
    (f^*\omega^k \wedge f^*\omega^l)
    (\pmb\xi_{i_1}, \dots, \pmb\xi_{i_{k+l}}).
  \end{aligned}
  $$
}
\end{prob}


\section{Differential forms}

\section{Integration of differential forms}

\section{Exterior differentiation}


\chapter{Symplectic manifolds}


A symplectic structure on a manifold is a closed nondegenerate differential
2-form.  The phase space of a mechanical system has a natural symplectic
structure.

On a symplectic manifold, as on a riemannian manifold, there is a natural
isomorphism between vector fields and 1-forms.  A vector field on a symplectic
manifold corresponds to the differential of a function is called a
hamiltonian vector field.  A vector field on a manifold determines a phase
flow, i.e., a one-parameter group of diffeomorphisms.  The phase flow of a
hamiltonian vector field on a symplectic manifold preserves the symplectic
structure of phase space.

The vector fields on a manifold form a Lie algebra.  The hamiltonian
vector fields on a symplectic manifold also form a Lie algebra. The operation
in this algebra is called the Poisson bracket.

% section 37
\section{Symplectic structures on manifolds}

% subsection A
\subsection{Definition}



%\begin{defn*}
Let $M^{2n}$ be an even-dimensional differentiable manifold.
A \emph{symplectic structure} on $M^{2n}$ is a closed nondegenerate differential 2-form
$\omega^2$ on $M^{2n}$:
$$
d\omega^2 = 0
$$
and
$$
\forall \pmb \xi \ne 0
\quad
\exists \pmb \eta:
\;
\omega^2(\pmb \xi, \pmb \eta) \ne 0
\quad
(\pmb \xi, \pmb \eta \in TM_{\mathbf x}).
$$
The pair $(M^{2n}, \omega^2)$ is called
a \emph{symplectic manifold}.
%\end{defn*}

\note{
  A \emph{closed} form $\omega^k$ means $d\omega^k = 0$.
  %
  Intuitively, a closed form has ``no source,'' at least locally.
  %
  On a vector space, being closed means
  $\omega^k$ itself is a differential
  $\omega^k = d\Omega^{k-1}$ for some $\Omega^{k-1}$,
  but this is not necessarily so in general.
  %
  For $\omega^1 = \sum_i a_i dx_i$,
  being closed means $\partial a_i /\partial x_j = \partial a_j/\partial x_i$
  any $i$ and $j$.
  %
  If $\Omega^0$ exists, then $a_i = \partial \Omega^0/\partial x_i$.
  %
  For $\omega^2 = \sum_{ij} a_{ij}dx_i \wedge dx_j$,
  being closed means that
  $\partial a_{ij}/\partial x_k
  = \partial a_{jk}/\partial x_i
  = \partial a_{ki}/\partial x_j$
  for any $i$, $j$, and $k$.
}

\begin{ex*}
  Consider the vector space $\mathbb R^{2n}$
  with coordinates $p_i, q_i$ and let
  $\omega^2 = \sum d p_i \wedge dq_i$.
\end{ex*}

\begin{prob*}
  Verify that $(\mathbb R^{2n}, \omega^2)$
  is a symplectic manifold.
  For $n = 1$ the pair $(\mathbb R^2, \omega^2)$
  is the pair (the plain, area).

\answer{
  Since $\omega^2 = d\omega^1$, with $\omega^1 = \sum_i p_i dq_i$,
  $d\omega^2 = dd\omega^1 = 0$ is closed.
  To show $\omega^2$ is degenerate, take a vector $\pmb\xi$,
  with at least one nonzero component, say it is $p_i$.
  Then, we construct another vector $\pmb\eta$ with $q_i = 1$,
  and other components being zeros.
  Obviously $\omega^2(\pmb\xi, \pmb\eta) = p_i \ne 0$.
  We can similarly show the case for a nonzero $q_i$ component.
  So the 2-form is nondegenerate.
}
\end{prob*}


The following example explains the appearance of symplectic manifolds
in dynamics.  Along with the tangent bundle of a differentiable manifold,
it is often useful to look at its dual--the cotangent bundle.

% subsection B
\subsection{The cotangent bundle and its symplectic structure}



Let $V$ be an $n$-dimensional differentiable manifold.
%
A 1-form on the tangent space to $V$ at a point $\mathbf x$ is called
a \emph{cotangent vector} to $V$ at $\mathbf x$.

This vector space of cotangent vectors is denoted by $T^*V_{\mathbf x}$,
called the \emph{cotangent space} to $V$ at $\mathbf x$.

The union of the cotangent spaces to the manifold at all of its points
is called the \emph{cotangent bundle}, and denoted by $T^*V$.
%
The set $T^*V$ has a natural structure of a differentiable manifold of
dimension $2 n$.
\note{Each point $\mathbf x \in V$ has a $n$-dimensional vectors space;
the dimensionality of $V$ is $n$}.
%
A point of $T^*V$ is a 1-form on the tangent space to $V$ at some point of $V$.
%
If $\mathbf q$ is a choice of a local coordinates for points in $V$,
then such a form is given by its $n$ components $\mathbf p$.
%
Together, the $2n$ numbers $\mathbf p, \mathbf q$ form a collection of local coordinates
for points in $T^*V$.


There is a natural projection
$f: T^*V \to V$.
\note{$f$ sends every 1-form on $TV_{\mathbf x}$
to the point $\mathbf x$}
%
The projection $f$ is differentiable and surjective.
\note{Each $\mathbf x \in V$ has at least one preimage on $T^*V$}
%
The preimage of a point $\mathbf x \in V$ under $f$
is the cotangent space $T^*V_{\mathbf x}$.


\begin{thm*}
The cotangent bundle $T^*V$ has a natural symplectic structure.
%
In the local coordinates described above,
the symplectic structure is given by the formula
$\omega^2 = d\mathbf p \wedge d\mathbf q = dp_1 \wedge dq_1 + \cdots + dp_n \wedge dq_n$.
\end{thm*}

\begin{proof}
First, we define a distinguished 1-form on $T^*V$.
%
Let $\pmb \xi \in T(T^*V)_p$ be a vector
\emph{tangent to the cotangent bundle at the point $p \in T^*V_{\mathbf x}$}
(Figure 166).
\note{This means $p$ is a 1-form with coordinates $\mathbf p$,
and we can express $\pmb \xi$ in local coordinates as $(d\mathbf p, d\mathbf q)$.}
%
The derivative $f_*: T(T^*V) \to TV$
of the natural projection $f: T^*V \to V$,
which takes $\pmb \xi$ to a vector $f_* \pmb \xi$ ($d\mathbf q$)
tangent to $V$ at $\mathbf x$.
%
We define a 1-form $\omega^1$ on $T^*V$ by the relation
$\omega^1(\pmb \xi) \equiv p( f_*\pmb \xi )$
\note{Remember that $p$ is a 1-form so it accepts
  a tangent vector $d\mathbf q = f_* \pmb \xi$
  as input and returns a number.}
%
In the local coordinates described above,
this form is
$\omega^1 = \mathbf p \cdot d\mathbf q$,
and
$\omega^2 = d\omega^1$ is nondegenerate.

\setcounter{figure}{165}
\begin{figure}
  \centering
  \begin{tikzpicture}
    % T^*V
    \draw [] (0, 2) -- (0, 5.5);
    \draw [] (1, 2) -- (1, 5.5);
    \draw [] (2, 2) -- (2, 5.5);
    \draw [] (3, 2) -- (3, 5.5);

    \node [] at (-0.7, 4.5) {$T^*V_{\mathbf x}$};

    % the mapping f
    \node [] at (1.2, 1.2) {$f$};
    \draw [ultra thick, ->] (1.5, 1.5) -- (1.5, 0.7);

    \node [] at (4.0, 3.2) {$T^*V$};
    \draw [ultra thick, ->] (4.0, 2.5) -- (4.0, 0.7);
    \node [] at (4.0, 0.1) {$V$};

    % vector xi
    \draw [ultra thick, ->] (0, 3.5) -- (0.9, 4.8);
    \node [] at (0.5, 3.8) {$\pmb\xi$};

    % point p
    \node [] at (-0.2, 3.5) {$p$};
    \draw [fill=white] (0, 3.5) circle (0.07);

    % V space

    \draw [thick] plot [smooth, tension=1]
      coordinates{(-0.3, -0.13) (1.5, 0.3) (3.3, -0.13)};
    \node [] at (1.5, 0) {$f_*\pmb\xi$};

    \draw [ultra thick, ->] (0, 0) -- (1.0, 0.4);
    \draw [fill=white] (0, 0) circle (0.07);

  \end{tikzpicture}
  \label{fig:1form_cotangent}
  \caption{The 1-form $\mathbf p \, d\mathbf q$ on
    the cotangent bundle}
\end{figure}


\end{proof}

\begin{rem*}
Consider a lagrangian mechanical system with configuration manifold $V$
and lagrangian function $L$.
It is easy to see that the lagrangian ``generalized velocity''
$\dot{\mathbf q}$ is a tangent vector to the configuration manifold $V$,
and the ``generalized momentum''
$\dot{\mathbf p} = \partial L/\partial \dot{\mathbf q}$
is a cotangent vector.
Therefore, the ``$\mathbf p, \mathbf q$'' phase space of the lagriangian
system is the cotangent bundle of the configuration manifold.
The theorem above shows that the phase space of a mechanical problem
has a natural symplectic manifold structure.
%Let $L = L(\mathbf q, \dot{\mathbf q})$  be a Lagrangian.
%%
%Then, $\dot{\mathbf q}$ is a tangent vector;
%%
%$\mathbf p = \partial L/\partial \dot{\mathbf q}$
%is a cotangent vector.
%%
%The $\mathbf p, \mathbf q$ phase space of the Lagrangian system
%is the cotangent of the configuration manifold.
%%
%The above theorem shows that the phase space of
%a mechanical problem has a natural symplectic
%manifold structure.
\end{rem*}

\begin{prob*}
  Show that the Legendre transform does not depend on the coordinate system:
  it takes a fucntion $:TV \to \mathbb R$ on the tangent bundle
  to a function $H: T^*V \to \mathbb R$ on the cotangent bundle.


\answer{
  Consider a coordinate transform $\mathbf q = \mathbf q(\mathbf Q)$,
  $$
  \begin{aligned}
  H
  &= \sum_i \dot q_i\frac{ \partial L } { \partial \dot q_i } - L
  = \sum_{ijk}
    \dot Q_j \frac{\partial q_i}{\partial Q_j}
    \frac{ \partial Q_k } { \partial q_i }
    \frac{ \partial L } { \partial Q_k } - L \\
  &= \sum_{jk}
    \dot Q_j \delta_{jk}
    \frac{ \partial L } { \partial Q_k } - L
  = \sum_j \dot Q_j \frac{ \partial L } { \partial Q_j } - L.
  \end{aligned}
  $$
  Thus the hamiltonian function is the same in the two coordinates.
}
\end{prob*}

% subsection C
\subsection{Hamiltonian vector fields}



A Riemann structure on a manifold establishes an isomorphism between
the spaces of tangent vectors and 1-forms.
%
A symplectic structure establishes a similar isomorphism.


\begin{defn*}
%
To each vector $\pmb \xi$
tangent to a symplectic manifold $(M^{2n}, \omega^2)$
at point $\mathbf x$, we associate a 1-form $\omega^1_{\pmb \xi}$
on $TM_{\mathbf x}$ by the formula
$$
\omega^1_{\pmb \xi}(\pmb \eta) = \omega^2(\pmb \eta, \pmb \xi),
\quad \forall \pmb \eta \in TM_{\mathbf x}.
$$
\end{defn*}

\begin{prob*}
Show that the correspondence $\pmb \xi \to \omega^1_{\mathbf \xi}$
is an isomorphism between the $2n$-dimensional vector spaces of vectors
and of 1-forms.
\end{prob*}

\begin{ex*}
  In $\mathbb{R}^{2n}=\{(\mathbf p, \mathbf q)\}$
  we will identify vectors and 1-forms by using the euclidean structure
  $(\mathbf x, \mathbf x) = \mathbf p^2 + \mathbf q^2$.
  Then the correspondences $\pmb\xi \to \omega^1_{\pmb\xi}$
  determines a transformation
  $\mathbb{R}^{2n} \to \mathbb{R}^{2n}$.
\end{ex*}

\begin{prob*}
  Calculate the matrix of this transformation in the basis
  $\mathbf p,\mathbf q$.

\answer{
For $n = 1$,
$\omega^2 = \pmb \eta \wedge \pmb \xi = \eta_1 \xi_2 - \eta_2 \xi_1$.
Then
$\omega^1_{\pmb \xi}(\pmb \eta) = (\pmb \eta, \mathbf J^{-1} \pmb \xi)$,
where $\mathbf J^{-1}$ means a rotation of $-\pi/2$, where
$$
\mathbf J =
\left(
  \begin{array}{cc}
    0  & -1 \\
    1  & 0
  \end{array}
\right)
\qquad
\mathbf J^{-1} =
\left(
  \begin{array}{cc}
    0  & 1 \\
    -1 & 0
  \end{array}
\right),
$$
with the indices of $p$ and $q$ being $1$ and $2$, respectively
(the convention of this book).

For higher dimensions, we just replace $1$ by the $n\times n$
identity matrix $E$,
$$
\mathbf J =
\left(
  \begin{array}{cc}
    0  & -E \\
    E  & 0
  \end{array}
\right)
\qquad
\mathbf J^{-1} =
\left(
  \begin{array}{cc}
    0  & E \\
    -E & 0
  \end{array}
\right).
$$
}

\note{
  \label{note:J_R2n}
Generally, we have
$$
\omega^1_{\pmb \xi}(\pmb \eta) = (\pmb \eta, \mathbf I^{-1} \pmb \xi)
=\eta' \mathbf J^{-1} \pmb\xi.
$$
with the prime``$'$'' denoting the transpose.

However, later in this book, the author will frequently use the result
$$
\omega^2(\pmb\eta,\pmb\xi) = (I\pmb\eta, \pmb\xi) = \pmb\eta'\mathbf J' \pmb\xi,
$$
for this case. This is not generally true.
It requires the isomorphism $I$ to be equivalent to a matrix multiplication
of the symplectic matrix $\mathbf J$, and $\mathbf J' = \mathbf J^{-1}$.

In general,
$\omega^1_{\pmb \xi}$ is represented by the vector $I^{-1} \pmb \xi$,
and a 1-form $\omega_1$ is represented by the vector $I\, \omega_1$.
}
\end{prob*}
%






We will denote by $I$ the isomorphism
$I: T^*M_{\mathbf x} \to TM_{\mathbf x}$
(from 1-forms to tangent vectors,
$\omega^1_{\pmb \xi} \to \pmb \xi$).
%
Now let $H$ be a function on a symplectic manifold $M^{2n}$.
%
Then $dH$ is a differential 1-form on $M$ and
for every point there is a tangent vector to $M$ associated to it.
%
In this way, we obtain a vector field $IdH$ on $M$.


\begin{defn*}
%
The vector field $IdH$ is called \emph{hamiltonian vector field}.
%
$H$ is called the \emph{hamiltonian function}.
\end{defn*}

\begin{ex*}
  If $M^{2n} = R^{2n} = {(\mathbf p, \mathbf q)}$,
  then we obtain the phase velocity field
  of Hamilton's canonical equation:
  $$
  \dot{\mathbf x} = I\,dH(\mathbf x)
  \iff
  \dot{\mathbf p} = - \frac{\partial H }{ \partial \mathbf q}
  \mathrm{\quad and \quad}
  \dot{\mathbf q} = \frac{\partial H}{\partial \mathbf p}.
  $$
\note{In the above example,
the 1-form is represented by the vector
$\nabla H = \left(\frac{\partial H}{\partial \mathbf p},
\frac{\partial H}{\partial q}\right)^T$
to invert this vector to corresponding tangent vector we multiple it by $\mathbf J$
%
\[
\arraycolsep=3.0pt\def\arraystretch{1.5}
\mathbf J \cdot \nabla H
=
\left(
  \begin{array}{ccc}
    0 & -1 \\
    1 & 0
  \end{array}
\right)
\left(
  \begin{array}{ccc}
    \frac{ \partial H }{ \partial \mathbf p } \\
    \frac{ \partial H }{ \partial \mathbf q }
  \end{array}
\right)
=
\left(
  \begin{array}{ccc}
    -\frac{ \partial H }{ \partial \mathbf q } \\
    \frac{ \partial H }{ \partial \mathbf p }
  \end{array}
\right)
=
\left(
  \begin{array}{ccc}
    \dot{\mathbf p} \\
    \dot{\mathbf q}
  \end{array}
\right).
\]}
\end{ex*}




\summary{
  \begin{enumerate}
    \item
      A $2n$-dimensional differentiable manifold, $M^{2n}$,
      along with a \emph{closed nondegenerate} 2-form $\omega^2$,
      is called a \emph{symplectic manifold}.
      The 2-form is called the \emph{symplectic structure}.
      Usually, the manifold has $n$ momentum components
      and $n$ coordinate components,
      and the 2-form is $\omega^2 = \sum_{i = 1}^n dp_i \wedge dq_i$.

    \item
      We can construct a $2n$-dimensional symplectic manifold
      from an $n$-dimensional differentiable manifold $V$.
      %
      At each point $\mathbf x \in V$, the 1-forms, written as
      $\omega^1 = \sum_{i=1}^n p_i dq_i$ in local coordinates,
      span an $n$-dimensional vector space for the coefficients
      $(p_1, \dots, p_n)$.
      This vector space is the \emph{cotangent space} $T^*V_\mathbf{x}$.
      %
      By supplementing each point $\mathbf x$
      by the cotangent space $T^V_\mathbf{x}$,
      we get a $2n$-dimensional joint space of
      $\mathbf x$ (with local coordinates $q_1, \dots, q_n$,
      and 1-forms $p_1, \dots, p_n$),
      called the \emph{cotangent bundle} $T^*V$.
      %
      Then we get a symplectic manifold $(T^*V, \omega^2)$,
      with $\omega^2 = \sum_i dp_i \wedge dq_i = d\left(\sum_i p_i dq_i \right)$.

    \item
      In the symplectic space,
      there is an isomorphism $I$ between 1-forms $\omega^1$
      and tangent vector, $\pmb\xi = I\omega^1$
      through the 2-form of the symplectic structure
      $$
      \omega^1_{\pmb\xi}(\pmb\eta)
      =
      \omega^2(\pmb\xi, \pmb\eta).
      $$
      In local coordinates of the euclidean space,
      $I$ is equivalent to multiplying symplectic matrix
      $$
      \mathbf J =
      \left(
        \begin{array}{ccc}
          0 & -E \\
          E & 0
        \end{array}
      \right)
      $$
      to a vector corresponding to the 1-form,
      e.g., $\nabla H = (\partial H/\partial \mathbf p, \partial H/\partial \mathbf q)$.

  \end{enumerate}
}





%section 38
\section{Hamiltonian phase flows and their integral invariants}

Liouville's theorem asserts that the phase flow
preserve the symplectic structure.
%
Poincar\'e found a whole series of differential forms
which are preserved by the hamiltonian flow.

%\subsection 38A
\subsection{Hamiltonian phase flows preserve the symplectic structure}

Let $(M^{2n}, \omega^2)$ be a symplectic manifold and
$H: M^{2n} \to \mathbb{R}$ a function.
Assume that the vector field $IdH$
corresponds to $H$ gives a 1-parameter group
of diffeomorphism: $g^t: M^{2n} \to M^{2n}$:
$$
\left.\frac{d}{dt}\right|_{t = 0} g^t\mathbf x
= I dH(\mathbf x).
$$
This group $g^t$ is the hamiltonian phase flow with
hamiltonian function $H$.

\note{
A \emph{diffeomorphism} is an isomorphism of smooth manifolds.
It is a smooth invertible function that maps one differentiable manifold
to another.

Not all differentiable maps are diffeomorphism, because of the one-to-one requirement.
For example, $(x, y) \to (y^2 \sin x, y^2 \cos x)$ is not invertible.
}

\begin{thm}
A hamiltonian phase flow preserves the symplectic structure:
$$
(g^t)^* \omega^2 = \omega^2.
$$
\end{thm}

\note{The difference between $g^t$ and $(g^t)^*$:
  $g^t$ applies to a point $\mathbf x$ or a tangent vector on the manifold $M$,
  $(g^t)^*$ applies to a differential form $\omega$.
  The definition of
  $$
  \left[ (g^t)^*\omega^2_{\mathbf x} \right](\pmb\xi, \pmb\eta)
  \equiv
  \omega^2_{g^t \mathbf x}(g^t\pmb\xi, g^t\pmb\eta).
  $$
  Here $\omega^2_{\mathbf x}$ means the 2-form evaluated at $\mathbf x$.
  See details in Sec. 33C.
  Generally, a 2-form depends on not only the tangent vectors,
    $\pmb\xi$ and $\pmb\eta$,
    but also the point $\mathbf x$ on the manifold.
  But for $\omega^2 = d\mathbf p \wedge \mathbf q$,
    this dependence is missing.
  In this book, the subscript is often omitted.
  We shall sometimes add it back in the notes for clarity.
}


In the case $n = 1$, $M^{2n} = \mathbb{R}^2$, this theorem says
that the phase flow $g^t$ preserves area (Liouville's theorem).

For the proof of this theorem, it is useful to introduce
the following notation.

Let $M$ be an arbitrary manifold,
$c$ a $k$-chain on $M$ and $g^t: M \to M$
a one-parameter family of differentiable mappings.
We will construct a $(k+1)$-chain $Jc$ on $M$,
which we will call the
\emph{track of the chain $c$ under the homotopy
$g^t$, $0 \le t \le \tau$}.
\note{Roughly, ``homotopy'' means time evolution.}


Let $(D, f, \mathrm{Or})$ be one of the cells in the chain $c$.
\note{$D$ is the domain, a convex polygon in $\mathbb{R}^k$,
  $f$ is a mapping from the euclidean space to the manifold $\mathbb{R}^k \to M$,
  $\mathrm{Or}$ is the orientation.
  See page 184, \S 35.D.}
%
To this cell will be associated a cell $(D', f', \mathrm{Or}')$
  in the chain $Jc$ where $D' = I\times D$ is the direct product
  of the interval of $0 \le t \le \tau$ and $D$;
  the mapping $f': D' \to M$ is obtained from
  $f: D \to M$ by the formula
  $f'(t, x) = g^t f(x)$;
  and the orientation $\mathrm{Or}'$ of the space $\mathbb{R}^{k+1}$
  containing $D'$ is given by the frame
  $\mathbf e_0, \mathbf e_1, \dots, \mathbf e_k$,
  where $\mathbf e_0$ is the unit vector of the $t$ axis,
  and $\mathbf e_1, \dots, \mathbf e_k$ is an oriented frame for $D$.


We could say that $Jc$ is the chain swept out by $c$
  under the homotopy $g^t$, $0 \le t \le \tau$.
  The boundary of the chain $Jc$ consists of ``end-walls''
  made up of the initial and final positions of $c$,
  and the ``side surfaces'' filled in by the boundary of $c$.
\note{Below, we want to prove that the integrals on the side surfaces
  vanishes, so is the integral on the volume enclosed by the tube.
  Then the integrals at the two end walls, which are opposite
  in the signs must add to zero.}

\setcounter{figure}{166}
\begin{figure}
\centering
  \begin{tikzpicture}
    % end-wall 1
    \draw [thick] plot [smooth cycle, tension=1]
      coordinates{(0, 0) (0.5, 1) (0, 2) (-0.5, 1)};
    % bottom of side surface
    \draw [thick] plot [smooth, tension=1]
      coordinates{(0, 0) (2.5, -0.2) (5, 0)};
    % top of the side surface
    \draw [thick] plot [smooth, tension=1]
      coordinates{(0, 2) (2.5,  1.8) (5, 2)};
    % end-wall 2
    \draw [thick, ->] plot [smooth, tension=1.5]
      coordinates{(5, 0) (5.3, 0.4) (5.4, 1.2)};
    \draw [thick] plot [smooth, tension=1.2]
    coordinates{(5.4, 1.2) (5.2, 1.8) (5, 2)};

    % intermediate rings
    \draw [] plot [smooth, tension=1]
      coordinates{(0.8, -0.1) (1.0, 1.0) (0.8, 1.9)};
    \draw [] plot [smooth, tension=1]
      coordinates{(1.6, -0.15) (1.8, 0.9) (1.6, 1.82)};
    \draw [] plot [smooth, tension=1]
      coordinates{(2.4, -0.18) (2.6, 0.9) (2.4, 1.82)};
    \draw [] plot [smooth, tension=1]
      coordinates{(3.3, -0.18) (3.5, 0.9) (3.3, 1.82)};
    \draw [] plot [smooth, tension=1]
      coordinates{(4.3, -0.1) (4.5, 0.9) (4.3, 1.92)};

    % dc
    \draw [->, thick] plot [smooth, tension=1]
      coordinates{(0.1, 0.2) (0.3, 0.6) (0.3, 1.2)};
    \node[](dc) at (0, -0.3){$\partial c$};

    % c
    \node[](c) at (0, 1.0){$c$};

    % J dc
    \draw [->, thick] plot [smooth, tension=0.5]
      coordinates{(2, 0.2) (3.5, 0.3) (3.6, 1.2)};
    \node[](Jc) at (3, 0.8){$J\partial c$};

    % g c
    \node[](gc) at (5.9, 1.0){$g^\tau c$};

    % k = 2
    \node[](keq2) at (2.7, -0.7){$k = 2$};
  \end{tikzpicture}
%
  \begin{tikzpicture}
    % c
    \draw [thick, ->] plot [smooth, tension=1]
      coordinates{(0, 0) (1, -0.1) (2, 0)};
    \node[](c) at (1, -0.3){$c$};
    % g c
    \draw [thick, ->] plot [smooth, tension=1]
      coordinates{(0, 2) (1., 1.9) (2, 2)};
    \node[](gc) at (1, 2.1){$g^\tau c$};
    % J c, left
    \draw [thick, ->] plot [smooth, tension=1]
      coordinates{(0, 1.9) (0.1, 1) (0, 0.1)};
    \node[](Jcleft) at (-0.5, 1){$J\partial c$};
    % J c, right
    \draw [thick, ->] plot [smooth, tension=1]
      coordinates{(2, 0.1) (2.1, 1) (2, 1.9)};
    \node[](Jcright) at (2.5, 1){$J\partial c$};

    % the circle
    \draw [thick, ->] plot [smooth, tension=1.0]
      coordinates{(0.5, 1.5) (1.5, 1.5) (1.5, 0.3) (0.5, 0.3)};
    \node[](Jc) at (1, 1){$Jc$};
    % k = 1
    \node[](gc) at (1.0, -0.8){$k = 1$};
  \end{tikzpicture}
  \caption{Track of a cycle under homotopy. \\
    %
    \note{ On the sign of the terms in \eqref{eq:c_homotopy}.\\
      %
      For $k = 2$ (left panel),
      $c$ represents an oriented area,
      which is positive for $-\mathbf x = \mathbf z \times \mathbf y$ direction;
      so the boundary $\partial c$ is positive
      for a counterclockwise rotation around the axis $-\mathbf x$.
      %
      The positive direction of $J$ represents a vector along $+\mathbf x$.
      %
      Thus for a correctly oriented volume element $Jc$,
      its sign should be negative, as
      $(\mathbf x, \mathbf z, \mathbf y) = \mathbf x \cdot (\mathbf z \times \mathbf y) < 0$.
      %
      $\partial (Jc)$, pointing to a direction of increasing $Jc$,
      or equivalently decreasing the absolute volume,
      is positive along the direction into the volume.
      %
      $J \partial c$ representing an oriented area element,
      is positive for the counterclockwise direction
      on the face facing the reader, as indicated by the arrow in the figure.
      %
      This means $J \partial c$ points out of the side surfaces,
      opposite to the direction of $\partial (Jc)$.
      %
      Since the positive direction of $c$ ($-\mathbf x$) is pointing out of the volume,
      it is opposite to the sign of $\partial (Jc)$.
      %
      Since the positive direction of $g^\tau c$ ($-\mathbf x$) is pointing into the volume,
      it shares the same sign as $\partial (Jc)$.
      %
      \\
      %
      For $k = 1$ (right panel),
      $c$ is an oriented line element
      which is positive along the $+\mathbf x$ direction.
      %
      The boundary $\partial c$ is the difference between the two points,
      positive for the final (larger $x$) point,
      and negative for the initial (smaller $x$) point.
      %
      The direction of $J$ is along the $+\mathbf y$ axis.
      %
      Thus, the positive direction of $Jc$ should be along
      $\mathbf y \times \mathbf x$
      ($c$ for $+\mathbf x$),
      a direction pointing into the paper.
      %
      It follows that the direction of $\partial(Jc)$ should be clockwise,
      according to the right-hand rule.
      %
      In this case, $J\partial c$ is $J$ multiplied by the sign of $\partial c$
      Thus, $J \partial c$ is positive for the right edge,
      and negative for the left edge (this is why $J\partial c$
      goes downwards there).
      %
      Clearly, $J\partial c$ and $\partial (Jc)$ run in the opposite directions;
      %
      $c$ and $\partial (Jc)$ also run in the opposite directions;
      but
      $g^\tau c$ and $\partial (Jc)$ run int the same direction.
    }
  }
\end{figure}

It is easy to verify that under the choice of orientation made above
\begin{equation}
\partial (J c_k) = g^\tau c_k - c_k - J \partial c_k.
\label{eq:c_homotopy}
\end{equation}

\begin{lem*}
  Let $\gamma$ be a 1-chain in the symplectic manifold $(M^{2n}, \omega^2)$.
  Let $g^t$ be phase flow on $M$ with hamiltonian function $H$.
  Then
  $$
  \frac{d}{d\tau} \int_{J\gamma} \omega^2
  =
  \int_{g^\tau\gamma} dH.
  $$
\end{lem*}

\begin{proof}
  It is sufficient to consider a chain $\gamma$ with one cell
  $f: [0,1] \to M$.
  \note{$\gamma$ is a curve, which will be $\partial c$.}
  We introduce the notation
  $$
    f'(s, t) = g^t f(s),
    \qquad
    \pmb\xi = \frac{ \partial f' } { \partial s },
    \mathrm{\quad and \quad}
    \pmb\eta = \frac{ \partial f' } { \partial t }
    = TM_{f'(s, t)}.
  $$
  By the definition of the integral,
  $$
  \int_{J\gamma} \omega^2
  =
  \int_0^1 \int_0^\tau \omega^2(\pmb\xi, \pmb\eta) \, dt \, ds.
  $$
  \note{There might be a missing minus sign:
    $\int_{J\gamma} \omega^2$ should really mean
    $\int_0^\tau \int_0^1 \omega^2(\pmb\eta, \pmb\xi) \, dt \, ds$,
    for, by literal translation, $J$ goes before $\gamma$,
    hence $\pmb\eta$ before $\pmb\xi$.
    This doesn't cause trouble, because we only consider
    closed chains (see the next Corollary).
    For closed chains, the integral vanishes, and
    the sign doesn't matter.
  }
  But by the definition of the phase flow,
  $\pmb \eta$ is a vector (at the point $f'(s, t)$)
  of the hamiltonian flow with hamiltonian function $H$.
  \note{$\pmb\eta = I dH$.}
  By defintion of a hamiltonian field
  $\omega^2(\pmb\xi, \pmb\eta) = dH(\pmb\xi)$.
  \begin{figure*}
    \centering
    \begin{tikzpicture}
      % q axis
      \draw [very thick, ->] (0,0) -- (0,3.5);
      \node[](q) at (-0.3, 3.2){$\mathbf q$};

      % p axis
      \draw [very thick, ->] (0,0) -- (5,0);
      \node[](p) at (5.5, 0){$\mathbf p$};

      % the parallelogram
      \draw [dashed, fill=gray!30!white] (0, 0) -- (1.2, 2) -- (3.6, 3.5) -- (2.4, 1.5) -- cycle;

      % dH
      \draw [thick, ->, blue] (0, 0) -- (2.4, -1.2);
      \node[](dH) at (2.4, -0.7){$\nabla H$};

      % eta = IdH
      \draw [thick, ->, blue] (0, 0) -- (1.2, 2);
      \node[](IdH) at (0.8, 2.4){$\pmb\eta = I dH$};

      % xi
      \draw [thick, ->, red] (0, 0) -- (2.4, 1.5);
      \node[](eta) at (2.5, 1.2){$\pmb\xi$};
    \end{tikzpicture}
    \caption*{Illustration of $\omega^2(\pmb\xi, \pmb\eta) = (\pmb\xi, \nabla H)$.
    The area spanned by $\pmb\xi$ and $\pmb\eta = IdH$ is equal
    to the projection of $\nabla H$ on $\pmb \xi$.}
  \end{figure*}
    \note{$\omega^2(\pmb\xi, \pmb\eta) = \omega^1_{\pmb\eta}(\pmb\xi)
      = \omega^1_{IdH}(\pmb\xi) = (\pmb\xi, I^{-1} IdH)
    = dH(\pmb\xi)$.}
  Thus,
  $$
  \int_{J\gamma}\omega^2 = \int_0^\tau
  \left(
    \int_{g^t\tau} dH
  \right) dt.
  $$
  \note{
    $\int_0^1 \omega^2(\pmb\xi, \pmb\eta) \, ds
    = \int_0^1 dH(\pmb\xi) \, ds = \int_0^1 dH(\pmb\xi \, ds).$
    But $\pmb\xi = \frac{ \partial f' } { \partial s }
    = g^t \frac{ d f }{ d s } \to
    \pmb\xi\, ds = g^t \, df = d(g^t f)$,
    So
    $\int_0^1 dH(\pmb\xi ds) = \int dH(d g^t f) = \int_{g^t\gamma} dH.$
  }
\end{proof}


\begin{cor*}
  If the chain $\gamma$ is closed ($\partial \gamma = 0$)
  then $\int_{J\gamma} \omega^2 = 0$.
\end{cor*}

\begin{proof}
  $\int_\gamma dH = \int_{\partial \gamma} H = 0.$

  \note{
    $-\int_{J\gamma} \omega^2 = \int_0^\tau \int_{g^t\gamma} dH \, dt
    = \int_0^\tau dt \int_{\partial(g^t \gamma)} H
    = \int_0^\tau dt \int_{g^t\partial\gamma} H = 0.$

    Alternatively, if $\gamma$ is a boundary $\partial c$,
    we have, by writing $\omega^1 = dH$,
    $-\int_{J\partial c} \omega^2(\xi, I\omega^1)
    = \int_0^\tau \int_{g^t\partial c} \omega^1(\xi) \, dt
    = \int_0^\tau dt \int_{\partial(g^t c)} d\omega^1(\xi) = 0.$
    The advantage of this proof is that it applies
    to a flow $I\omega^1$ induced by any closed 1-form $\omega^1$,
    not just total differentials.
  }
\end{proof}

\begin{proof}[Proof of the theorem.]
  We consider any 2-chain $c$. We have
  $$
  0 \stackrel{1}{=} \int_{Jc} d\omega^2
  \stackrel{2}{=} \int_{\partial Jc} \omega^2
  \stackrel{3}{=}
  \left(
    \int_{g^\tau c}
    -\int_{c}
    -\int_{J\partial c}
  \right)
  \omega^2
  \stackrel{4}{=}
  \left(
    \int_{g^\tau c}
    -\int_{c}
  \right)
  \omega^2.
  $$
  (1 since $\omega^2$ is closed, 2 by Stokes formula,
  3 by formula \eqref{eq:c_homotopy},
  4 by the corollary above with $\gamma = \partial c$).
  Thus the integrals of the form $\omega^2$
  on any chain $c$ and on its image $g^\tau c$ are the same.
\end{proof}


% subsection B
\subsection{Integral invariants}

Let $g:M\to M$ be a differentiable map.

\begin{defn*}
  A differential $k$-form $\omega$ is called an \emph{integral invariant}
  of the map $g$ if the integrals of $\omega$ on
  any $k$-chain $c$ and on its image under $g$ are the same:
  \begin{equation}
  \int_{gc}\omega = \int_c \omega.
  \label{eq:integral_invariant}
  \end{equation}
\end{defn*}

\note{The precise meaning of \eqref{eq:integral_invariant} is the following.
  Let $f$ be a mapping from $\mathbb R$ to $M$,
  For a $k$-chain $c$ with one cell:
  $f:[0, 1]^k \to M$,
  we have $f(\mathbf s) \in M$ for $\mathbf s \in [0,1]^k$.
  %
  The $k$ tangent vectors are defined as
  $\pmb\xi_i = \partial f/\partial s_i$
  for $i = 1, \dots k$.
  %
  Then, for a $k$-form $\omega = \omega^k$,
  the right-hand side reads
  $$
  \int_{c} \omega
  =
  \int_0^1 \dots \int_0^1
    \omega^k_{f \mathbf s}(\pmb\xi_1,\dots, \pmb\xi_k)
    \, ds_1 \cdots ds_k
  =
  \int_0^1 \dots \int_0^1
    \omega^k_{\mathbf x}(\pmb\xi_1,\dots, \pmb\xi_k)
    \, ds_1 \cdots ds_k.
  $$
  The left-hand side reads
  $$
  \int_{gc} \omega
  =
  \int_0^1 \dots \int_0^1
    \omega^k_{(g \circ f)\, \mathbf s}(g \pmb\xi_1,\dots, g \pmb\xi_k)
    \, ds_1 \cdots ds_k
  =
  \int_0^1 \dots \int_0^1
    \omega^k_{g \mathbf x}(g \pmb\xi_1,\dots, g \pmb\xi_k)
    \, ds_1 \cdots ds_k.
  $$
  The point to note here is that \eqref{eq:integral_invariant}
  implicitly assumes the transformation $g$ on the coordinates $\mathbf x$
  and the tangent vectors $\pmb\xi_1, \dots, \pmb\xi_k$,
  on the left-hand side.
}

\begin{ex*}
  If $M = \mathbb{R}^2$ and $\omega^2 = dp \wedge dq$ is the area element,
  then $\omega^2$ is an integral invariant of any map $g$
  with jacobian $1$.
\end{ex*}

\begin{prob*}
  Show that a form $\omega^k$ is an integral invariant
  of a mapping if and only if $g^*\omega^k = \omega^k$.

  \answer{
    It is sufficient to consider a chain $c$ with one cell
    $f: [0, 1]^k \to M$.
    Then using the above notation,
    for $\mathbf x = f\mathbf s \in M$, and
    $\xi_i = \partial f/\partial s_i$,
    we have
    $$
    \begin{aligned}
      \int_{gc} \omega^k
      &=
      \int_0^1 \dots \int_0^1 \omega^k_{g\mathbf x}
      (g\pmb\xi_1, \dots, g\pmb\xi_k)
          \,ds_1 \dots ds_k
      \\
      &=
      \int_0^1 \dots \int_0^1 \left( g^*\omega^k_{\mathbf x} \right)
      (\pmb\xi_1, \dots, \pmb\xi_k)
          \,ds_1 \dots ds_k
      =
      \int_c g^*\omega^k.
    \end{aligned}
    $$
    Note that $\omega^k$ on the left is integrated over $gc$,
    $g^*\omega^k$ on the right over $c$.
    Conceptually, $gc$ and $c$ can be thought as chains
    of two different manifolds $gM$ and $M$.

    If $g^*\omega^k = \omega^k$, then
    $\int_{gc} \omega^k = \int_c \omega^k$,
    and $\omega^k$ is an integral invariant of $g$.

    Conversely, if $\omega^k$ is an integral invariant,
    then
    $\int_{c} \omega^k = \int_{gc} \omega^k = \int_c g^*\omega^k$,
    for any $k$-chain $c$, so
    $g^*\omega^k = \omega^k$.

    While this result follows straightforwardly from definition,
    it expresses two different ways of thinking
    of integral invariants.
    First,
    $\int_{gc}\omega = \int_c \omega$
    means that we get the same number from integrating
    the chains before and after the mapping $g$.
    %
    Alternatively,
    $g^* \omega = \omega$ means that if we stick
    to the chain before the mapping but
    inversely transform the form $\omega$ by $g^*$,
    we get the same result after integration.
  }
\end{prob*}

\begin{prob*}
  Show that if the forms $\omega^k$ and $\omega^l$
  are integral invariants of the map,
  then the form $\omega^k \wedge \omega^l$
  is also an integral invariant of $g$.

  \answer{
    It follows from Problem \ref{prob:fstar_exprod} in Sec. 33.
    $$
    \begin{aligned}
    \int_{gc} (\omega^k \wedge \omega^l)
    &=
    \int_{c} (\omega^k \wedge \omega^l)(g\pmb\xi_1, \dots, g\pmb\xi_{k+l})
    =
    \int_{c} g^*(\omega^k \wedge \omega^l)(\pmb\xi_1, \dots, \pmb\xi_{k+l})
    \\
    &=\int_{c} (g^*\omega^k \wedge g^*\omega^l)(\pmb\xi_1, \dots, \pmb\xi_{k+l})
    =\int_{c} (\omega^k \wedge \omega^l)(\pmb\xi_1, \dots, \pmb\xi_{k+l}).
    \end{aligned}
    $$
  }
\end{prob*}

The theorem in subsection A can be reformulated as follows.

\begin{thm*}
  The form $\omega^2$ giving the symplectic structure
  is an integral invariant of a hamiltonian phase flow.
\end{thm*}

We now consider the exterior powers of $\omega^2$,
$$
(\omega^2)^2 = \omega^2 \wedge \omega^2,
\quad
(\omega^2)^3 = \omega^2 \wedge \omega^2 \wedge \omega^2,
\dots
$$

\begin{cor*}
  Each of the forms $(\omega^2)^2$, $(\omega^2)^3$, $(\omega^2)^4$, \dots
  is an integral invariant of a hamiltonian phase flow.
\end{cor*}

\begin{prob*}
Suppose that the dimension of the symplectic manifold
$(M^{2n}, \omega^2)$ is $2n$,
show that $(\omega^2)^k = 0$ for $k > n$,
and that $(\omega^2)^n$ is a nondegenerate $2n$-form on $M^{2n}$.
\end{prob*}

We define a volume element on $M^{2n}$ using $(\omega^2)^n$.
Then, a hamiltonian phase flow preserves volume,
and we obtain Liouville's theorem from the corollary above.

\begin{ex*}
  Consider the symplectic coordinate space
  $M^{2n} = \mathbb R^{2n} = \{(\mathbf p, \mathbf q)\}$,
  $\omega^2 = d\mathbf p \wedge d\mathbf q = \sum dp_i \wedge dq_i$.
  In this case the form $(\omega^2)^k$ is proportional to the form
  $$
  \omega^{2k} = \sum_{i_1 < \dots < i_k}
  dp_{i_1} \wedge \dots \wedge dp_{i_k} \wedge
  dq_{i_1} \wedge \dots \wedge dq_{i_k}.
  $$
  The integral of $\omega^{2k}$ is equal to the sum of
  the oriented volumes of projections on to the coordinate planes
  $(p_{i_1}, \dots, p_{i_k}, q_{i_1}, \dots, q_{i_k})$.
\end{ex*}

The map
$g: \mathbb R^{2n} \to \mathbb R^{2n}$
is called \emph{canonical} if it has $\omega^2$ as an integral invariant.
A canonical map is generally called a \emph{canonical transformation}.
Each of the forms $\omega^4, \omega^6, \dots, \omega^{2n}$
is an integral invariant of every canonical transformation.
Therefore, \emph{under a canonical transformation,
  the sum of the oriented areas of projections onto the coordinate planes
  $(p_{i_1}, \dots, p_{i_k}, q_{i_1}, \dots, q_{i_k})$,
  $1 \le k \le n$, is preserved}.
In particular, \emph{canonical transformations preserve volume}.

The hamiltonian phase flow given by the equations
$\dot{\mathbf p} = -\partial H/\partial \mathbf q$,
$\dot{\mathbf q} = \partial H/\partial \mathbf p$
consists of canonical transformations $g^t$.

The integral invariants considered above are also called
\emph{absolute integral invariants}.

\begin{defn*}
  A differential $k$-form is called a
  \emph{relative integral invariant} of the map
  $g: M \to M$ if
  $\int_{gc} \omega = \int_c \omega$
  for every \emph{closed} $k$-chain $c$.
\end{defn*}

\begin{thm*}
  Let $\omega$ be a relative integral invariant of a map $g$.
  Then $d\omega$ is an absolute integral invariant of $g$.
\end{thm*}

\begin{proof}
  Let $c$ be a $k+1$-chain. Then
  $$
  \int_c d\omega \stackrel{1}{=}
  \int_{\partial c} \omega
  \stackrel{2}{=}
  \int_{g\partial c} \omega
  \stackrel{3}{=}
  \int_{\partial gc} \omega
  \stackrel{4}{=}
  \int_{gc} d\omega.
  $$
  (1 and 4 are by Stokes' formula,
  2 by the definition of relative invariant,
  and 3 by the definition of boundary).
\end{proof}


\begin{ex*}
  A canonical map $g:\mathbb R^{2n} \to \mathbb R^{2n}$
  has the 1-form
  $$
  \omega^1 = \mathbf p \, d\mathbf q = \sum_{i = 1}^n p_i \, dq_i
  \mbox{ as a relative integral invariant.}
  $$
  \note{This is more like a converse of the above theorem,
  not a deduction.}
  In fact, every closed chain $c$ on $\mathbb R^{2n}$
  is the boundary of some chain $\sigma$
  \note{Recall the cone construction in Sec. 36},
  and we find
  $$
  \int_{gc} \omega^1
  \stackrel{1}{=}
  \int_{g\partial \sigma} \omega^1
  \stackrel{2}{=}
  \int_{\partial g\sigma} \omega^1
  \stackrel{3}{=}
  \int_{g\sigma} d\omega^1
  \stackrel{4}{=}
  \int_{\sigma} d\omega^1
  \stackrel{5}{=}
  \int_{\partial \sigma} \omega^1
  \stackrel{6}{=}
  \int_{c} \omega^1.
  $$
  (1 and 6 are by definition of $\sigma$,
  2 by definition of $\partial$,
  3 and 5 by Stokes' formula,
  and 4 since $g$ is canonical and
  $d\omega^1 = d(pdq) = dp \wedge dq = \omega^2$).
\end{ex*}


\begin{prob*}
  Let $d\omega^k$ be an absolute integral invariant of the map
  $g: M \to M$. Does it follow that $\omega^k$ is a
  relative integral invariant?
\end{prob*}

\begin{ans*}
  No, if there is a closed $k$-chain on $M$ which is not a boundary.
  \note{
  We still have
  $
  \int_{g\partial c} \omega^k =
  \int_{gc} d\omega^k =
  \int_c d\omega^k =
  \int_{\partial c} \omega^k.
  $
  The problem is that there are closed chains $\gamma$ that cannot be
  written as $\partial c$, like an equator of the torus, $T^2$,
  which will fail $\omega^k$.
  }
\end{ans*}


% subsection C
\subsection{The law of conservation of energy}

\begin{thm*}
  The function $H$ is a first integral of the hamiltonian phase flow
  with hamiltonian function $H$.
\end{thm*}

\begin{proof}
  The derivative of $H$ in the direction of a vector $\pmb\eta$
  is equal to the value of $dH$ on $\pmb\eta$.
  By definition of the hamiltonian field
  $\pmb\eta = IdH$ we find
  $$
  dH(\pmb\eta) = \omega^2(\pmb\eta, IdH)
  = \omega^2(\pmb\eta, \pmb\eta) = 0.
  $$
\end{proof}

\begin{prob*}
  Show that the 1-form $dH$ is an integral invariant
  of the phase flow with hamiltonian function $H$.

\answer{
  $$
  \left( \int_{g\gamma} - \int_{\gamma} \right) dH
  =
  \int_{\partial(Jc) } dH + \int_{J\partial c} dH
  =
  \int_{Jc} ddH + \int_0^1 dH(\pmb\eta) \, dt
  = 0 + 0 = 0.
  $$
}
\end{prob*}



\summary{
  \begin{enumerate}
    \item \emph{A hamiltonian phase flow preserves the symplectic structure.}
      $\int \omega^2_{g\mathbf x}(g^t\pmb\xi, g\pmb\eta)
      = \int \omega^2_{\mathbf x}(\pmb\xi, \pmb\eta)$,
      which means the integral of $\omega^2$ over any chain $c$
      gives the same value as the integral of $\omega^2$
      over the time evolved chain $g^t c$.

    \item The result is shown using the homotopy formula
      by constucting a tube of phase flow connecting the two chains
      $c$ and $g^tc$.

    \item Generally, if a form $\omega$ is invariant under a differentiable map $g$
      $\int_{gc} \omega = \int_c \omega$ is called an \emph{integral invariant} of $g$.

    \item If two forms $\omega^k$ and $\omega^l$ are integral invariants of $g$,
      so is their exterior product $\omega^k \wedge \omega^l$.

    \item So $\omega^2$ of the symplectic structure is an integral invariant
      of \emph{any} phase flow, so are the powers of
      $(\omega^2)^2, \dots, (\omega^2)^n$.

    \item A \emph{relative integral invariant} is a less restrict concept
      than the above \emph{absolute} integral invariant.
      It requires $\int_{gc} \omega = \int_c \omega$
      only for closed $c$-chains.

    \item If $\omega$ is a relative integral invariant,
      then $d\omega$ is an absolute integral invariant.
      However, the converse is not always true
      (although true for vector space):
      if $d\omega$ is an aboslute integral invariant,
      $\omega$ is not necessarily a relative integral invariant
      ($\omega$ is invariant for boundaries $\partial c$,
      but not all closed chains are not boundaries,
      e.g., when $M$ is a torus).

    \item The hamiltonian function $H$ is conserved
      along the phase flow $IdH$.
  \end{enumerate}
}



% section 39
\section{The Lie algebra of vector fields}


Every pair of vector fields on a manifold determines a new vector field,
called their Poisson bracket\footnote{Or Lie bracket.}.
%
The Poisson bracket operation makes the vector space of
infinitely differentiable vector fields
on a manifold into a Lie algebra.

% subsection 39A
\subsection{Lie algebras}

One example of a Lie algebra is a three-dimensional oriented euclidean
vector space equipped with the operation of vector multiplication.
%
The vector product is bilinear, skew symmetric, and satisfies the
\emph{Jacobi identity}
  $$
    [[A, B], C] + [[B, C], A] + [[C, A], B].
  $$

\note{The Jacobi identity for the vector product reads
$$
\mathbf{
  (A \times B) \times C
+ (B \times C) \times A
+ (C \times A) \times B
= 0}.
$$
To show this, we recall
$\mathbf{[(A \times B) \times C]}_k = \epsilon_{ijk}\epsilon_{imn} A_m B_n C_j
= (\delta_{jm}\delta_{kn} - \delta_{jn}\delta_{mk}) A_m B_n C_j
= C_j A_j B_k - B_j C_j A_k
= \mathbf{[(C\cdot A) \, B - (B\cdot C) A]}_k$;
similarly
$\mathbf{
  (B\times C)\times A
=(A\cdot B) \, C - (C \cdot A) \, B}$,
and
$\mathbf{(C\times A)\times B
=(B\cdot C) \, A - (A \cdot B) \, C}$.
The three sum to $0$.
Poisson bracket can be viewed as a generalization of
the idea of vector cross product in higher spaces.
}

\begin{defn*}
  A \emph{Lie algebra} is a vector space $L$,
  together with a bilinear skew-symmetric operation
  $L\times L \to L$ which satisfies the Jacobi identity.

  The operation is usually denoted by square brackets
  and called the commutator.
\end{defn*}

\begin{prob*}
  Show that the set of $n\times n$ matrices becomes a Lie algebra
  if we define the commutator by $[A, B] = AB - BA$.

  \answer{The bilinearity is easy. Let us verify the Jacobi identity.
    After expansion, each term on the left-hand side is a product of
    three matrices.  Let us collect all terms that end with $C$:
    $[[A, B], C]$ contributes $[A, B] C$;
    $[[B, C], A]$ contributes $-ABC$ through $-A[B,C]$,
    $[[C, A], B]$ contributes $BAC$ through $-B[C,A]$,
    and
    $$[A, B] C - ABC + BAC = 0.$$
    By the cyclic symmetry, the same holds for terms end with $A$ or $B$,
    so the Jacobi identity is satisfied.
  }
\end{prob*}


% subsection B
\subsection{Vector fields and differential operators}

Let $M$ be a smooth manifold and $\mathbf A$ a smooth vector field on $M$:
at every point $\mathbf x \in M$ we are given a tangent vector
$\mathbf{ A(x) } \in TM_{\mathbf x}$.
With every such vector field we associate the following two objects:
\begin{enumerate}
  \item
    \emph{The one-parameter group of diffeomorphisms} or \emph{flow}
    of $A^t: M \to M$ for which $\mathbf A$ is the velocity vector field
    (Figure 168):\footnote{
    By theorems of existence, uniqueness and differentiability
    in the theory of ordinary differential equations,
    the group $A^t$ is defined if the manifold is compact.
    In the general case, the maps $A^t$ are defined only in a neighborhood
    of $\mathbf x$ and only for small $t$; this is enough
    for the following constructions.
    \note{A subset is
      ``compactness'' if it is \emph{closed}
      (containing all its limit points)
      and \emph{bounded} (having all its points lie
      within some fixed distance of each other).
      Examples of compact manifolds include
      the circle and $n$-dimensional sphere and torus.
    }
    }
    $$
    \frac{d}{dt}\bigg|_{t = 0} A^t \mathbf x = \mathbf{ A(x) }.
    $$

    \begin{figure}
      \centering
      \begin{tikzpicture}
        % parallelogram
        \draw [] plot [smooth, tension=1]
        coordinates{(1, 0) (2, 0.4) (3, 0.5)};
        \draw [] plot [smooth, tension=1]
          coordinates{(3, 0.5) (2.6, 1.5) (2, 2.2)};
        \draw [] plot [smooth, tension=1]
          coordinates{(2, 2.2) (1, 1.9) (0, 1.2)};
        \draw [] plot [smooth, tension=1]
          coordinates{(0, 1.2) (0.5, 0.7) (1, 0)};

        % A
        \node [] at (-0.1, 0.8) {$\mathbf A$};

        % x
        \node [] at (0.9, 0.7) {$\mathbf x$};

        % A^t(x)
        \node [] at (2.2, 0.9) {$A^t(\mathbf x)$};

        % A(x)
        \node [] at (1.1, 1.5) {$\mathbf{ A(x)}$};
        % the curve A^t(x)
        \draw [thick] plot [smooth, tension=1]
          coordinates{(0.8, 0.9) (1.7, 1.3) (2.6, 1.2)};

        % the tangent vector
        \draw [ultra thick, ->] (0.9, 1.0) -- (2.0, 1.6);

        \draw [fill=white] (0.9, 1.0) circle (0.07);

      \end{tikzpicture}
      \label{fig:flow_vecfield}
      \caption{The group of diffeomorphism given by
      a vector field}
    \end{figure}

  \item
    The first-order differential operator $L_\mathbf{A}$.
    We refer here to the differentiation of functions
    in the direction of the field $\mathbf A$:
    for any function $\varphi: M \to \mathbb F$,
    the \emph{derivative in the direction of $\mathbb A$}
    is a new function $L_{\mathbf A} \varphi$,
    whose value at a point $\mathbf x$ is
    $$
    (L_{\mathbf A}\varphi) (\mathbf x)
    =
    \frac{d}{dt}\bigg|_{t = 0} \varphi(A^t\mathbf x).
    $$

\end{enumerate}

\begin{prob*}
  Show that the operator $L_\mathbf{A}$ is linear:
  $$
  L_\mathbf{A}(\lambda_1 \varphi_1 + \lambda_2 \varphi_2)
  =
  \lambda_1 L_\mathbf{A}\varphi_1
  +
  \lambda_2 L_\mathbf{A}\varphi_2
  \qquad
  (\lambda_1, \lambda_2 \in \mathbb{R}).
  $$
  Also, prove the Leibniz's formula
  $
  L_\mathbf{A}(\varphi_1\varphi_2)
  = \varphi_1 L_\mathbf{A} \varphi_2 + \varphi_2 L_\mathbf{A} \varphi_1.
  $

  \answer{
    For the linearity:
    $$
    \begin{aligned}
    L_\mathbf{A}(\lambda_1 \varphi_1 + \lambda_2 \varphi_2)
    &=
    \frac{d}{dt}\bigg|_{t = 0}
    \left[
    \lambda_1 \varphi_1(A^t\mathbf x)
    +
    \lambda_2 \varphi_2(A^t\mathbf x)
    \right]
    \\
    &=
    \lambda_1
    \frac{d}{dt}\bigg|_{t = 0}
    \varphi_1(A^t\mathbf x)
    +
    \lambda_2
    \frac{d}{dt}\bigg|_{t = 0}
    \varphi_2(A^t\mathbf x) \\
    &=
    \lambda_1
    (L_{\mathbf A}\varphi_1) (\mathbf x)
    +
    \lambda_2
    (L_{\mathbf A}\varphi_2) (\mathbf x).
    \end{aligned}
    $$

    For the Leibniz's formula:
    $$
    \begin{aligned}
    L_\mathbf{A}(\varphi_1 \varphi_2)
    &=
    \frac{d}{dt}\bigg|_{t = 0}
    \varphi_1(A^t\mathbf x)
    \varphi_2(A^t\mathbf x)
    \\
    &=
    \varphi_1(\mathbf x)
    \frac{d}{dt}\bigg|_{t = 0}
    \varphi_2(A^t\mathbf x)
    +
    \varphi_2(\mathbf x)
    \frac{d}{dt}\bigg|_{t = 0}
    \varphi_1(A^t\mathbf x) \\
    &=
    \varphi_1(\mathbf x)
    (L_{\mathbf A}\varphi_2) (\mathbf x)
    +
    \varphi_2(\mathbf x)
    (L_{\mathbf A}\varphi_1) (\mathbf x).
    \end{aligned}
    $$
  }
\end{prob*}

\begin{ex*}
  Let $(x_1, \dots, x_n$ be local coordinates on $M$.
  In this coordinate system the vector $\mathbf{ A(x) }$
  is given by its components
  $(A_1(\mathbf x), \dots, A_n(\mathbf x))$;
  the flow $A^t$ is given by the system of differential equations
  $$
  \dot x_1 = A_1(\mathbf x), \dots
  \dot x_n = A_n(\mathbf x)
  $$
  and, therefore, the derivative of
  $\varphi = \varphi(x_1, \dots, x_n)$
  in the direction $\mathbf A$ is
  $$
  L_\mathbf{A} \varphi = A_1 \frac{\partial \varphi}{\partial x_1}
  + \dots A_n \frac{ \partial \varphi }{ \partial x_n }.
  $$
  We could say that in the coordinates $(x_1, \dots, x_n)$
  the operator $L_\mathbf{A}$ has the form
  $$
  L_\mathbf{A} = A_1 \frac{\partial }{\partial x_1}
  + \dots + A_n \frac{ \partial }{ \partial x_n}.
  $$
  This is the general form of a first-order linear differential operator
  on coordinate space.
\end{ex*}

\begin{prob*}
  Show that the correspondences between vector fields $\mathbf A$,
  flows $A^t$, and differentiations $L_\mathbf{A}$ are one-to-one.

  \answer{
    The correspondence between the vector field $\mathbf A$
    and the differentiations $L_\mathbf{A}$ are apparent
    from the above example.
    For $\mathbf A$ and the flow, we first note that
    by definition the vector field $\mathbf{ A(x)}$ is determined by the flow.
    Conversely, we can trace the flow
    by following the vector field $\mathbf{ A(x) }$,
    That is,
    for a sufficiently small $\Delta t$,
    the flow approximately satisfies the recurrence relation
    $$
    A^t(\mathbf x) \approx
    A^{t-\Delta t}(\mathbf x + \Delta t \mathbf{A(x)})
    =
    A^{t-\Delta t} (1 + \Delta t \mathbf{A})\mathbf x.
    $$
    Or,
    $$
    A^t(\mathbf x)
    =
    \lim_{n\to \infty}
    \left(1 + \frac{t}{n} \mathbf{A}\right)^{n} \mathbf x.
    =
    \exp(t\mathbf{A}) \, \mathbf x.
    $$
    which means the flow is completely determined by the vector field.
  }
\end{prob*}

% subsection C
\subsection{Poisson bracket of vector fields}

Suppose that we are given two vector fields
$\mathbf A$ and $\mathbf B$ on a manifold $M$.
The corresponding flows $A^t$ and $B^s$
do not, in general commute:
$A^t B^s \ne B^s A^t$
(Figure 169).

    \begin{figure}
      \centering
      \begin{tikzpicture}
        % parallelogram
        \draw [thick] plot [smooth, tension=1]
          coordinates{(0, 0) (1.5, -0.2) (3, -0.6)};
          % A^t x
          \node [] at (2.9, -0.9) {$A^t \mathbf x$};

        \draw [thick] plot [smooth, tension=1]
          coordinates{(3, -0.6) (3.2, 0.4) (3.5, 1.0)};
          % B^s A^t x
          \node [] at (3.5,  1.3) {$B^s A^t \mathbf x$};

        \draw [thick] plot [smooth, tension=1]
          coordinates{(0.0, 0.0) (0.2, 1.4) (0.5, 2.0)};
          % B^s x
          \node [] at (0.2,  2.3) {$B^s \mathbf x$};

        \draw [thick] plot [smooth, tension=1]
          coordinates{(0.5, 2.0) (1.5, 2.0) (2.8, 1.8)};
          % A^t B^s x
          \node [] at (2.8,  2.1) {$A^t B^s \mathbf x$};

        \draw [fill=white] (3.0, -0.6) circle (0.07);
        \draw [fill=white] (3.5, 1.0) circle (0.07);
        \draw [fill=white] (0.5, 2.0) circle (0.07);
        \draw [fill=white] (2.8, 1.8) circle (0.07);

        % A
        \node [] at ( 1.3, 0.3) {$\mathbf A$};

        % B
        \node [] at (-0.2, 0.5) {$\mathbf B$};

        % x
        \node [] at (-0.2, -0.2) {$\mathbf x$};

        % the tangent vector
        \draw [ultra thick, ->] (0.0, 0.0) -- (1.8, 0.0);
        \draw [ultra thick, ->] (0.0, 0.0) -- (0.0, 1.0);

      \end{tikzpicture}
      \label{fig:noncommflows}
      \caption{Non-commutative flows}
    \end{figure}

\begin{prob*}
  Problem. Find an example.

  \solution{
    The fields $\mathbf A = \mathbf e_1$,
    $\mathbf B = x_1 \mathbf e_2$
    on the $(x_1, x_2)$ plane.

    \note{
      $$
      \begin{aligned}
        A^tB^s\mathbf x &= A^t (x_1, x_2 + x_1 s) = (x_1 + t, x_2 + x_1 s), \\
        B^sA^t\mathbf x &= B^s (x_1 + t, x_2) = (x_1 + t, x_2 + x_1 s + t s).
      \end{aligned}
      $$
    }
  }
\end{prob*}


To measure the degree of non-commutativity
of two flows $A^t$ and $B^s$ we consider the two points
$A^tB^s\mathbf x$ and $B^sA^t\mathbf x$.
%
In order to estimate the difference between these points,
we compare the value at them of some smooth function
$\varphi$ on the manifold $M$. The difference
$$
\Delta(t; s; \mathbf x)
=
\varphi(A^tB^s\mathbf x)
-
\varphi(B^sA^t\mathbf x)
$$
is clearly a differentiable function which is zero for $s = 0$
and for $t = 0$.
Therefore, the first term different from $0$ in the Taylor series
in $s$ and $t$ of $\Delta$ at $0$ contains $st$,
and the other terms of second order vanish.
%
We will calculate this principal bilinear term of $\Delta$ at $0$.

\note{
  At $t = 0$,
  $\Delta(0; s; \mathbf x) = \varphi(1 \, B^s \mathbf x) - \varphi(B^s \, 1 \mathbf x) = 0$.
  Similarly, for $s = 0$,
  $\Delta(t; 0; \mathbf x) = \varphi(A^t \, 1 \mathbf x) - \varphi(1 \, A^t \mathbf x) = 0$.
  So the Taylor series goes like
  $$
  \Delta(t; s; \mathbf x)
  = \Delta_{11} t s
  + \frac{\Delta_{12} }{1! \, 2!} t \, s^2
  + \frac{\Delta_{21} }{2! \, 1!} t^2 s + \dots
  $$
}

\begin{lem}
  The mixed partial derivative $\partial^2 \Delta/\partial s \partial t$ at $0$
  is equal to the commutator of differentiation in the directions
  $\mathbf A$ and $\mathbf B$:
  $$
  \frac{\partial^2}{\partial s \partial t}\bigg|_{s=t=0}
  {\varphi(A^tB^s\mathbf x) - \varphi(B^sA^t\mathbf x)}
  =
  (L_\mathbf{B} L_\mathbf{A} \varphi
  -L_\mathbf{A} L_\mathbf{B} \varphi)
  (\mathbf x).
  $$
\end{lem}

\begin{proof}
  By the definition of $L_\mathbf{A}$,
  $$
  \frac{\partial}{\partial t}\bigg|_{t=0}
  \varphi(A^tB^s\mathbf x)
  =
  (L_\mathbf{A} \varphi)(B^s\mathbf x).
  $$
  If we denote the function $L_\mathbf{A}\varphi$ by $\psi$,
  then by the definition of $L_\mathbf{B}$
  $$
  \frac{\partial}{\partial s}\bigg|_{s=0}
  \psi(B^s\mathbf x)
  =
  (L_\mathbf{B} \psi)(\mathbf x).
  $$
  Thus,
  $$
  \frac{\partial^2}{\partial s \partial t}\bigg|_{s=t=0}
  \varphi(A^tB^s\mathbf x)
  =
  (L_\mathbf{B} L_\mathbf{A} \varphi)(\mathbf x).
  $$
\end{proof}

We now consider the commutator of differentiation operator
$L_\mathbf{B} L_\mathbf{A} - L_\mathbf{A} L_\mathbf{B}$.
%
At first glance this is a \emph{second}-order differential operator.

\begin{lem}
  The operator
  $L_\mathbf{B} L_\mathbf{A} \varphi-L_\mathbf{A} L_\mathbf{B} \varphi$
  is a first-order linear differential operator.
\end{lem}

\begin{proof}
  Let $(A_1, \dots, A_n)$ and $(B_1, \dots, B_n)$
  be the components of the fields $\mathbf A$ and $\mathbf B$
  in the local coordinate system $(x_1, \dots, x_n)$ on $M$.
  Then
  $$
  L_\mathbf{B} L_\mathbf{A} \varphi
  =
  \sum_{i=1}^n B_i \frac{\partial}{\partial x_i}
  \sum_{j=1}^n A_j \frac{\partial}{\partial x_j} \varphi
  =
  \sum_{i,j=1}^n
    B_i \frac{\partial A_j}{\partial x_i}
    \frac{\partial}{\partial x_j} \varphi
  +
  \sum_{i,j=1}^n
    B_i A_j
    \frac{\partial^2 \varphi}{\partial x_i \partial x_j} \varphi.
  $$
  If we subtract $L_\mathbf{A} L_\mathbf{B} \varphi$,
  the term with the second derivatives of $\varphi$ vanishes,
  and we obtain
  $$
  (L_\mathbf{B} L_\mathbf{A} - L_\mathbf{A} L_\mathbf{B}) \varphi
  =
  \sum_{i,j=1}^n
    \left(
      B_i \frac{\partial A_j}{\partial x_i}
      -
      A_i \frac{\partial B_j}{\partial x_i}
    \right)
    \frac{\partial}{\partial x_j} \varphi.
  $$
\end{proof}

\note{Notice the change of order of $A$ and $B$
  from $A^t B^s$ to $L_{\mathbf B}L_{\mathbf A}$.
  Example.
  In $\mathbb R^n$,
  for $B^s \mathbf x = e^s \mathbf x$,
  $$
  \frac{\partial}{\partial s}\bigg|_{s=0}
  \psi(e^s\mathbf x)
  =
  \sum_{i = 1}^n x_i \frac{ \partial \psi }{ \partial x_i }.
  $$
  So $L_\mathbf{B} = \mathbf x \cdot \nabla$,
  and $e^{s L_\mathbf{B}} \psi(\mathbf x) = \psi(e^s \mathbf x)$.
  %
  For $A^t \mathbf x = \mathbf x + t\mathbf a$,
  $$
  \frac{\partial}{\partial t}\bigg|_{t=0}
  \varphi(\mathbf x + t \mathbf a)
  =
  \sum_{i = 1}^n a_i \frac{ \partial \varphi }{ \partial x_i }.
  $$
  So $L_\mathbf{A} = \mathbf a \cdot \nabla$,
  and $e^{t L_\mathbf{A}} \varphi(\mathbf x) = \varphi(\mathbf x + t \mathbf a)$.
  Thus
  $$
  e^{s L_\mathbf{B}} e^{t L_\mathbf{A}} \varphi(\mathbf x)
  =
  e^{s L_\mathbf{B}} \varphi(\mathbf x + t\mathbf a)
  =
  \varphi(e^s \mathbf x + t\mathbf a).
  $$
  which corresponds to
  $A^t B^s \mathbf x = A^t (e^s \mathbf x) = e^s \mathbf x + t \mathbf a$.
  However,
  $$
  e^{t L_\mathbf{A}} e^{s L_\mathbf{B}} \varphi(\mathbf x)
  =
  e^{t L_\mathbf{A}} \varphi(e^s \mathbf x)
  =
  \varphi(e^s (\mathbf x + t\mathbf a) )
  $$
  does not.
  The point is that
  the first (innermost) operator applied to the coordinates $B^s$
  corresponds to the last (outermost) differential operator
  applied to the function $e^{s L_\mathbf{B}}$.
  %
  For a chain of opertions,
  $\mathbf x \to B^s \mathbf x \to A^t B^s \mathbf x$,
  a flow operator, such as $A^t$ or $B^s$,
  applies on the current argument, or the current coordinates,
  so the first geometric operation
  goes into the innermost level.
  %
  On the other hand,
  differential operators for functions,
  like $e^{s L_\mathbf{B}}$ and $e^{t L_\mathbf{A}}$, always operate
  on $\mathbf x$ (instead of the argument of the function),
  so the operator corresponds to the first operation
  needs to be placed outermost to access
  the original $\mathbf x$.
}

Since every first-order linear differential operator is given by
a vector field, our operator
$L_\mathbf{B} L_\mathbf{A} - L_\mathbf{A} L_\mathbf{B}$
also corresponds to some vector field $L_\mathbf{C}$.


\begin{defn*}
  The \emph{Poisson bracket} or \emph{commutator}
  of two vector fields $\mathbf A$ and $\mathbf B$
  on a manifold $M$\footnote{In many books the bracket
    is given the opposite sign.
    Our sign agrees with  the sign of the commutator
    in the theory of Lie groups (cf. subsection F).}
  is the vector field $\mathbf C$, for which
  $$
  L_\mathbf{C} = L_\mathbf{B} L_\mathbf{A} - L_\mathbf{A} L_\mathbf{B}.
  $$
  The Poisson bracket of two vector fields is denoted by
  $\mathbf C = [ \mathbf A, \mathbf B ]$.
\end{defn*}

\begin{prob*}
  Suppose that the vector fields $\mathbf A$ and $\mathbf B$
  are given by their components $A_i$, $B_i$ in coordinates $x_i$.
  Find the components of the Poisson bracket.

  \solution{
    In the proof of Lemma 2, we proved the formula
    $$
    [\mathbf A, \mathbf B]_j =
    \sum_{i = 1}^n
      B_i \frac{ \partial A_j }{ \partial x_i }
      -
      A_i \frac{ \partial B_j }{ \partial x_i }.
    $$
  }
\end{prob*}


\begin{prob*}
  Let $\mathbf A_1$ be the linear vector field of velocities of a rigid body
  rotating with angular velocity $\pmb\omega_1$ around $\mathbf 0$,
  and $\mathbf A_2$ the same thing with $\pmb\omega_2$.
  Find the Poisson bracket $[\mathbf A_1, \mathbf A_2]$.

  \answer{Assuming summation over repeated indices.
    $A_{1j} = \epsilon_{jmn}\omega_{1m}x_n$,
    $\frac{ \partial A_{1j} }{ x_i } = \epsilon_{jmi}\omega_{1m}$,
    So
    $$
    \begin{aligned}
      A_{2i} \frac{ \partial A_{1j} }{ x_i }
      &= \epsilon_{ipq} \omega_{2p} x_q \epsilon_{jmi}\omega_{1m}
      = (\delta_{pj}\delta_{qm} - \delta_{pm}\delta_{qj}) \, \omega_{2p} x_q \omega_{1m} \\
      &= (\omega_{1m} x_m) \, \omega_{2j} - (\omega_{1m} \omega_{2m}) \, x_j.
    \end{aligned}
    $$
    By symmetry,
    $$
      A_{1i} \frac{ \partial A_{2j} }{ x_i }
      =
      (\omega_{2m} x_m) \, \omega_{1j} - (\omega_{1m} \omega_{2m}) x_j.
    $$
    Thus
    $$
    \begin{aligned}
      A_{2i} \frac{ \partial A_{1j} }{ x_i }
      -
      A_{1i} \frac{ \partial A_{2j} }{ x_i }
      &=
      (\omega_{1m} x_m) \, \omega_{1j}
      -
      (\omega_{2m} x_m) \, \omega_{1j} \\
      &=
      (\delta_{rm} \delta_{sj} - \delta_{sm} \delta_{rj} ) \omega_{1r} \omega_{2s} x_m
      \\
      &=
      \epsilon_{irs} \epsilon_{imj} \omega_{1r} \omega_{2s} x_m
      = [(\pmb\omega_1 \times \pmb\omega_2) \times \mathbf x]_j.
    \end{aligned}
    $$
    This shows the Poisson bracket represents a rotation with angular velocity
    $\pmb\omega_1 \times \pmb\omega_2$
    (and the author's choice of the sign of Poisson bracket
    is the natural one).
  }
\end{prob*}

% subsection 39D
\subsection{The Jacobi identity}

\begin{thm*}
  The Poisson bracket  makes the vector space of vector fields on a manifold $M$
  into a Lie algebra.
\end{thm*}

\begin{proof}
  Linearity and skew-symmetry of the Poisson bracket are clear.
  We will prove the Jacobi identity. By the definition of Poisson bracket,
  we have
  $$
  L_\mathbf{ [[A, B], C]} =
  L_{\mathbf C} L_\mathbf{ [A, B] } -L_\mathbf{ [A, B]} L_{\mathbf C}
  =
   L_{\mathbf C} L_{\mathbf B} L_{\mathbf A}
  -L_{\mathbf C} L_{\mathbf A} L_{\mathbf B}
  -L_{\mathbf B} L_{\mathbf A} L_{\mathbf C}
  +L_{\mathbf A} L_{\mathbf B} L_{\mathbf C}
  $$
  There will be 12 terms in all in the sum
  $ L_{\mathbf [[A, B], C]} + L_{\mathbf [[B, C], A]} + L_{\mathbf [[C, A], B]}$.
  Each term appears in the sum twice with opposite signs.
  \note{The other 8 terms:
  $$
  \begin{aligned}
  L_\mathbf{ [[B, C], A]}
  &=
  L_{\mathbf A} L_\mathbf{ [B, C] } -L_\mathbf{ [B, C]} L_{\mathbf A}
  =
   L_{\mathbf A} L_{\mathbf C} L_{\mathbf B}
  -L_{\mathbf A} L_{\mathbf B} L_{\mathbf C}
  -L_{\mathbf C} L_{\mathbf B} L_{\mathbf A}
  +L_{\mathbf B} L_{\mathbf C} L_{\mathbf A},  \\
  L_\mathbf{ [[C, A], B]}
  &=
  L_{\mathbf B} L_\mathbf{ [C, A] } -L_\mathbf{ [C, A]} L_{\mathbf B}
  =
   L_{\mathbf B} L_{\mathbf A} L_{\mathbf C}
  -L_{\mathbf B} L_{\mathbf C} L_{\mathbf A}
  -L_{\mathbf A} L_{\mathbf C} L_{\mathbf B}
  +L_{\mathbf C} L_{\mathbf A} L_{\mathbf B}.
  \end{aligned}
  $$
  }
\end{proof}

% subsection 39E
\subsection{A condition for the commutativity flows}

Let $\mathbf{A}$ and $\mathbf{B}$ be vector fields
on a manifold $M$.

\begin{thm*}
  The two flows $A^t$ and $B^s$ commute if and only if
  the Poisson bracket of the corresponding vectors fields
  $[\mathbf A, \mathbf B]$ is equal to zero.
\end{thm*}

\begin{proof}
  If $A^tB^s = B^s A^t$ then $[\mathbf A, \mathbf B] = 0$ by Lemma 1.
  If $[\mathbf A, \mathbf B] = 0$,
  then by Lemma 1,
  $$
  \varphi(A^tB^s\mathbf x)
  -
  \varphi(B^sA^t\mathbf x)
  = o(s^2 + t^2)
  \qquad
  s \to 0
  \; \mathrm{and} \;
  t \to 0
  $$
  for any function $\varphi$ at any point $\mathbf x$.
  \note{This is the ``little $o$'' notation instead of the ``big $O$'' notation.
    $o(s^2+t^2)$ means the leading term of the expansion is smaller than
  (instead of as large as) a multiple of $s^2 +t^2$,
  i.e., the leading term start with the third power of $s$ and $t$.}
  We will show that this implies
  $\varphi(A^tB^s\mathbf x) = \varphi(B^sA^t\mathbf x)$
  for sufficiently small $s$ and $t$.
  %
  If we apply this to the local coordinates,
  $(\varphi = x_1, \dots, \varphi = x_n)$
  we obtain $A^tB^s = B^s A^t$.

  Consider the rectangle $0 \le t \le t_0$, $0 \le s \le s_0$
  (Figure 170) in the $t,s$-plane.
  %
  To every path going from $(0,0)$ to $(t_0, s_0)$
  and consisting of a finite number of intervals
  in the coordinate directions, we associate
  a product of transformations of the flows $A^t$ and $B^s$.
  %
  Namely to each interval $t_1 \le t \le t_2$,
  we associate $A^{t_2 - t_1}$
  and to each interval $s_1 \le t \le s_2$,
  we associate $B^{s_2 - s_1}$;
  the transformations are applied to
  the order in which the intervals occur
  in the path, beginning at $(0,0)$.
  %
  For example,
  the sides $(0 \le t \le t_0, s = 0)$
  and $(t = t_0, 0 \le s \le s_0)$
  corresponds to the product $B^{s_0} A^{t_0}$,
  and the sides $(t = 0, 0 \le s \le s_0)$
  and $(s = s_0, 0 \le t \le t_0)$
  to the product $A^{t_0} B^{s_0}$.

  \begin{figure}[h]
    \centering
    \begin{tikzpicture}
      \draw [thick,->] (0,0) -- (4,0);
      \draw [thick,->] (0,0) -- (0,3.5);

      % horizontal lines
      \draw (0, 0.4) -- (2.8, 0.4)
            (0, 0.8) -- (2.8, 0.8)
            (0, 1.2) -- (2.8, 1.2)
            (0, 1.6) -- (2.8, 1.6)
            (0, 2.0) -- (2.8, 2.0)
            (0, 2.4) -- (2.8, 2.4)
            (0, 2.8) -- (2.8, 2.8);
      % vertical lines
      \draw (0.4, 0) -- (0.4, 2.8)
            (0.8, 0) -- (0.8, 2.8)
            (1.2, 0) -- (1.2, 2.8)
            (1.6, 0) -- (1.6, 2.8)
            (2.0, 0) -- (2.0, 2.8)
            (2.4, 0) -- (2.4, 2.8)
            (2.8, 0) -- (2.8, 2.8);

      \draw [ultra thick]
        (0, 0) -- (0.8, 0) -- (0.8, 1.6) -- (2.4, 1.6)
        -- (2.4, 2.4) -- (2.8, 2.4) -- (2.8, 2.8)
        (2.0, 1.6) -- (2.0, 2.0) -- (2.4, 2.0);
      \node [] at (0,-0.2) {$0$};
      \node [] at (2.8,-0.2) {$t_0$};
      \node [] at (4.2,0) {$t$};
      \node [] at (-0.2,2.8) {$s_0$};
      \node [] at (0, 3.6) {$s$};
      \node [] at (2.8,3.0) {$t_0, s_0$};
    \end{tikzpicture}
    \caption{Proof of the commutativity of flows}
  \end{figure}

  \begin{figure}[h]
    \centering
    \begin{tikzpicture}
      [
        % frame node (empty)
        fnode/.style={minimum size=0, inner sep=0},
        % circle node
        cnode/.style={draw, circle, minimum size=0.2cm, inner sep=0.0cm}
      ]
      % frame
      \node[fnode] (f1) at (-1.0, -1.0) {};
      \node[fnode] (f2) at ( 5.0, -1.2) {} edge [bend right=10] (f1);
      \node[fnode] (f3) at (-1.8,  4.8) {} edge [bend left=15] (f1);
      \node[fnode] (f4) at ( 5.2,  5.0) {}
          edge [bend left=10] (f2)
          edge [bend right=10] (f3);

      \node (M) at (-0.5, -0.5) {$M$};

      \node[cnode, label={below:$\mathbf x$}] (x) at ( 0.0,  0.0) {};
      \node[fnode] (x1) at ( 1.5, 0.0) {}
          edge [ultra thick, bend right=5] (x);
      \node[fnode] (x1y2) at ( 1.5, 2.0) {}
          edge [ultra thick, bend left=5] (x1);
      \node[cnode, label={below:$\pmb\delta$}] (delta) at ( 2.0, 1.95) {}
          edge [ultra thick] (x1y2);
      \node[cnode, label={below:$\pmb\gamma$}] (gamma) at ( 3.0, 1.85) {}
          edge [ultra thick] (delta);
      \node[cnode, label={right:$\pmb\beta$}] (beta) at ( 3.1, 2.65) {}
          edge [ultra thick] (gamma);
      \node[cnode, label={left:$\pmb\epsilon$}] (epsilon) at ( 2.1, 2.75) {}
          edge [ultra thick] (delta);
      \node[cnode, label={115:$\pmb\alpha$}] (alpha) at ( 2.8, 2.7) {}
          edge [ultra thick] (epsilon);
      \node[fnode] (pt2) at ( 2.95, 3.75) {}
          edge [ultra thick] (alpha);
      \node[fnode] (pt3) at ( 3.40, 3.70) {}
          edge [ultra thick] (pt2);
      \node[cnode, label={left:$\pmb\alpha'$}] (alphap) at ( 3.45, 4.05) {}
          edge [ultra thick] (pt3);
      \node[fnode] (pt4) at ( 3.20, 3.55) {}
          edge [ultra thick] (beta);
      \node[fnode] (pt5) at ( 3.65, 3.50) {}
          edge [ultra thick] (pt4);
      \node[cnode, label={right:$\pmb\beta'$}] (betap) at ( 3.70, 4.00) {}
          edge [ultra thick] (pt5);


      % right edge
      \node [cnode, label={below:$A^{t_0}\mathbf x$}] (At0x) at (4.1, -0.3) {}
          edge [dotted, bend right=5] (x1);
      \node [cnode, label={right:$B^{s_0}A^{t_0}\mathbf x$}] (Bs0At0x) at (4.5, 3.9) {}
          edge [ultra thick, bend left=5] (At0x);

      % top edge
      \node [cnode, label={100:$B^{s_0}\mathbf x$}] (Bs0x) at (-0.3, 4.0) {};
      \node [cnode, label={above:$A^{t_0}B^{s_0}\mathbf x$}] (At0Bs0x) at (3.2, 4.5) {}
          edge [ultra thick, bend right=10] (Bs0x);
    \end{tikzpicture}
    \caption{
      Curvilinear quadrilateral $\beta\gamma\delta\epsilon\alpha$
    }
  \end{figure}
  In addition, we associate to each such path in the $(t, s)$-plane
  a path on the manifold $M$ starting at the point $\mathbf x$
  and composed of trajectories of the flows $A^t$ and $B^s$
  (Figure 171).
  %
  If a path in the $(t, s)$-plane corresponds to the product
  $A^{t_1} B^{s_1} \cdots A^{t_n} B^{s_n}$,
  then on the manifold $M$
  the corresponding path ends at the point
  $A^{t_1} B^{s_1} \cdots A^{t_n} B^{s_n} \mathbf x$.
  %
  Our goal will be to show that all these paths
  actually terminate at one point
  $A^{t_0} B^{s_0} \mathbf x = B^{s_0} A^{t_0} \mathbf x$.


  \begin{figure}[h]
    \centering
    \begin{tikzpicture}
      \draw[ultra thick] (0,0) -- (4,0) -- (4,4) -- (0,4) -- cycle;
      \draw[] (0.3, 0) -- (0.3, 2.4) -- (2.2, 2.4) -- (2.2, 4);
      \draw[] (0.6, 0) -- (0.6, 2.0) -- (3.6, 2.0) -- (3.6, 4);
      \draw[] (2.2, 0) -- (2.2, 1.6) -- (4.0, 1.6);

      \node[] at (4.6, 3.0) {$N = 2$};
      \node[] at (2.4, 1.4) {$1$};
      \node[] at (0.8, 1.8) {$2$};
      \node[] at (2.4, 3.8) {$3$};
      \node[] at (0.2, 3.8) {$4$};
    \end{tikzpicture}
    \caption{Going from one pair of sides to the other}
  \end{figure}
  We partition the intervals $0 \le t \le t_0$
  and $0 \le s \le s_0$ into $N$ equal parts,
  so that the whole rectangle is divided into $N^2$
  small triangles.
  %
  The passage from the sides $(0,0) - (t_0, 0) -(t_0, s_0)$
  to the sides $(0, 0) - (0, s_0) - (t_0, s_0)$
  can be accomplished in $N^2$ steps,
  in each of which a pair of neighboring sides of
  a small rectangle is exchanged for the other pair (Figure 172).
  %
  In general,
  this small rectangle corresponds to a non-closed curvilinear
  quadrilateral $\pmb\beta\pmb\gamma\pmb\delta\pmb\epsilon\pmb\alpha$
  on the manifold (Figure 171).
  %
  Consider the distance\footnote{In some riemannian metric on $M$.}
  \note{The distance is denoted by $\rho$}
  between its vertices $\pmb\alpha$ and $\pmb\beta$
  corresponding to the largest values of $s$ and $t$.
  %
  As we saw earlier,
  $\rho(\pmb\alpha, \pmb\beta) \le C_1 N^{-3}$
  (where the constant $C_1 > 0$ does not depend on $N$).
  %
  Using the theorem of the differentiability of solutions
  of differential equations with respect to the initial data,
  it is not difficult to derive from this a bound on the distance
  between the ends $\pmb\alpha'$ and $\pmb\beta'$ of the paths
  $\mathbf x\pmb\delta\pmb\gamma\pmb\beta\pmb\beta'$
  and
  $\mathbf x\pmb\delta\pmb\epsilon\pmb\alpha\pmb\alpha'$
  on $M$:
  $\rho(\pmb\alpha', \pmb\beta') < C_2 N^{-3}$,
  where the constant $C_2 > 0$ again does not depend on $N$.
  %
  But we broke up the whole journey from $B^{s_0}A^{t_0}\mathbf x$
  to $A^{t_0}B^{s_0}\mathbf x$ into $N^2$ such pieces.
  %
  Thus, $\rho(A^{t_0}B^{s_0}\mathbf x, B^{s_0}A^{t_0}\mathbf x)
  \le N^2 C_2 N^{-3} \; \forall N$.
  Therefore, $A^{t_0}B^{s_0}\mathbf x = B^{s_0}A^{t_0}\mathbf x$.

\end{proof}




% subsection 39F Appendix
\subsection{Appendix: Lie algebras and Lie groups}


A \emph{Lie group} is a group $G$ which is a differentiable manifold,
and for which the operations (product and inverse)
are differentiable maps $G\times G \to G$
and $G \to G$.
%
\note{The differentiable manifold defining the Lie group
is a manifold of diffeomorphisms
(i.e., generalized geometric transformations,
like rotations and translations).
Since there are so many possible transformations
even in one dimension,
the dimension of this manifold is infinite,
different from the $2n$-dimensional symplectic manifold.
}

The tangent space $TG_e$ to a Lie group $G$
at the identity has a natural Lie algebra structure;
it is defined as follows:
\note{We may think the identity element as
  the identity transformation,
  and the tangent space consists of
  infinitesimal transformations.
}

For each tangent vector $\mathbf A \in TG_e$
there is a one-parameter subgroup $A^t \subset G$
with velocity vector $\mathbf A = (d/dt)|_{t = 0} A^t$.

The degree of non-commutativity of two subgroups $A^t$ and $B^s$
is measured by the product $A^tB^sA^{-t}B^{-s}$.
%
It turns out that there is one and only one subgroup $C^r$ for which
$$
\rho(A^tB^sA^{-t}B^{-s}, C^{st}) = o(s^2 + t^2)
\quad
\mathrm{as \;}
s \mathrm{\; and \;} t \to 0.
$$
The corresponding vector $\mathbf C =(d/dr)|_{r = 0} C^r$
is called the \emph{Lie bracket}
%
$\mathbf C = [\mathbf A, \mathbf B]$
of the vectors $\mathbf A$ and $\mathbf B$.
%
It can be verified that the operation of Lie bracket
introduced in this way makes the space $TG_e$
into a Lie algebra (i.e., the operation
is bilinear, skew-symmetric, and satisfies the
Jacobi identity).
%
This algebra is called the \emph{Lie algebra of the Lie group $G$}.

\begin{prob*}
  Compute the bracket operation in the Lie algebra
  of the group SO(3) of rotations in three-dimensional
  euclidean space.

  \answer{
    Consider the rotation $A^t$ around the axis $\mathbf a$
    (a unit vector) by angle $t$.
    %
    Any vector $\mathbf x$ can be decomposed to
    parallel $\mathbf x_\parallel = \mathbf a \, (\mathbf a \cdot \mathbf x)$
    and
    perpendicular $\mathbf x_\perp = \mathbf x - \mathbf x_\parallel$
    components to $\mathbf a$.
    The former is unchanged under rotation,
    the latter is rotated by $t$.
    So
    %
    $$
    A^t\mathbf x
    =
    \mathbf x_\parallel
    +
    \mathbf x_\perp \, \cos t
    +
    (\mathbf a \times \mathbf x_\perp) \, \sin t.
    $$
    %
    So
    $
    (d/dt)|_{t = 0} A^t\mathbf x
    = \mathbf a \times \mathbf x_\perp
    = \mathbf a \times \mathbf x,
    $
    and the vector field $\mathbf{A(x)} = \mathbf a \times \mathbf x$.
    Or in component form:
    $\sum_j A_{ij} x_j = \sum_{jk} \epsilon_{ikj} a_k x_j$,
    which means
    $A_{ij} = \sum_k \epsilon_{ikj} a_k$.

    For the product
    $P_{s,t}\,\mathbf x = A^tB^sA^{-t}B^{-s}\mathbf x$
    $$
    \begin{aligned}
    P_{s, t} \, \mathbf x
    &=
    \exp(t \mathbf A) \,
    \exp(s \mathbf B) \,
    \exp(-t \mathbf A) \,
    \exp(-s \mathbf B) \, \mathbf x
    \\
    &\approx
    \left(1 + t \mathbf A + \tfrac{t^2 \mathbf A^2}{2}\right) \,
    \left(1 + s \mathbf B + \tfrac{s^2 \mathbf B^2}{2}\right) \,
    \left(1 - t \mathbf A + \tfrac{t^2 \mathbf A^2}{2}\right) \,
    \left(1 - s \mathbf B + \tfrac{s^2 \mathbf B^2}{2}\right) \, \mathbf x
    \\
    &=
    \mathbf x
    +
    ts (\mathbf{A B - BA}) \, \mathbf x + \dots.
    \end{aligned}
    $$
    (The series has to start with the $st$ term
    since $P_{t=0, s} = P_{t, s=0} = 1$.)
    This shows
    $$
    \mathbf C = \mathbf A \mathbf B - \mathbf B \mathbf A.
    $$
    Now
    $$
    (\mathbf A \mathbf B)_{ij}
    = \sum_k A_{ik} B_{kj}
    = \sum_{k, p, q} \epsilon_{ipk} a_p \epsilon_{kqj} b_q
    = \sum_{k, p, q} (\delta_{iq} \delta_{pj} - \delta_{ij} \delta_{pg}) a_p \, b_q
    = a_j b_i - \delta_{ij} a_p b_p,
    $$
    and
    $$
    (\mathbf A \mathbf B - \mathbf B \mathbf A)_{ij}
    = a_j b_i - a_i b_j
    = \sum_{p, q} (\delta_{jp} \delta_{iq} - \delta_{ip} \delta_{jq}) \, a_p \, b_q
    = \sum_{k, p, q} \epsilon_{ikj} \epsilon_{kpq} a_p \, b_q.
    $$
    If this quantity is $\mathbf C_{ij} = \sum_k \epsilon_{ikj} c_k$,
    then
    $c_k = \epsilon_{kpq} a_p \, b_q$,
    or in vector form $\mathbf c = \mathbf a \times \mathbf b$.
  }
\end{prob*}


Lemma 1 shows that the Poisson bracket of vector fields
can be defined as the Lie bracket for the
``infinite-dimensional Lie group''
of diffeomorphism\footnote{
  Our choice of sign in the definition of Poisson bracket
  was determined by the correspondence.
}
of the manifold $M$.

On the other hand,
the Lie bracket can be defined
using the Poisson bracket of vector fields
on a Lie group $G$.
%
Let $g \in G$.
%
Right translation $R_g$ is the map
$R_g: G \to G, R_g h = h g$.
%
The differential of $R_g$ at the point $e$
maps $TG_e$ into $TG_g$.
%
\note{Using $A^t$ for $h$,
  $R_g \, A^t = A^t \, g$.
  As $t \to 0$,
  we map an infinitesimal transformation $A^t = 1 + t \mathbf A$
  to a transformation that is infinitely close to $g$.
  %
  So $(d/dt)|_{t = 0} R_g \, A^t = (d/dt)|_{t = 0} A^t g = \mathbf A \, g$,
  where $\mathbf A \in TG_e$,
  and $\mathbf A \, g \in TG_g$.
}
%
In this way, every vector $\mathbf A \in TG_e$
corresponds to a vector field on the group:
it consists of the right translations $(R_g)_* \mathbf A$
and is called a \emph{right-invariant vector field}.
%
Clearly, a right-invariant vector field
on a group is uniquely determined by its value
at the identity.

\begin{prob*}
  Show that the Poisson bracket of right-invariant vector fields
  on a Lie group $G$ is a right-invariant vector field,
  and its value at the identity of the group is equal to
  the Lie bracket of the values of the original vector fields
  at the identity.

  \answer{(Not sure.)
    The Poisson bracket of two right vector fields may be defined as
    $$
    [\pmb\xi, \pmb\eta]_g = \pmb\xi \, g^{-1} \pmb\eta - \pmb\eta \, g^{-1} \pmb\xi.
    $$
    Then, for $\pmb\xi = (R_g)_*\mathbf A = \mathbf A g$,
    and $\pmb\eta = (R_g)_*\mathbf B = \mathbf B g$, we have
    $$
    [(R_g)_*\mathbf A, (R_g)_*\mathbf B]
    = \mathbf A \, g \, g^{-1} \mathbf B \, g
    - \mathbf B \, g \, g^{-1} \mathbf A \, g
    = (\mathbf A \mathbf B - \mathbf B \, \mathbf A) \, g
    = (R_g)_* [\mathbf A, \mathbf B]_e,
    $$
    which is a right-invariant vector field of $[\mathbf A, \mathbf B]_e$.
    %
    The value at $g = e$ is simply $[\mathbf A, \mathbf B]_e$.
  }
\end{prob*}

\summary{
  \begin{enumerate}
    \item A \emph{Lie algebra} is a vector space $L$ equipped with a
      \emph{Poisson bracket}, or \emph{commutator}, $[A, B]$,
      which is bilinear and satisfies the Jacobi identity:
      $$
      [[A, B], C] + [[B, C], A] + [[C, A], B] = 0.
      $$
      The Poisson bracket can be thought as a generalization
      of the vector product in three-dimensional space.

    \item Particularly, we studied the Lie algebra of vector fields
        $\mathbf A(\mathbf x)$.
        Each vector fields corresponds to a flow $A^t$
        and a Lie derivative
        $L_{\mathbf A} = \mathbf A \cdot \nabla
        = \sum_i A_i \frac{ \partial } { \partial x_i } $,
        which is a linear differential operator.
        %
        The flow applies to the points on the manifold $M$,
        the Lie derivative to function of the points on the manifold $M$.
        The composition of two flows $A^t B^s$
        is equivalent to the reverse composition of Lie derivatives
        $L_\mathbf{B} L_\mathbf{A}$:
        $\varphi(A^t \, B^s \mathbf x)
        = e^{s L_\mathbf{B}} e^{t L_\mathbf{A}} \varphi(\mathbf x)$.

    \item The Poisson bracket $[\mathbf A, \mathbf B]$
        of two vector fields $\mathbf A$ and $\mathbf B$
        is defined through the commutator of the Lie deriviatives,
        such that
        $$
        L_\mathbf{[A, B]} = L_\mathbf{B} L_\mathbf{A} - L_\mathbf{A} L_\mathbf{B}.
        $$
        In components,
        $$
        [\mathbf A, \mathbf B]_j
        = \sum_i \left(
          B_i \frac{\partial A_j } { \partial x_i}
        - A_i \frac{\partial B_j } { \partial x_i}
          \right).
        $$
        (Remember the opposite sign, for Lie derivatives
        apply to functions, instead of points on the manifold.)

    \item The above Poisson bracket of vector fields
      satisfies the Jacobi identity.

    \item If the Poisson bracket $[\mathbf A, \mathbf B]$ of two vector fields vanishes,
      the two flows commute $A^t B^s = B^s A^t$, vice versa.
  \end{enumerate}
}



% section 40
\section{The Lie algebra of hamiltonian functions}

The hamiltonian vector fields on a symplectic manifold
form a subalgebra of the Lie algebra of all fields.
%
The hamiltonian functions also form a Lie algebra:
the operation in this algebra is called the Poisson bracket
of functions.
\note{The hamiltonian functions
also form a vector space.}
%
The first integrals of a hamiltonian phase flow form
a subalgebra of the Lie algebra of hamiltonian functions.


\begin{figure}[h]
  \centering
  \begin{tikzpicture}
    \node (vf) at (0, 0)
      [draw, align=center, minimum size=9em, minimum width=15em]
      { \\[7em] Lie algebra of vector fields};
    \node (hamiltonianvf) at (0, 0)
      [draw, align=center, minimum size=6em, minimum width=10em]
      { Lie algebra \\ of hamiltonian \\ vector fields};

    \node (hamiltonianfunc) at (15em, 0)
      [draw, align=center, minimum size=6em, minimum width=10em]
      { \\[3em] Lie algebra of \\ hamiltonian functions}
      edge[ultra thick, ->] (hamiltonianvf);

    \node (firstintegrals) at (15em, 1em)
      [draw, align=center, minimum size=3em, minimum width=9em]
      { Lie algebra of the \\ first integrals of $H$ };
  \end{tikzpicture}
\end{figure}

% subsection 40A
\subsection{The Poisson bracket of two functions}

Let $(M^{2n}, \omega^2)$ be a symplectic manifold.
To a given function $H: M^{2n} \to \mathbb R$
on the symplectic manifold
there corresponds to a one-parameter
$g_H^t: M^{2n} \to M^{2n}$
of canonical transformations of $M^{2n}$--the
phase flow of the hamiltonian function equal to $H$.
%
Let $F: M^{2n} \to \mathbb R$
be another function on $M^{2n}$.

\begin{defn*}
  The \emph{Poisson bracket} $(F, H)$ of functions $F$ and $H$
  given on a symplectic manifold $(M^{2n}, \omega^2)$
  is the derivative of the function $F$ in the direction of
  the phase flow with hamiltonian function $H$:
  $$
  (F, H)(\mathbf x)
  =
  \left. \frac{ d }{ dt } \right|_{t = 0}
  F( g_H^t( \mathbf x ) ).
  $$
  Thus, the Poisson bracket of two functions on $M$ is again
  a function on $M$.
\end{defn*}

% Corollary 1
\begin{cor}
  A function $F$ is a first integral of the phase flow
  with hamiltonian function $H$ if and only if its Poisson bracket
  with $H$ is identically zero: $(F, H) \equiv 0$.
\end{cor}

We can give the definition of Poisson bracket in a slightly
different from if we use the isomorphism $I$ between 1-forms
and vector fields on a symplectic manifold $(M^{2n}, \omega^2)$.
%
%\note{Cf. Sec. 39C. The 1-form $\omega^1$ is mapped to $I\omega^1$
%such that $\omega^1(\pmb\eta) \equiv \omega^2(\pmb\eta, I\omega^1)$.
%}
%
This isomorphism is defined by the relation (cf. Section 37)
$$
\omega^2(\pmb\eta, I\omega^1)
=
\omega^1(\pmb\eta).
$$
The velocity vector of the phase flow $g_H^t$ is $IdH$.
This implies
(\note{$\omega^1 = dF$, $\pmb\eta = IdH$.})

% Corollary 2
\begin{cor}
  The Poisson bracket of the functions $F$ and $H$
  is equal to the value of the 1-form $dF$
  on the velocity vector $IdH$ of the phase flow with
  hamiltonian function $H$:
  $$
  (F, H) = dF(IdH).
  $$
\end{cor}

Using the preceding formula again, we obtain

% Corollary 3
\begin{cor}
  The Poisson bracket of the functions $F$ and $H$ is equal to the
  ``skew scalar product'' of the velocity vectors of the phase flows
  with hamiltonian functions $H$ and $F$:
  $$
  (F, H) = \omega^2(IdH, IdF).
  $$
\end{cor}

It is now clear that

% Corollary 4
\begin{cor}
  The Poisson bracket of the functions $F$ and $H$
  is a skew-symmetric bilinear function of $F$ and $H$:
  $$
  (F, H) = -(H, F)
  $$
  and
  $$
  (H, \lambda_1 F_1 + \lambda_2 F_2)
  =
  \lambda_1 (H, F_1)
  +
  \lambda_2 (H, F_2)
  \qquad
  (\lambda_1 \in \mathbb R).
  $$
\end{cor}

Although the above arguments are obvious,
they lead to nontrivial deductions,
including the following generalization
of a theorem of E. Noether.

\begin{thm*}
  If a hamiltonian function $H$ on a symplectic manifold $(M^{2n}, \omega^2)$
  admits the one-parameter group of canonical transformations
  given by a hamiltonian $F$,
  then $F$ is a first integral of the system with hamiltonian function $H$.
\end{thm*}

\begin{proof}
  Since $H$ is a first integral of the flow $g_F^t$,
  $(H, F) = 0$ (Corollary 1).
  Therefore $(F, H) = 0$ (Corollary 4)
  and $F$ is a first integral (Corollary 1).

  \note{
    $(F, H) = \left.\frac{d}{dt}\right|_{t = 0}F(g_H^t(\mathbf x)) = 0$.
  }
\end{proof}

% Problem 1
\begin{prob}
  Compute the Poisson bracket of two functions $F$ and $H$
  in the canonical coordinates
  $\mathbb R^{2n} = \{(\mathbf p, \mathbf q)\}$,
  $\omega^2(\pmb\xi, \pmb\eta) = (I\pmb\xi, \pmb\eta)$.
  \note{The last formula is only true in
  the canonical coordinates.
  Cf. the note in subsection 37C.}

  \solution{
    By the Corollary 3 we have
    $$
    (F, H) =
    \sum_{i = 1}^n
      \frac{ \partial H } { \partial p_i } \frac{ \partial F } { \partial q_i }
      -
      \frac{ \partial H } { \partial q_i } \frac{ \partial F } { \partial p_i }
    $$
    (we use the fact that $I$ is symplectic and has the form
    $$
    I = \left(\begin{array}{ccc}
        0 & -E \\
        E & 0
    \end{array}\right)
    $$
    in the basis $(\mathbf p, \mathbf q)$).
  }
\end{prob}

% Problem 2
\begin{prob}
  Compute the Poisson brackets of the basic functions $p_i$ and $q_i$.

  \solution{
    The gradients of the basic functions form a ``symplectic basis'':
    their skew-scalar products are
    $$
    (p_i, p_j) = (p_i, q_j) = (q_i, q_j) = 0 \quad (\mathrm{if}\; i\ne j)
    \qquad
    (q_i, p_i) = -(p_i, q_i) = 1.
    $$
  }
\end{prob}

% Problem 3
\begin{prob}
  Show that the map $A: \mathbb R^{2n} \to R^{2n}$
  sending $(\mathbf p, \mathbf q) \to
  (\mathbf P(\mathbf p, \mathbf q), \mathbf Q(\mathbf p, \mathbf q))$
  is canonical if and only if the Poisson brackets of any two
  functions in the variables $(\mathbf p, \mathbf q)$
  and $(\mathbf P, \mathbf Q)$ coincide:
  $$
  (F, H)_\mathbf{p, q}
  =
  \frac{\partial H}{\partial \mathbf p} \frac{\partial F}{\partial \mathbf q}
  -
  \frac{\partial H}{\partial \mathbf q} \frac{\partial F}{\partial \mathbf p}
  =
  \frac{\partial H}{\partial \mathbf P} \frac{\partial F}{\partial \mathbf Q}
  -
  \frac{\partial H}{\partial \mathbf Q} \frac{\partial F}{\partial \mathbf P}
  =
  (F, H)_\mathbf{P, Q}.
  $$

  \solution{
    \note{The ``only if'' part: canonical $\to$ Poisson brackets coincide.}
    Let $A$ be canonical.
    %
    Then the symplectic structure $d\mathbf p \wedge d\mathbf q$
    and $d\mathbf P \wedge d\mathbf Q$ coincide.
    \note{This is equivalent to saying $\int_c \omega^2 = \int_{gc} \omega^2$.}
    But the definition of the Poisson bracket $(F, H)$
    was given invariably in terms of the symplectic structure;
    it did not involve the coordinates. Therefore,
    $$
    (F, H)_\mathbf{p, q} = (F, H) = (F, H)_\mathbf{P, Q}.
    $$
    \note{The ``if'' part: Poisson brackets coincide $\to$ canonical.}
    Conversely, suppose that the Poisson brackets
    $(P_i, Q_j)_\mathbf{p, q}$ have the standard form
    of Problem 2.
    Then, clearly $d\mathbf P \wedge d\mathbf Q = d\mathbf p \wedge d\mathbf q$,
    i.e., the map is canonical.
    \note{
      For the ``if'' part, note that $(F, H)_\mathbf{p, q} = \omega^2(IdH, IdF)$
      for the two vectors, $IdH$ and $IdF$.
      %
      The 2-form $\omega^2$ giving the symplectic structure
      on the $2n$-dimensional manifold has a finite dimension,
      $2 \, n \, (2 \, n-1)/2$.
      The idea for the proof is that if two 2-forms yield
      the same value for all pairings for $2n$ independent vectors,
      we can then ensure the two 2-forms are the same.
    }

    \note{
      Alternative argument for the ``if'' part:
      if $(F, H)_\mathbf{p, q} = (F, H)_\mathbf{P, Q}$ for $\forall F, H$,
      then $d\mathbf p \wedge d\mathbf q = d\mathbf P \wedge d\mathbf Q$.

      Let $\mathbf x = (\mathbf p, \mathbf q)$,
      $\mathbf X = (\mathbf P, \mathbf Q)$,
      we have
      $$
      \begin{aligned}
      (F, H)_\mathbf{p, q}
      &=
      \sum_{k,l} J^{kl}
        \frac{ \partial F } { \partial x^k }
        \frac{ \partial H } { \partial x^l }
      =
      \sum_{k,l,K,L} J^{kl}
        \frac{ \partial F } { \partial X^K }
        \frac{ \partial X^K } { \partial x^k }
        \frac{ \partial H } { \partial X^L }
        \frac{ \partial X^L } { \partial x^l }
      \\
      (F, H)_\mathbf{P, Q}
      &=
      \sum_{K,L} J^{KL}
        \frac{ \partial F } { \partial X^K }
        \frac{ \partial H } { \partial X^L }.
      \end{aligned}
      $$
      Since the two expression are supposed to be the same,
      we conclude
      \begin{equation}
      \sum_{k,l} J^{kl}
        \frac{ \partial X^K } { \partial x^k }
        \frac{ \partial X^L } { \partial x^l }
      = J^{KL}.
      \label{eq:symplectic_condition}
      \end{equation}

      Now let us expand the 2-form $\omega^2(\pmb\xi,\pmb\eta)$
      in components.
      First we shall review the meaning of ``components'' $\xi_k$ of a vector $\pmb\xi$.
      For a scalar $\phi$, we have
      $$
      d\phi = \sum_k \frac{ \partial \phi } { \partial x^k } dx^k
      \qquad \mathrm{and} \qquad
      d\phi
      = \sum_K \frac{ \partial \phi } { \partial X^K } dX^K
      = \sum_{k, K} \frac{ \partial \phi } { \partial X^K }
      \frac{ \partial X^K } { \partial x^k } d x^k.
      $$
      So
      $$
      \frac{ \partial \phi } { \partial x^k }
      =
      \sum_K \frac{ \partial \phi } { \partial X^K } \frac { \partial X^K } { \partial x^k },
      $$
      The components $\xi_k$ of a (covariant) vector $\pmb\xi$ are quantities
      behaves like $\partial \phi/\partial x^k$.  So
      %
      $$
      \xi_k = \sum_K \xi_K \frac { \partial X^K } { \partial x^k }.
      $$

      Now for the 2-form
      $$
      \begin{aligned}
      \omega^2(\pmb\xi, \pmb\eta)
      &=
      \sum_{k,l} J^{kl} \xi_k \eta_l
      =
      \sum_{k,l,K,L} J^{kl} \frac{ \partial X^K } { \partial x^k }
        \frac{ \partial X^L } { \partial x^l } \xi_K \xi_L \\
      &\stackrel{\eqref{eq:symplectic_condition}}{=\joinrel=}
      \sum_{K,L} J^{KL} \xi_K \xi_L.
      \end{aligned}
      $$
      The last expression is $\omega^2(\pmb\xi, \pmb\eta)$
      written in coordinates $\mathbf X = (\mathbf P, \mathbf Q)$.
      So this is precisely the statement
      $d\mathbf p \wedge d\mathbf q = d\mathbf P \wedge d\mathbf Q$
      in component form.
    }
  }
\end{prob}

% Problem 4
\begin{prob}
  Show that the Poisson bracket of a product can be calculated by Leibniz's rule:
  $$
  (F_1 F_2, H) = F_1 (F_2, H) + F_2 (F_1, H).
  $$

  \hint{The Poisson bracket $(F_1 F_2, H)$ is the derivative of the product $F_1 F_2$
  in the direction of the field $IdH$.}

  \answer{
    $$(F_1 F_2, H) = d(F_1 F_2)(IdH) = F_1 dF_2(IdH) + F_2 dF_1(IdH)
    = F_1(F_2, H) + F_2 (F_1, H).$$
  }
\end{prob}


% subsection 40B
\subsection{The Jacobi identity}

\begin{thm*}
  The Poisson bracket of three functions $A$, $B$ and $C$
  satisfies the Jacobi identity:
  $$
  ((A, B), C) + ((B, C), A) + ((C, A), B) = 0.
  $$
\end{thm*}

\begin{cor*}[Poisson's theorem]
  The Poisson bracket of two first integrals $F_1, F_2$
  of a system with hamiltonian function $H$
  is again a first integral.
\end{cor*}

\begin{proof}[Proof of the corollary]
  By the Jacobi identity,
  $$
  ((F_1, F_2), H)
  =
  (F_1, (F_2, H))
  +
  (F_2, (H, F_1)) = 0 + 0.
  $$
  as was to be shown.
\end{proof}

In this way, by knowing two first integrals we can find a third, fourth, etc.
by a simple computation.
%
Of course, not all the integrals we get will be essentially new,
since there cannot be more than $2n$ independent functions on $M^{2n}$.
%
Sometimes we may get functions of old integrals or constants,
which may be zero.
%
But sometimes we do obtain new integrals.

\begin{prob*}
  Calculate the Poisson brackets of the components
  $p_1$, $p_2$, $p_3$, $M_1$, $M_2$, $M_3$ of the
  linear and angular momentum vectors of
  a mechanical system.

  \begin{ans*}
    $(M_1, M_2) = M_3, (M_1, p_1) = 0, (M_1, p_2) = p_3, (M_1, p_3) = -p_2.$
  \end{ans*}

  \note{
    $M_i = \epsilon_{ijk} q_j \, p_k, \quad M_r = \epsilon_{rst} q_s \, p_t.$
    $$
    \begin{aligned}
      (M_i, M_r)
      &=
      \frac{ \partial M_i } { \partial q_n }
      \frac{ \partial M_r } { \partial p_n }
      -
      \frac{ \partial M_i } { \partial p_n }
      \frac{ \partial M_r } { \partial q_n }
      =
      \epsilon_{ink} p_k \epsilon_{rsn} q_s
      -
      \epsilon_{ijn} q_j \epsilon_{rnt} p_t
      \\
      &=
      (p_r \, q_i - p_k q_k \delta_{ir})
      -
      (q_r \, p_i - q_j p_j \delta_{ir})
      \\
      &=
      p_r \, q_i - q_r \, p_i
      =
      \epsilon_{mir} \epsilon_{muv} q_u p_v
      =
      \epsilon_{mir} M_m.
      \\
      (M_i, p_m)
      &=
      \frac{ \partial M_i } { \partial q_n }
      \frac{ \partial p_m } { \partial p_n }
      =
      \epsilon_{ink} p_k \delta_{mn}
      =
      \epsilon_{imk} p_k.
    \end{aligned}
    $$
  }
\end{prob*}

This implies

{\small
\begin{thm*}
  If two components $M_1$ and $M_2$ of the angular momentum
  of some mechanical problem are conserved,
  then the third component is also conserved.
\end{thm*}
}

\begin{proof}[Proof of the Jacobi identity]
  Consider the sum
  $$
  ((A, B), C) + ((B, C), A) + ((C, A), B)
  $$
  This sum is a ``linear combination of second partial derivatives''
  \note{
    Every term in $(A, B)$ is of the form of
    $\frac{ \partial }{ \partial q_i } \frac{ \partial }{ \partial p_i }$,
    which subject to $(, C)$,
    this becomes
    $\frac{ \partial }{ \partial q_j } \left( \frac{ \partial }{ \partial q_i } \frac{ \partial }{ \partial p_i } \right)$
    or
    $\frac{ \partial }{ \partial p_j } \left( \frac{ \partial }{ \partial q_i } \frac{ \partial }{ \partial p_i } \right)$,
    which contains a second partial derivative of a function
    in the inner bracket $(, )$.
  }
  of the functions $A$, $B$ and $C$.
  We will compute the terms in the second derivatives of $A$:
  $$
  ((A, B), C) + ((C, A), B)
  =
  (L_\mathbf{C} L_\mathbf{B} - L_\mathbf{B} L_\mathbf{C}) A
  $$
  \note{$= (L_{IdB} A, C) - (L_{IdC} A, B) = L_{IdC} L_{IdB} A - L_{IdB} L_{IdC} A$,}
  where $L_{\pmb\xi}$ is differentiation in the direction of $\pmb\xi$
  and $\mathbf F$ is the hamiltonian field with hamiltonian function $F$.
  But by Lemma 2, Section 39,
  the commutator of the differentiation
  $L_\mathbf{C} L_\mathbf{B} - L_\mathbf{B} L_\mathbf{C}$
  is a first-order differential operator.
  %
  This means that none of the second derivatives of $A$
  are contained in our sum.
  The same thing is true for the second derivatives of $B$ and $C$.
  Therefore the sum is zero.

  \note{
    The above argument appears to require the 2-form $\omega^2$
    giving the symplectic structure to be
    independent of the coordinates.
    %
    Below we shall handle the general case.
    %
    In component form, we have
    $
    \omega^2(\pmb\xi, \pmb\eta)
    =
    \sum_{ij} \omega^2_{ij} \xi_i \eta_j,
    $
    where $\omega^2_{ij}$ may depend on the coordinates.
    %
    Note that $\omega^2_{ij} = I^{-1}_{ij}$
    also gives the coefficents for the inverse isomorphism
    from 1-forms to vector fields, for
    $
    \omega^2(\pmb\xi, \pmb\eta) = I^{-1}\pmb\eta(\pmb\xi)
    = I^{-1}_{ij}\eta_j \, \xi_i.
    $
    Thus $\omega^2_{ij}$ and $I^{-1}_{ij}$ have to coincide.

    By Corollary 3, we have
    $$
    (A, B) = \omega^2(\mathbf B, \mathbf A)
    = \sum_{ij} \omega_{ij} B_i \, A_j,
    $$
    and by Corollary 2
    $$
    ((A, B), C)
    = d(A,B)(\mathbf C)
    = \sum_{k} \frac{ \partial (A, B) } { \partial x_k } C_k
    = \sum_{ijk} \frac{ \partial (\omega^2_{ij} B_i \, A_j) } { \partial x_k } C_k,
    $$
    where $F_i$ is the component of $\mathbf F$.
    $$
    \frac{ \partial (\omega^2_{ij} B_i \, A_j) } { \partial x_k } C_k
    =
    \frac{ \partial \omega^2_{ij} } { \partial x_k } B_i \, A_j \, C_k
    + \frac{ \partial B_i } { \partial x_k } \omega^2_{ij} A_j \, C_k
    + \frac{ \partial A_j } { \partial x_k } \omega^2_{ij} B_i \, C_k.
    $$
    Summing over cyclic versions, and taking into account of
    the antisymmetry of $\omega^2_{ij}$, we get
    \begin{align}
    \sum_{\operatorname{cyc}} ((A, B), C)
    &=
    \sum_{\substack{\operatorname{cyc}\\ i,j,k}}
    \left[
    \frac{ \partial \omega^2_{ij} } { \partial x_k } B_i \, A_j \, C_k
    + \frac{ \partial C_j } { \partial x_k } \omega^2_{ij} (A_i \, B_k - A_k \, B_i).
    \right]
    \notag \\
    &=
    \sum_{\substack{\operatorname{cyc}\\ i,j,k}}
    \left[
    -\frac{ \partial \omega^2_{ij} } { \partial x_k } A_i \, B_j \, C_k
    + \frac{ \partial \omega^2_{ij} } { \partial x_k } (A_i \, B_k \, C_j - A_k \, B_i \, C_j)
    \right]
    \notag \\
    &\hphantom{=}
    + \sum_{\substack{\operatorname{cyc}\\ i,j,k}}
    \frac{ \partial (\omega^2_{ij} \, C_j) } { \partial x_k } (A_i \, B_k - A_k \, B_i).
    \notag \\
    &=
    \sum_{\substack{\operatorname{cyc}\\ i,j,k}}
    -\left[
    \frac{ \partial \omega^2_{ij} } { \partial x_k }
    +
    \frac{ \partial \omega^2_{jk} } { \partial x_i }
    +
    \frac{ \partial \omega^2_{ki} } { \partial x_j }
    \right]
    A_i \, B_j \, C_k
    +
    \frac{ \partial (\omega^1_C)_i } { \partial x_k } (A_i \, B_k - A_k \, B_i),
    \label{eq:jacobi_hf_proof}
    \end{align}
    where in the second step, we have used
    $\partial (\omega^2_{ij} C_j) = C_j \partial \omega^2_{ij} + \omega^2_{ij} C_j$.
    In the last step, we used the fact that
    $\omega^2_{ij} C_j = I^{-1}_{ij} C_j$
    gives the 1-form corresponds to the vector field $\mathbf C$,
    which is $\omega^1_C = dC$.
    %
    Now for the first term of \eqref{eq:jacobi_hf_proof},
    the sum in the square brackets for any $i$, $j$, and $k$
    vanishes because $\omega^2$ is closed.
    %
    For the second term,
    $\partial (\omega^1_C)_i /\partial x_k = \partial^2 C/\partial x_i \partial x_k$
    is symmetric with respect to $i$ and $k$;
    and its product with the antisymmetric tensor $A_i B_k - A_k B_i$
    is zero.

    The argument given in the book might not address the term
    containing the square brackets,
    although it obviously vanishes when $\omega^2$ does not depend on
    coordinates.
  }
\end{proof}

% Corollary 5
\begin{cor}
  Let $\mathbf B$ and $\mathbf C$ be hamiltonian fields
  with hamiltonian function $B$ and $C$.
  Consider the Poisson bracket $[\mathbf B, \mathbf C]$
  of the vector fields.
  This vector field is hamiltonian,
  and its hamiltonian function is equal to the Poisson bracket
  of the hamiltonian functions $(B, C)$.
\end{cor}

\begin{proof}
  Set $(B, C) = D$.
  The Jacobi identity can be written in the form
  \begin{align}
    &(A, D) = ((A, B), C) - ((A, C), B)
    \label{eq:jacobi_D} \\
    &L_\mathbf{D} = L_\mathbf{C} L_\mathbf{B} - L_\mathbf{B} L_\mathbf{C}
    \qquad L_\mathbf{D} = L_{[\mathbf B, \mathbf C]}
    \notag
  \end{align}
  as was to be shown.

  \note{The left-hand side of \eqref{eq:jacobi_D}
    can be written as $L_{IdD} A = L_\mathbf{D} A$.
    The right-hand side of \eqref{eq:jacobi_D} is
    $
      (L_{IdB} A, C) - (L_{IdC} A, B)
    = L_{IdC} L_{IdB} A - L_{IdB} L_{IdC} A
    = (L_\mathbf{C} L_\mathbf{B} - L_\mathbf{B} L_\mathbf{C}) A
    = L_{[\mathbf B, \mathbf C]} A.
    $
  }
\end{proof}


% subsection 40C
\subsection{The Lie algebra of hamiltonian fields,
hamiltonian functions, and first integrals}

A linear subspace of a Lie algebra is called a \emph{subalgebra}
if the commutator of any two elements of the subspace
belongs to it.
%
A subalgebra of a Lie algebra is itself a Lie algebra.
%
The preceding corollary implies, in particular,

% Corollary 6
\begin{cor}
  The hamiltonian vector fields on a symplectic manifold
  form a subalgebra of the Lie algebra of all vector fields.
\end{cor}

Poisson's theorem of the first integrals
can be reformulated as

% Corollary 7
\begin{cor}
  The first integrals of a hamiltonian phase flow
  form a subalgebra of the Lie algebra of all functions.
\end{cor}

The Lie algebra of hamiltonian functions can be
mapped naturally onto the Lie algebra of hamiltonian
vector fields.
\note{A function $f$ from $X$ to $Y$ is \emph{surjective}
  (or \emph{onto}), if every element $y \in Y$
  has at least one preimage $x \in X$, such that $f(x) = y$.
  On the other hand, a function is \emph{injective}
  if every element $y \in Y$ has at most one preimage $x$
  such $f(x) = y$. If a function is surjective and injective,
  then it is \emph{bijective}, or \emph{one-to-one}.
}
%
To do this, to every function $H$ we associate the hamiltonian
vector field $\mathbf H$ with \emph{hamiltonian function} $H$.

% Corollary 8
\begin{cor}
  The map of the Lie algebra of functions
  onto the Lie algebra of hamiltonian fields
  is an algebra homomorphism.
  Its kernel consists of the locally constant
  functions.
  If $M^{2n}$ is connected,
  the kernel is one-dimensional and consists of constants.
\end{cor}

\note{A homomorphism is a mapping between two algebras
  preserving some structure
  (here it is the Poisson bracket for Lie algebra,
  and the mapping is linear).
  Here, the ``kernel'' means the set of functions
  that are mapped to the null hamiltonian field.
}

\begin{proof}
  Our map is linear. Corollary 5 says that our map carries
  the Poisson bracket of functions into the Poisson bracket
  of vector fields. The kernel consists of functions
  for which $IdH \equiv 0$.
  Since $I$ is an isomorphism, $dH \equiv 0$ and $H = \mathrm{const}$.
\end{proof}

% Corollary 9
\begin{cor}
  The phase flows with hamiltonian functions $H_1$ and $H_2$
  commute if and only if the Poisson bracket of the functions
  $H_1$ and $H_2$ is (locally) constant.
\end{cor}

\begin{proof}
  By the theorem in Section 39, E, it is necessary and sufficient
  that $[\mathbf H_1, \mathbf H_2] \equiv 0$,
  and by Corollary 8 this condition is equivalent to
  $d(H_1, H_2) \equiv 0$.
\end{proof}

We obtain yet another generalization of E. Noether's theorem:
given a flow \note{$g_{H_2}^t$}
which commutes with the one under consideration \note{$g_{H_1}^t$},
one can construct a first integral \note{$(H_1, H_2)$}.

% subsection 40D
\subsection{Locally hamiltonian vector fields}

Let $(M^{2n}, \omega^2)$ be a symplectic manifold and
$g^t: M^{2n} \to M^{2n}$
a one-parameter group of diffeomorphisms preserving
the symplectic structure.
%
Will $g^t$ be a hamiltonian flow?


\begin{ex*}
  Let $M^{2n}$ be a two-dimensional torus $T^2$,
  a point of which is given by a pair of coordinates
  $(p, q) \mod 1$.
  Let $\omega^2$ be the usual area element $dp \wedge dq$.
  Consider the family of translations
  $g^t(p, q) = (p + t, q)$ (Figure 173).
  The maps $g^t$ preserve the symplectic structure
  (i.e., area). Can we find a hamiltonian function
  corresponding to the vector field ($\dot p=1, \dot q = 0$)?
  If $\dot p = -\partial H/\partial q$
  and $\dot q = \partial H/\partial p$,
  we would have $\partial H/\partial p = 0$ and
  $\partial H/\partial q = -1$, i.e.,
  $H = -q + C$.
  But $q$ is only a \emph{local} coordinate on $T^2$;
  \note{over a period $1$, $q$ has to increase by $1$,
  so is $H$. So the value of $H$ is not uniquely defined.}
  there is no map $H: T^2 \to \mathbb R$
  for which $\partial H/\partial p = 0$ and
  $\partial H/\partial q = 1$.
  Thus $g^t$ is not a hamiltonian phase flow.

  \setcounter{figure}{172}
  \begin{figure}[h]
    \centering
   \begin{tikzpicture}
      %\draw (-1,0) to[bend left] (1,0);
      %\draw (-1.2,.1) to[bend right] (1.2,.1);
      \draw[rotate=0] (0,0.1) ellipse (0.8 and 0.3);
      \draw[rotate=0] (0,0) ellipse (2 and 1);
      \draw[ultra thick] plot [smooth,tension=1.2]
        coordinates{(-1.95, -0.2) (0, -0.8) (1.95, -0.2)};

      % arrows
      \draw[thick,->] plot [smooth,tension=1.0]
        coordinates{(-0.7,  0.95) (-0.5,  0.8) (-0.3, 0.4)};

      \draw[thick,->] plot [smooth,tension=1.0]
        coordinates{(-1.5,  0.65) (-1.2,  0.6) (-0.75, 0.2)};

      \draw[thick,->] plot [smooth,tension=1.0]
        coordinates{(-1.95, -0.2) (-1.5, 0.05) (-0.8, 0)};

      \draw[thick,->] plot [smooth,tension=1.0]
        coordinates{(-1.5, -0.7) (-1.2, -0.3) (-0.7, -0.1)};

      \draw[thick,->] plot [smooth,tension=1.0]
        coordinates{(-0.8, -0.9) (-0.6, -0.55) (-0.3, -0.2)};

      \draw[thick,->] plot [smooth,tension=1.0]
        coordinates{( 0.0, -1.0) ( 0, -0.2)};

      \draw[thick,->] plot [smooth,tension=1.0]
        coordinates{( 0.8, -0.9) ( 0.6, -0.55) ( 0.3, -0.2)};

      \draw[thick,->] plot [smooth,tension=1.0]
        coordinates{( 1.5, -0.7) ( 1.2, -0.3) ( 0.7, -0.1)};

      \draw[thick,->] plot [smooth,tension=1.0]
        coordinates{( 1.95, -0.2) ( 1.5, 0.05) ( 0.8, 0)};

      \draw[thick,->] plot [smooth,tension=1.0]
        coordinates{( 1.5,  0.65) ( 1.2,  0.6) ( 0.75, 0.2)};

      \draw[thick,->] plot [smooth,tension=1.0]
        coordinates{( 0.7,  0.95) ( 0.5,  0.8) ( 0.3, 0.4)};

      \draw[thick,->] plot [smooth,tension=1.0]
        coordinates{( 0.0,  1.0)  ( 0.0,  0.4)};

      \node[] at (-1.0, -1.1) {$q$};
      \node[] at (-1.8,  0.6) {$p$};
    \end{tikzpicture}
    \caption{A locally hamiltonian field on the torus}
  \end{figure}

\end{ex*}


\begin{defn*}
  A \emph{locally hamiltonian vector field}
  on a symplectic manifold $(M^{2n}, \omega^2)$
  is the vector field $I\omega^1$,
  where $\omega^1$ is closed 1-form on $M^{2n}$.
\end{defn*}

Locally, a closed 1-form is the differential of a function,
$\omega^1 = dH$.
However, in attempting to extend the function $H$
to the whole manifold $M^{2n}$,
we may obtained a ``many-valued hamiltonian function,''
since a closed 1-form on a non-simply-connected manifold
may not be a differential (for example, the form $dq$ on $T^2$).
%
A phase flow given by a locally hamiltonian vector field
is called a \emph{locally hamiltonian flow}.

\begin{prob*}
  Show that a one-parameter group of diffeomorphisms of
  a symplectic manifold preserves the symplectic structure
  if and only if it is a locally hamiltonian phase flow.

  \hint{ Cf. Section 38A. }

  \answer{
    For a chain $c$ of one cell,
    $$
    \begin{aligned}
     \left( \int_{gc} - \int_{c} \right) \omega^2
     &\stackrel{1}{=}
     \int_{\partial(Jc)} \omega^2 + \int_{J\partial c} \omega^2
     \stackrel{2}{=}
     \int_{Jc} d\omega^2
     - \int_0^\tau \int_0^1 \omega^2(\pmb\xi, \pmb\eta) \, ds \, dt
      \\
      &\stackrel{3}{=}
     - \int_0^\tau \int_0^1 \omega^2(\pmb\xi, I\omega^1) \, ds \, dt
     \stackrel{4}{=} - \int_0^\tau \int_0^1 \omega^1(\pmb\xi) \, ds \, dt
     \\
     &= - \int_0^\tau \int_{g^\tau \partial c} \omega^1 \, ds \, dt
     \stackrel{5}{=} - \int_0^\tau \int_{\partial (g^\tau c)} \omega^1 \, ds \, dt
     \\
     &= - \int_0^\tau \int_{g^\tau c} d\omega^1 \, ds \, dt
     \stackrel{6}{=} 0.
     \end{aligned}
     $$
     (1 by the homotopy formula in Section 38A;
     2 by Stokes' formula;
     3 by the definition of $\pmb\eta$;
     4 by the definition of isomorphism $I$;
     5 by the definition of boundary;
     6 because $\omega^1$ is closed.

     For the other direction, invert the above steps.
   }
\end{prob*}

\begin{prob*}
  Show that in the symplectic space $\mathbb R^{2n}$,
  every one-parameter group of canonical diffeomorphisms
  (preserving $d\mathbf p \wedge d\mathbf q$)
  is a hamiltonian flow.

  \hint{Every closed 1-form on $\mathbb R^{2n}$ is the differential of a function.}

  \answer{
    Every one-parameter group of canonical diffeomorphisms
    is generated by a closed 2-form $\omega^1$.
    But $\mathbb R^{2n}$ is a vector space,
    so by Section 36, we know $\omega^1$ is a differential $dH$
    by the cone construction.
    Thus, the flow generated by $I\omega^1 = IdH$ is a hamiltonian flow.
  }
\end{prob*}

\begin{prob*}
  Show that the locally hamiltonian vector fields form
  a subalgebra of the Lie algebra of all vector fields.
  In addition, the Poisson bracket of two locally hamiltonian fields
  is actually a hamiltonian field, with a hamiltonian function
  uniquely determined by the given fields $\pmb\xi$ and $\pmb\eta$,
  by the formula $H=\omega^2(\pmb\xi, \pmb\eta)$.
  Thus, the hamiltonian fields form an ideal
  in the Lie algebra of locally hamiltonian fields.

  \answer{
    We shall establish a mapping from closed 1-forms
    to locally hamiltonian vector fields
    in a similar fashion of establishing the mapping from
    hamiltonian functions to hamiltonian vector fields,
    as done in the book.

    For two closed 1-forms $\omega_A$ and $\omega_B$, we define
    the Poisson bracket as
    \begin{equation}
    (\omega_A, \omega_B)
    = d [ \omega^2(I\omega_B, I\omega_A) ]
    = d [ \omega^2(\mathbf B, \mathbf A) ],
    \label{eq:PB_closed_1-form}
    \end{equation}
    which is clearly also a closed 1-form
    (in fact, a total differential).
    The bilinearity and antisymmetry are readily seen.
    To verify the Jacobi identity,
    we use the component form
    $(\omega_A, \omega_B) = d\left(\sum_{ij} \omega^2_{ij} A_i B_j \right)$.
    If we denote $H_{AB} = \omega^2(\mathbf B, \mathbf A)$,
    then
    $$
    \begin{aligned}
    ((\omega_A, \omega_B), \omega_C)
    &= (dH_{AB}, \omega_C)
    = d[ \omega^2(\mathbf C, IdH_{AB}) ]
    = d[ dH_{AB}(\mathbf C) ]
    \\
    &= d\left[
      \sum_k \frac{ \partial H_{AB} } { \partial x_k } C_k
    \right]
    = d\left[
      \sum_{ijk} \frac{ \partial (\omega^2_{ij} A_i B_j) } { \partial x_k } C_k
    \right]
    = d H_{ABC},
    \end{aligned}
    $$
    where we have denoted the sum in the square brackets by $H_{ABC}$.
    Below we shall show that the cyclic sum $H_{ABC} + H_{BCA} + H_{CAB} = 0$,
    then the Jacobi identity follows naturally.
    %
    The proof follows that leading to \eqref{eq:jacobi_hf_proof}, and
    \begin{align}
    \sum_{\operatorname{cyc}} H_{ABC}
    &=
    \sum_{\substack{\operatorname{cyc}\\ i,j,k}}
    -\left[
    \frac{ \partial \omega^2_{ij} } { \partial x_k }
    +
    \frac{ \partial \omega^2_{jk} } { \partial x_i }
    +
    \frac{ \partial \omega^2_{ki} } { \partial x_j }
    \right]
    A_i \, B_j \, C_k
    +
    \frac{ \partial (\omega_C)_i } { \partial x_k } (A_i \, B_k - A_k \, B_i)
    =
    0.
    \notag
    \end{align}
    %
    Again, for the first term,
    the sum in the square brackets for any $i$, $j$, and $k$
    vanishes because $\omega^2$ is closed.
    %
    The second term vanishes because
    $\partial (\omega_C)_i /\partial x_k = \partial (\omega_C)_k/\partial x_i$
    is symmetric with respect to $i$ and $k$;
    whereas $A_i B_k - A_k B_i$ is antisymmetric.
    Thus $\sum_{\operatorname{cyc}} ((\omega_A, \omega_B), \omega_C)
    = d\left( \sum_{\operatorname{cyc}} H_{ABC} \right) = 0.$

    Let us establish a homeomorphism from closed 1-forms to
    locally hamiltonian vector fields.
    This is simply the isomorphism $I$
    of the symplectic structure: $\mathbf A = I \omega_A$.
    %
    From \eqref{eq:PB_closed_1-form}, we have
    $$
    (\omega_A, \omega_B)
    =
    d[ \omega^2(\mathbf B, I\omega_A) ]
    =
    d[ \omega_A(\mathbf B) ]
    =
    d (i_\mathbf{B} \omega_A)
    =
    L_\mathbf{B} \omega_A,
    $$
    where $i_\mathbf B \omega^1 \equiv \omega^1(\mathbf B)$
    is the interior derivative defined in Sec. 36;
    and we have used the homotopy formula
    $L_\mathbf{B} = d i_\mathbf{B} + i_\mathbf{B} d$,
    with $d\omega_A = 0$ (closed 1-form).
    %
    So
    $$
    ((\omega_A, \omega_B), \omega_C)
    -
    ((\omega_A, \omega_C), \omega_B)
    =
    L_\mathbf{C}L_\mathbf{B} \omega_A
    -
    L_\mathbf{B}L_\mathbf{C} \omega_A
    =
    L_{\mathbf{[B, C]}} \omega_A.
    $$
    By the Jacobi identity of closed 1-forms, this is equal to
    $$
    (\omega_A, (\omega_B, \omega_C))
    =
    L_{I(\omega_B, \omega_C)} \omega_A.
    $$
    This shows that the Poisson bracket $[\mathbf B, \mathbf C]$
    of the vector fields
    corresponds to a hamiltonian (hence locally hamiltonian) vector field
    $I(\omega_B, \omega_C)$.
  }
\end{prob*}

\section{Symplectic geometry}

\section{Parametric resonance in systems with many degrees of freedom}

\setcounter{subsection}{2}
% subsection C
\subsection{Stability}

\begin{defn*}
  A transformation $S$ is called \emph{stable} if
  $$
  \forall \epsilon > 0,
  \exists \delta > 0:
  |\mathbf x| < \delta
  \iff
  |S^N \mathbf x| < \epsilon|.
  \qquad
  \forall N > 0.
  $$
\end{defn*}

\begin{prob*}
  Show that if at least one of the eigenvalues of
  a symplectic transformation $S$ doe not lie on the unit circle,
  then $S$ is unstable.

  \hint{
    In view of the demonstrated symmetry, if one of the eigenvalues
    does not lie on the unit circle, there there exists an eigenvalue
    outside the unit circle $|\lambda| > 1$;
    in the corresponding invariant subspace,
    $S$ is an ``expansion with a rotation.''
  }
\end{prob*}

\begin{prob*}
  Show that if all the eigenvalues of a linear transformation
  are distinct and lie on the unit circle, then the transformation is stable.

  \hint{
    Change to a basis of eigenvectors.
  }

  \answer{
    Any vector can be expanded in eigenvectors as
    $\mathbf x = \sum_i c_i \, \mathbf v_i$,
    Then
    $S^N \mathbf x = \sum_i c_i \, \lambda_i^N \, \mathbf v_i$.
    %
    Since the eigenvectors are orthogonal,
    and the eigenvalues lie on the unit circle,
    we have
    $|S^N \mathbf x|^2 = \sum_{i} |c_i|^2 \, |\lambda_i^N|^2 = \sum_i |c_i|^2 = |\mathbf x|^2$.
    Thus, we only need to choose $\delta = \epsilon$,
    to satisfy the stability criterion.
  }
\end{prob*}

\begin{defn*}
  A symplectic transformation $S$ is called \emph{strongly stable}
  if every symplectic transformation sufficiently close\footnote{
    $S_1$ is sufficiently close to $S$ if the elements of
    the matrix of $S_1$ in a fixed basis differ from the
    elements of the matrix of $S$ in the same basis by less than a
    sufficiently small number $\epsilon$.
  }
  to $S$ is stable.
\end{defn*}

In Section 25 we establish that $S: \mathbb R^2 \to \mathbb R^2$
is strongly stable if $\lambda_{1,2} = e^{\pm i\alpha}$
and $\lambda_1 \ne \lambda_2$.

\begin{thm*}
  If all $2n$ eigenvalues of a symplectic transformation $S$ are distinct
  and lie on the unit circle, then $S$ is strongly stable.
\end{thm*}

\begin{proof}
  We enclose the $2n$ eigenvalues $\lambda$ in $2n$ non-intersecting neighborhoods,
  symmetric with respect to the unit circle and the real axis (Figure 177).
  The $2n$ roots of the characteristic polynomial depends continuously on
  the elements of the matrix of $S$.
  %
  Therefore, if the matrix $S_1$ is sufficiently close to $S$,
  exactly one eigenvalue $\lambda_1$ on the matrix of $S_1$
  will lie in each of the $2n$ neighborhoods of the $2n$
  points of $\lambda$.
  %
  But if one of the points $\lambda_1$ did not lie on the unit circle,
  for example, if it lay outside unit circle, then by the theorem in
  subsection B, there would be another $\lambda_2$, $|\lambda_2| < 1$
  in the same neighborhood,
  and the total number roots would be greater than $2n$,
  which is not possible.

  \setcounter{figure}{176}
  \begin{figure}[h]
    \centering
    \begin{tikzpicture}
      % large circle
      \draw[very thick] (0, 0) circle (2);
      % origin
      \node[circle, fill=black, label={below:$0$}] at (0, 0) {};
      % x-axis
      \draw[] (-2.7, 0) -- (2.7, 0);
      \node[label={-30:$1$}] at (2.0, 0) {};

      \draw[]           (1.732, 1) circle (0.40);
      \draw[fill=white] (1.732, 1) circle (0.10);

      \draw[]           (1, 1.732) circle (0.40);
      \draw[fill=white] (1, 1.732) circle (0.10);

      \draw[]           (-1, 1.732) circle (0.40);
      \draw[fill=white] (-1, 1.732) circle (0.10);

      \draw[]           (1.732, -1) circle (0.40);
      \draw[fill=white] (1.732, -1) circle (0.10);

      \draw[]           (1, -1.732) circle (0.40);
      \draw[fill=white] (1, -1.732) circle (0.10);

      \draw[]           (-1, -1.732) circle (0.40);
      \draw[fill=white] (-1, -1.732) circle (0.10);
    \end{tikzpicture}
    \caption{
      Behavior of simple eigenvalues under a small change
      of the symplectic transformation
    }
  \end{figure}

  Thus all the roots of $S_1$ lie on the unit circle and are distinct,
  so $S_1$ is stable.
\end{proof}

We might say that an eigenvalue $\lambda$ of
a symplectic transformation can leave the unit circle
only by colliding with another eigenvalue (Figure 178);
at the same time, the complex-conjugate eigenvalues
will collide, and from the two pairs of roots on the unit circle,
we obtain one 4-tuple (or pair real $\lambda$).

\begin{figure}[h]
  \centering
  \begin{tikzpicture}
    [
      wnode/.style={circle, fill=white, draw=black, minimum size=2mm, inner sep=0},
      enode/.style={minimum size=0, inner sep=0}
    ]
    % origin
    \node[circle, fill=black, label={above:$0$}] at (0, 0) {};
    % x-axis
    \draw[] (-2.5, 0) -- (2.5, 0);
    \node[label={30:$1$}] at (2.0, 0) {};

    % large circle
    \draw[thick] ( 1.732, -1.0) arc (-30:30:2);
    \draw[thick] ( 1.0,  1.732) arc (60:300:2);

    \node[wnode] (u1) at (1.732, 1.0) {};
    \node[wnode] (v1) at (1.8, 1.8) {};
    \node[enode] (uv1) at (1.48, 1.414) {};
    \draw[ultra thick, ->] (u1)[out=120,in=-90] to (uv1)[out=90,in=-135] to (v1);

    \node[wnode] (u2) at (1.0, 1.732) {};
    \node[wnode] (v2) at (1.0, 1.0) {};
    \node[enode] (uv2) at (1.34, 1.414) {};
    \draw[ultra thick, ->] (u2)[out=-30,in=90] to (uv2)[out=-90,in=45] to (v2);

    \node[wnode] (u3) at (1.732, -1.0) {};
    \node[wnode] (v3) at (1.8, -1.8) {};
    \node[enode] (uv3) at (1.48, -1.414) {};
    \draw[ultra thick, ->] (u3)[out=-120,in=90] to (uv3)[out=-90,in=135] to (v3);

    \node[wnode] (u4) at (1.0, -1.732) {};
    \node[wnode] (v4) at (1.0, -1.0) {};
    \node[enode] (uv4) at (1.34, -1.414) {};
    \draw[ultra thick, ->] (u4)[out=30,in=-90] to (uv4)[out=90,in=-45] to (v4);
  \end{tikzpicture}
  \caption{
    Behavior of multiple eigenvalues under a small
    change of the symplectic transformation
  }
\end{figure}

It follows from the results of Section 25 that the condition
for parametric resonance to arise in a linear canonical system
with a periodically changing hamilton function is precisely that
the corresponding symplectic transformation of phase space
should cease to be stable.
%
It is clear from the theorem above that this can happen only after
a collision of eigenvalues on the unit circle.
%
In fact as M. G. Krein noticed, not every such collision is dangerous.

It turns out that the eigenvalues $\lambda$ with $|\lambda| = 1$
are divided into two classes:
\emph{positive} and \emph{negative}.
%
When two roots with the same sign collide,
the roots ``go through one another,''
and cannot leave the unit circle.
%
On the other hand,
when two roots with different signs collide,
they generally leave the unit circle.

M.G. Krein's theory goes beyond the limits of this book;
we will formulate the basic results here in the form of problems.




\section{A symplectic atlas}

\chapter{Canonical formalism}

\section{The integral invariant of Poincar\'e-Cartan}

\section{Applications of the integral invariant of Poincar\'e-Cartan}

\section{Huygens' principle}

\section{The Hamilton-Jacobi method for integrating Hamilton's canonical equations}

\section{Generating functions}

\chapter{Introduction to perturbation theory}

\section{Integrable systems}

% section 50
\section{Action-angle variables}

We show here that, under the hypotheses of Liouville's theorem,
we can find symplectic coordinates $(\mathbf I, \pmb\varphi)$
such that the first integrals $\mathbf F$
depend only on $\mathbf I$, and $\pmb\varphi$
are angular coordinates on the torus $M_\mathbf{f}$.

% subsection A
\subsection{Description of action-angle variables}

In section 49 we studied one particular compact connected
level manifold of the integrals:
$M_\mathbf{f} = \{x: \mathbf F(x) = \mathbf f\}$;
it turned out that $M_\mathbf{f}$
was an $n$-dimensional torus,
invariant with respect to the phase flow.
\note{
Think about the $n$ phases $\varphi_i$ of $n$-independent oscillators,
each phase can vary from $0$ to $2\pi$ and then wrap back.
In this case, $F_i$ is the amplitude (or energy) of the $i$th oscillator.
}
%
We chose angular coordinates $\varphi_i$ on $M$
so that the phase flow with hamiltonian function $H = F_1$
takes an especially simple form:
$$
\frac{ d\pmb\varphi } { dt }
=
\pmb\omega(\mathbf f)
\qquad
\pmb\varphi(t)
=
\pmb\varphi(0)
+\pmb\omega t.
$$
We will now look at a neighborhood of the $n$-dimensional manifold $M_\mathbf{f}$
in $2n$-dimensional phase space.

\begin{prob*}
  Show that the manifold $M_\mathbf{f}$ has a neighborhood
  diffeomorphic to the direct product of the $n$-dimensional torus $T^n$
  and the disc $D^n$ in $n$-dimensional euclidean space.

  \hint{
    Take the functions $F_i$ and the angles $\varphi_i$ constructed above
    as coordinates.
    %
    In view of the linear independence of the $dF_i$,
    the functions $F_i$ and $\varphi_i$
    ($i = 1, \dots, n$)
    give a diffeomorphism of a neighborhood of $M_\mathbf{f}$
    onto the direct product $T^n \times D^n$.
  }
\end{prob*}

In the coordinates $(\mathbf F, \pmb\varphi)$
the phase flow with hamiltonian function $H = F_1$
can be written in the form of the simple system
of $2n$ ordinary differential equations
\begin{equation}
  \frac{ d \mathbf F } { dt } = 0
  \qquad
  \frac{ d \pmb\varphi } { dt } = \pmb\omega( \mathbf F ),
  \label{eq:eom_Fphi}
\end{equation}
which is easily integrated:
$\mathbf F(t) = \mathbf F(0)$,
$\pmb\varphi(t) = \pmb\varphi(0) + \pmb\omega(\mathbf F(0))\,t$.

Thus,
in order to integrate explicitly the original canonical system of
differential equations,
it is sufficient to find the variables $\pmb\varphi$
in explicit form.
%
It turns out that this can be done using only quadratures.
%
A construction of the variable $\pmb\varphi$ is given below.

We note that the variables $(\mathbf F, \pmb\varphi)$
are not, in general, symplectic coordinates.
%
It turns out that there are functions of $\mathbf F$,
which we will denote by
$\mathbf I = \mathbf I(\mathbf F), \mathbf I = (I_1, \dots, I_n)$,
such that the variables $(\mathbf I, \pmb\varphi)$
are symplectic coordinates:
the original symplectic structure $\omega^2$
is expressed in them  by the usual formula
$$
\omega^2 = \sum dI_i \wedge d\varphi_i.
$$
The variables $\mathbf I$
are called action variables;\footnote{
  It is not hard to see that $\mathbf I$ has the dimensions of action.
}
together with the angle variables $\pmb\varphi$
they form the \emph{action-angle system of canonical coodinates}
in a neighborhood of $M_\mathbf{f}$.
\note{
  The 2-form $\omega^2$ should not be confused with
  the function $\pmb\omega$ in \eqref{eq:eom_Fphi}.
}


The quantities $I_i$ are first integrals of the system with hamiltonian
function $H = F_1$, since they are functions of the first integrals $F_j$.
%
In turn, the variables $F_i$ can be expressed in terms of $\mathbf I$ and,
in particular, $H = F_1 = H(\mathbf I)$.
%
In action-angle variables the differential equations of our flow
\eqref{eq:eom_Fphi} have the form
\begin{equation}
  \frac{ d\mathbf I } { dt } = 0
  \qquad
  \frac{ d\pmb\varphi } { dt } = \pmb\omega(\mathbf I).
  \label{eq:eom_Iphi}
\end{equation}

\begin{prob*}
  Can the functions $\pmb\omega(\mathbf I)$ in \eqref{eq:eom_Iphi}
  be arbitrary?

  \solution{
    In the variables $(\mathbf I, \pmb\varphi)$,
    the equations of the flow \eqref{eq:eom_Iphi}
    have the canonical form with hamiltonian function $H(\mathbf I)$.
    Therefore,
    $\pmb\omega(\pmb I) = \partial H/\partial \mathbf I$;
    thus if the number of degrees of freedom is $n \ge 2$,
    the functions $\pmb\omega(\mathbf I)$ are not arbitrary,
    but satisfy the symmetry condition
    $\partial \omega_i /\partial I_j = \partial \omega_j/\partial I_i$.
  }
\end{prob*}

Action-angle variables are especially important for perturbation theory;
in Section 52 we will demonstrate their application to the theory
of adiabatic invariants.


% subsection B
\subsection{Construction of action-angle variables in the
  case of one degree of freedom}

A system with one degree of freedom in the phase plane $(p,q)$
is given by the hamiltonian function $H(p, q)$.

% Example 1
\begin{ex}
  The harmonic oscillator $H = \frac{1}{2} p^2 + \frac{1}{2} q^2$;
  or more generally $H = \frac{1}{2} a^2 \, p^2 + \frac{1}{2} b^2 \, q^2$.

  \note{
    $I = H, \varphi = \frac{1}{ab} \tan^{-1} \frac{bq}{ap}$.
  }
\end{ex}

% Example 2
\begin{ex}
  The mathematical pendulum $H = \frac{1}{2} p^2 - \cos q$.
  In both cases we have a compact closed curve
  $M_h(H = h)$, and the conditions of the theorem of Section 49
  for $n = 1$ are satisfied.
\end{ex}

In order to construct the action-angle variables,
we will look for a canonical transformation
$(p, q) \to (I, \varphi)$
satisfying the two conditions:
\begin{equation}
  \begin{aligned}
    1. \; & I = I(h), \\
    2. \; & \oint_{M_h} d\varphi = 2 \, \pi.
  \end{aligned}
  \label{eq:CT_Iphi_condition}
\end{equation}

\begin{prob*}
  Find the action-angle variables in the case of the simple harmonic oscillator
  $H = \frac{1}{2} p^2 + \frac{1}{2} q^2$.

  \solution{
    If $r, \phi$ are polar coordinates,
    then $dp \wedge dq = r dr \wedge d\varphi = d(r^2/2) \wedge d\varphi$.
    Therefore, $I = H = (p^2 + q^2)/2$.
  }
\end{prob*}

In order to construct the canonical transformation $p, q \to I, \varphi$
in the general case, we will look for its generating function $S(I, q)$:
\note{
  Here $S = -F_2$, for
  $d(-F_1) = p \, dq - I \, d\varphi$,
  we have
  $dS = d(I \varphi - F_1) = p \, dq + \varphi \, d I$.
}
\begin{equation}
  p = \frac{ \partial S(I, q) } { \partial q }
  \quad
  \phi = \frac{ \partial S(I, q) } { \partial I }
  \quad
  H\left(
    \frac{ \partial S(I, q) } { \partial q },
    q
  \right)
  = h(I).
  \label{eq:S_Iq}
\end{equation}
We first assume that the function $h(I)$ is known
and invertible, so that every curve $M_h$ is determined
by the value of $I$ ($M_h = M_{h(I)}$).
%
Then for a fixed value of $I$
we have from \eqref{eq:S_Iq}
$$
dS\big|_{I = \mathrm{const}} = p \, dq.
$$
This relation determines a well-defined differential 1-form $dS$
on the curve $M_{h(I)}$.

Integrating this 1-form on the curve $M_{h(I)}$
we obtain (in a neighborhood of a point $q_0$)
a function
$$
S(I, q) = \int_{q_0}^q p \, dq.
$$
This function will be the generating function
of the transformation \eqref{eq:S_Iq}
in a neighborhood of the point $(I, q_0)$.
%
The first of the conditions \eqref{eq:CT_Iphi_condition}
is satisfied automatically: $I = I(h)$.
%
To verify the second condition,
we consider the behavior of $S(I, q)$ ``in the large.''
%
After a circuit of the closed curve $M_{h(I)}$
the integral of $p\, dq$ increases by
$$
\Delta S(I) = \oint_{M_{h(I)}} p \, dq.
$$
equal to the area $\Pi$ enclosed by the curve $M_{h(I)}$.
%
Therefore, the function $S$ is a ``multiple-valued function''
on $M_{h(I)}$:
it is determined up to addition of integral multiples of $\Pi$.
%
This term has no effect of the derivative
$\partial S(I, q)/\partial I$;
but it leads to the multi-valuedness of $\varphi = \partial S/\partial I$.
%
This derivative turns out to be defined only up to multiples of
$d \Delta S(I) / dI$.
%
More precisely,
the formulas \eqref{eq:S_Iq}
define a 1-form $d\varphi$ on the curve $M_{h(I)}$,
and the integral of this form on $M_{h(I)}$
is equal to $d\Delta S(I)/dI$.

In order to fulfill the second condition,
$\oint_{M_{h}} d\varphi = 2 \pi$,
we need that
$$
\frac{d}{dI} \Delta S(I) = 2 \, \pi
\qquad
I = \frac{ \Delta S  }{ 2 \pi }
= \frac{ \Pi } { 2 \pi },
$$
where
$\Pi = \int_{M_h} p \, dq$
is the area bounded by the phase curve $H = h$.

\begin{defn*}
  The \emph{action variable} in the one-dimensional problem
  with hamiltonian function $H(p, q)$
  is the quantity $I(h) = (1/2\pi) \Pi(h)$.
\end{defn*}

Finally, we arrive at the following conclusion.
%
Let $d\Pi \, dh \ne 0$.
%
Then the inverse $I(h)$ of the function $h(I)$ is defined.

\section{Averaging}

\section{Averaging of perturbations}

%\appendix
%\renewcommand{\thechapter}{\arabic{chapter}}
%
%\chapter{Riemannian curvature}
%
%\chapter{Geodesics of left-invariant metrics on Lie groups and
%the hydrodynamics of ideal fluids}
%
%\chapter{Symplectic structures on algebraic manifolds}
%
%\chapter{Contact structures}
%
%\chapter{Dynamical systems with symmetries}
%
%\chapter{Normal forms of quadratic hamiltonians}
%
%\chapter{Normal forms of hamiltonian systems near stationary points
%and closed trajectories}
%
%\chapter{Theory of perturbations of conditionally periodic motion,
%and Kolmogorov's theorem}
%
%\chapter{Poincar\'e's geometric theorem, its generalizations and
%applications}
%
%\chapter{Multiplicities of characteristic frequencies, and ellipoids
%depending on parameters}
%
%\chapter{Short wave asymptotics}
%
%\chapter{Lagrangian singularities}
%
%\chapter{The Korteweg-de Vries equation}
%
%\chapter{Poisson structures}
%
%\chapter{On elliptic coordinates}
%
%\chapter{Singularities of ray systems}

\end{document}
